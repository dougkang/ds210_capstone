WARNING: Logging before InitGoogleLogging() is written to STDERR
I1026 01:51:20.884052  2532 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1026 01:51:20.884207  2532 net.cpp:435] Input 0 -> data
I1026 01:51:20.884276  2532 layer_factory.hpp:76] Creating layer conv1
I1026 01:51:20.884306  2532 net.cpp:110] Creating Layer conv1
I1026 01:51:20.884317  2532 net.cpp:477] conv1 <- data
I1026 01:51:20.884337  2532 net.cpp:433] conv1 -> conv1
I1026 01:51:20.884452  2532 net.cpp:155] Setting up conv1
I1026 01:51:20.884480  2532 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1026 01:51:20.884512  2532 layer_factory.hpp:76] Creating layer relu1
I1026 01:51:20.884528  2532 net.cpp:110] Creating Layer relu1
I1026 01:51:20.884539  2532 net.cpp:477] relu1 <- conv1
I1026 01:51:20.884551  2532 net.cpp:419] relu1 -> conv1 (in-place)
I1026 01:51:20.884572  2532 net.cpp:155] Setting up relu1
I1026 01:51:20.884584  2532 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1026 01:51:20.884594  2532 layer_factory.hpp:76] Creating layer pool1
I1026 01:51:20.884608  2532 net.cpp:110] Creating Layer pool1
I1026 01:51:20.884618  2532 net.cpp:477] pool1 <- conv1
I1026 01:51:20.884630  2532 net.cpp:433] pool1 -> pool1
I1026 01:51:20.884655  2532 net.cpp:155] Setting up pool1
I1026 01:51:20.884680  2532 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1026 01:51:20.884690  2532 layer_factory.hpp:76] Creating layer norm1
I1026 01:51:20.884704  2532 net.cpp:110] Creating Layer norm1
I1026 01:51:20.884714  2532 net.cpp:477] norm1 <- pool1
I1026 01:51:20.884726  2532 net.cpp:433] norm1 -> norm1
I1026 01:51:20.884753  2532 net.cpp:155] Setting up norm1
I1026 01:51:20.884766  2532 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1026 01:51:20.884776  2532 layer_factory.hpp:76] Creating layer conv2
I1026 01:51:20.884789  2532 net.cpp:110] Creating Layer conv2
I1026 01:51:20.884799  2532 net.cpp:477] conv2 <- norm1
I1026 01:51:20.884811  2532 net.cpp:433] conv2 -> conv2
I1026 01:51:20.885823  2532 net.cpp:155] Setting up conv2
I1026 01:51:20.885841  2532 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1026 01:51:20.885857  2532 layer_factory.hpp:76] Creating layer relu2
I1026 01:51:20.885870  2532 net.cpp:110] Creating Layer relu2
I1026 01:51:20.885880  2532 net.cpp:477] relu2 <- conv2
I1026 01:51:20.885891  2532 net.cpp:419] relu2 -> conv2 (in-place)
I1026 01:51:20.885905  2532 net.cpp:155] Setting up relu2
I1026 01:51:20.885915  2532 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1026 01:51:20.885926  2532 layer_factory.hpp:76] Creating layer pool2
I1026 01:51:20.885937  2532 net.cpp:110] Creating Layer pool2
I1026 01:51:20.885947  2532 net.cpp:477] pool2 <- conv2
I1026 01:51:20.885958  2532 net.cpp:433] pool2 -> pool2
I1026 01:51:20.885973  2532 net.cpp:155] Setting up pool2
I1026 01:51:20.885985  2532 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1026 01:51:20.885995  2532 layer_factory.hpp:76] Creating layer norm2
I1026 01:51:20.886008  2532 net.cpp:110] Creating Layer norm2
I1026 01:51:20.886018  2532 net.cpp:477] norm2 <- pool2
I1026 01:51:20.886029  2532 net.cpp:433] norm2 -> norm2
I1026 01:51:20.886042  2532 net.cpp:155] Setting up norm2
I1026 01:51:20.886054  2532 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1026 01:51:20.886065  2532 layer_factory.hpp:76] Creating layer conv3
I1026 01:51:20.886077  2532 net.cpp:110] Creating Layer conv3
I1026 01:51:20.886087  2532 net.cpp:477] conv3 <- norm2
I1026 01:51:20.886099  2532 net.cpp:433] conv3 -> conv3
I1026 01:51:20.889821  2532 net.cpp:155] Setting up conv3
I1026 01:51:20.889843  2532 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1026 01:51:20.889860  2532 layer_factory.hpp:76] Creating layer relu3
I1026 01:51:20.889873  2532 net.cpp:110] Creating Layer relu3
I1026 01:51:20.889883  2532 net.cpp:477] relu3 <- conv3
I1026 01:51:20.889894  2532 net.cpp:419] relu3 -> conv3 (in-place)
I1026 01:51:20.889907  2532 net.cpp:155] Setting up relu3
I1026 01:51:20.889919  2532 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1026 01:51:20.889930  2532 layer_factory.hpp:76] Creating layer conv4
I1026 01:51:20.889941  2532 net.cpp:110] Creating Layer conv4
I1026 01:51:20.889951  2532 net.cpp:477] conv4 <- conv3
I1026 01:51:20.889962  2532 net.cpp:433] conv4 -> conv4
I1026 01:51:20.892750  2532 net.cpp:155] Setting up conv4
I1026 01:51:20.892771  2532 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1026 01:51:20.892786  2532 layer_factory.hpp:76] Creating layer relu4
I1026 01:51:20.892798  2532 net.cpp:110] Creating Layer relu4
I1026 01:51:20.892808  2532 net.cpp:477] relu4 <- conv4
I1026 01:51:20.892819  2532 net.cpp:419] relu4 -> conv4 (in-place)
I1026 01:51:20.892832  2532 net.cpp:155] Setting up relu4
I1026 01:51:20.892844  2532 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1026 01:51:20.892854  2532 layer_factory.hpp:76] Creating layer conv5
I1026 01:51:20.892866  2532 net.cpp:110] Creating Layer conv5
I1026 01:51:20.892876  2532 net.cpp:477] conv5 <- conv4
I1026 01:51:20.892889  2532 net.cpp:433] conv5 -> conv5
I1026 01:51:20.894765  2532 net.cpp:155] Setting up conv5
I1026 01:51:20.894785  2532 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1026 01:51:20.894803  2532 layer_factory.hpp:76] Creating layer relu5
I1026 01:51:20.894816  2532 net.cpp:110] Creating Layer relu5
I1026 01:51:20.894826  2532 net.cpp:477] relu5 <- conv5
I1026 01:51:20.894839  2532 net.cpp:419] relu5 -> conv5 (in-place)
I1026 01:51:20.894865  2532 net.cpp:155] Setting up relu5
I1026 01:51:20.894878  2532 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1026 01:51:20.894888  2532 layer_factory.hpp:76] Creating layer pool5
I1026 01:51:20.894901  2532 net.cpp:110] Creating Layer pool5
I1026 01:51:20.894911  2532 net.cpp:477] pool5 <- conv5
I1026 01:51:20.894922  2532 net.cpp:433] pool5 -> pool5
I1026 01:51:20.894938  2532 net.cpp:155] Setting up pool5
I1026 01:51:20.894950  2532 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1026 01:51:20.894960  2532 layer_factory.hpp:76] Creating layer fc6
I1026 01:51:20.894983  2532 net.cpp:110] Creating Layer fc6
I1026 01:51:20.894992  2532 net.cpp:477] fc6 <- pool5
I1026 01:51:20.895005  2532 net.cpp:433] fc6 -> fc6
I1026 01:51:21.054038  2532 net.cpp:155] Setting up fc6
I1026 01:51:21.054113  2532 net.cpp:163] Top shape: 10 4096 (40960)
I1026 01:51:21.054136  2532 layer_factory.hpp:76] Creating layer relu6
I1026 01:51:21.054160  2532 net.cpp:110] Creating Layer relu6
I1026 01:51:21.054172  2532 net.cpp:477] relu6 <- fc6
I1026 01:51:21.054188  2532 net.cpp:419] relu6 -> fc6 (in-place)
I1026 01:51:21.054205  2532 net.cpp:155] Setting up relu6
I1026 01:51:21.054216  2532 net.cpp:163] Top shape: 10 4096 (40960)
I1026 01:51:21.054226  2532 layer_factory.hpp:76] Creating layer drop6
I1026 01:51:21.054263  2532 net.cpp:110] Creating Layer drop6
I1026 01:51:21.054275  2532 net.cpp:477] drop6 <- fc6
I1026 01:51:21.054286  2532 net.cpp:419] drop6 -> fc6 (in-place)
I1026 01:51:21.054304  2532 net.cpp:155] Setting up drop6
I1026 01:51:21.054317  2532 net.cpp:163] Top shape: 10 4096 (40960)
I1026 01:51:21.054328  2532 layer_factory.hpp:76] Creating layer fc7
I1026 01:51:21.054342  2532 net.cpp:110] Creating Layer fc7
I1026 01:51:21.054352  2532 net.cpp:477] fc7 <- fc6
I1026 01:51:21.054365  2532 net.cpp:433] fc7 -> fc7
I1026 01:51:21.124961  2532 net.cpp:155] Setting up fc7
I1026 01:51:21.125036  2532 net.cpp:163] Top shape: 10 4096 (40960)
I1026 01:51:21.125056  2532 layer_factory.hpp:76] Creating layer relu7
I1026 01:51:21.125077  2532 net.cpp:110] Creating Layer relu7
I1026 01:51:21.125088  2532 net.cpp:477] relu7 <- fc7
I1026 01:51:21.125102  2532 net.cpp:419] relu7 -> fc7 (in-place)
I1026 01:51:21.125120  2532 net.cpp:155] Setting up relu7
I1026 01:51:21.125131  2532 net.cpp:163] Top shape: 10 4096 (40960)
I1026 01:51:21.125141  2532 layer_factory.hpp:76] Creating layer drop7
I1026 01:51:21.125156  2532 net.cpp:110] Creating Layer drop7
I1026 01:51:21.125166  2532 net.cpp:477] drop7 <- fc7
I1026 01:51:21.125180  2532 net.cpp:419] drop7 -> fc7 (in-place)
I1026 01:51:21.125193  2532 net.cpp:155] Setting up drop7
I1026 01:51:21.125205  2532 net.cpp:163] Top shape: 10 4096 (40960)
I1026 01:51:21.125216  2532 layer_factory.hpp:76] Creating layer fc8
I1026 01:51:21.125231  2532 net.cpp:110] Creating Layer fc8
I1026 01:51:21.125241  2532 net.cpp:477] fc8 <- fc7
I1026 01:51:21.125252  2532 net.cpp:433] fc8 -> fc8
I1026 01:51:21.142278  2532 net.cpp:155] Setting up fc8
I1026 01:51:21.142320  2532 net.cpp:163] Top shape: 10 1000 (10000)
I1026 01:51:21.142338  2532 layer_factory.hpp:76] Creating layer prob
I1026 01:51:21.142354  2532 net.cpp:110] Creating Layer prob
I1026 01:51:21.142365  2532 net.cpp:477] prob <- fc8
I1026 01:51:21.142380  2532 net.cpp:433] prob -> prob
I1026 01:51:21.142415  2532 net.cpp:155] Setting up prob
I1026 01:51:21.142427  2532 net.cpp:163] Top shape: 10 1000 (10000)
I1026 01:51:21.142437  2532 net.cpp:240] prob does not need backward computation.
I1026 01:51:21.142448  2532 net.cpp:240] fc8 does not need backward computation.
I1026 01:51:21.142458  2532 net.cpp:240] drop7 does not need backward computation.
I1026 01:51:21.142468  2532 net.cpp:240] relu7 does not need backward computation.
I1026 01:51:21.142478  2532 net.cpp:240] fc7 does not need backward computation.
I1026 01:51:21.142489  2532 net.cpp:240] drop6 does not need backward computation.
I1026 01:51:21.142498  2532 net.cpp:240] relu6 does not need backward computation.
I1026 01:51:21.142508  2532 net.cpp:240] fc6 does not need backward computation.
I1026 01:51:21.142547  2532 net.cpp:240] pool5 does not need backward computation.
I1026 01:51:21.142559  2532 net.cpp:240] relu5 does not need backward computation.
I1026 01:51:21.142568  2532 net.cpp:240] conv5 does not need backward computation.
I1026 01:51:21.142596  2532 net.cpp:240] relu4 does not need backward computation.
I1026 01:51:21.142608  2532 net.cpp:240] conv4 does not need backward computation.
I1026 01:51:21.142618  2532 net.cpp:240] relu3 does not need backward computation.
I1026 01:51:21.142628  2532 net.cpp:240] conv3 does not need backward computation.
I1026 01:51:21.142639  2532 net.cpp:240] norm2 does not need backward computation.
I1026 01:51:21.142649  2532 net.cpp:240] pool2 does not need backward computation.
I1026 01:51:21.142659  2532 net.cpp:240] relu2 does not need backward computation.
I1026 01:51:21.142669  2532 net.cpp:240] conv2 does not need backward computation.
I1026 01:51:21.142679  2532 net.cpp:240] norm1 does not need backward computation.
I1026 01:51:21.142689  2532 net.cpp:240] pool1 does not need backward computation.
I1026 01:51:21.142699  2532 net.cpp:240] relu1 does not need backward computation.
I1026 01:51:21.142709  2532 net.cpp:240] conv1 does not need backward computation.
I1026 01:51:21.142719  2532 net.cpp:283] This network produces output prob
I1026 01:51:21.142745  2532 net.cpp:297] Network initialization done.
I1026 01:51:21.142755  2532 net.cpp:298] Memory required for data: 62497920
I1026 01:51:22.114936  2532 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1026 01:51:22.115020  2532 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1026 01:51:22.115031  2532 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1026 01:51:22.115041  2532 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1026 01:51:22.622298  2532 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
58.152.249.17:43095 - - [26/Oct/2015 01:51:23] "HTTP/1.1 POST /resources/1" - 200 OK
I1026 01:51:41.928040  2533 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1026 01:51:41.928148  2533 net.cpp:435] Input 0 -> data
I1026 01:51:41.928180  2533 layer_factory.hpp:76] Creating layer conv1
I1026 01:51:41.928200  2533 net.cpp:110] Creating Layer conv1
I1026 01:51:41.928211  2533 net.cpp:477] conv1 <- data
I1026 01:51:41.928225  2533 net.cpp:433] conv1 -> conv1
I1026 01:51:41.928285  2533 net.cpp:155] Setting up conv1
I1026 01:51:41.928308  2533 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1026 01:51:41.928328  2533 layer_factory.hpp:76] Creating layer relu1
I1026 01:51:41.928344  2533 net.cpp:110] Creating Layer relu1
I1026 01:51:41.928355  2533 net.cpp:477] relu1 <- conv1
I1026 01:51:41.928366  2533 net.cpp:419] relu1 -> conv1 (in-place)
I1026 01:51:41.928380  2533 net.cpp:155] Setting up relu1
I1026 01:51:41.928392  2533 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1026 01:51:41.928402  2533 layer_factory.hpp:76] Creating layer pool1
I1026 01:51:41.928416  2533 net.cpp:110] Creating Layer pool1
I1026 01:51:41.928426  2533 net.cpp:477] pool1 <- conv1
I1026 01:51:41.928436  2533 net.cpp:433] pool1 -> pool1
I1026 01:51:41.928454  2533 net.cpp:155] Setting up pool1
I1026 01:51:41.928467  2533 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1026 01:51:41.928478  2533 layer_factory.hpp:76] Creating layer norm1
I1026 01:51:41.928489  2533 net.cpp:110] Creating Layer norm1
I1026 01:51:41.928499  2533 net.cpp:477] norm1 <- pool1
I1026 01:51:41.928511  2533 net.cpp:433] norm1 -> norm1
I1026 01:51:41.928526  2533 net.cpp:155] Setting up norm1
I1026 01:51:41.928539  2533 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1026 01:51:41.928549  2533 layer_factory.hpp:76] Creating layer conv2
I1026 01:51:41.928561  2533 net.cpp:110] Creating Layer conv2
I1026 01:51:41.928571  2533 net.cpp:477] conv2 <- norm1
I1026 01:51:41.928582  2533 net.cpp:433] conv2 -> conv2
I1026 01:51:41.929632  2533 net.cpp:155] Setting up conv2
I1026 01:51:41.929651  2533 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1026 01:51:41.929667  2533 layer_factory.hpp:76] Creating layer relu2
I1026 01:51:41.929680  2533 net.cpp:110] Creating Layer relu2
I1026 01:51:41.929690  2533 net.cpp:477] relu2 <- conv2
I1026 01:51:41.929702  2533 net.cpp:419] relu2 -> conv2 (in-place)
I1026 01:51:41.929715  2533 net.cpp:155] Setting up relu2
I1026 01:51:41.929726  2533 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1026 01:51:41.929736  2533 layer_factory.hpp:76] Creating layer pool2
I1026 01:51:41.929749  2533 net.cpp:110] Creating Layer pool2
I1026 01:51:41.929759  2533 net.cpp:477] pool2 <- conv2
I1026 01:51:41.929770  2533 net.cpp:433] pool2 -> pool2
I1026 01:51:41.929785  2533 net.cpp:155] Setting up pool2
I1026 01:51:41.929797  2533 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1026 01:51:41.929807  2533 layer_factory.hpp:76] Creating layer norm2
I1026 01:51:41.929819  2533 net.cpp:110] Creating Layer norm2
I1026 01:51:41.929841  2533 net.cpp:477] norm2 <- pool2
I1026 01:51:41.929854  2533 net.cpp:433] norm2 -> norm2
I1026 01:51:41.929868  2533 net.cpp:155] Setting up norm2
I1026 01:51:41.929880  2533 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1026 01:51:41.929890  2533 layer_factory.hpp:76] Creating layer conv3
I1026 01:51:41.929904  2533 net.cpp:110] Creating Layer conv3
I1026 01:51:41.929914  2533 net.cpp:477] conv3 <- norm2
I1026 01:51:41.929926  2533 net.cpp:433] conv3 -> conv3
I1026 01:51:41.934036  2533 net.cpp:155] Setting up conv3
I1026 01:51:41.934058  2533 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1026 01:51:41.934075  2533 layer_factory.hpp:76] Creating layer relu3
I1026 01:51:41.934088  2533 net.cpp:110] Creating Layer relu3
I1026 01:51:41.934098  2533 net.cpp:477] relu3 <- conv3
I1026 01:51:41.934109  2533 net.cpp:419] relu3 -> conv3 (in-place)
I1026 01:51:41.934123  2533 net.cpp:155] Setting up relu3
I1026 01:51:41.934134  2533 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1026 01:51:41.934144  2533 layer_factory.hpp:76] Creating layer conv4
I1026 01:51:41.934156  2533 net.cpp:110] Creating Layer conv4
I1026 01:51:41.934166  2533 net.cpp:477] conv4 <- conv3
I1026 01:51:41.934177  2533 net.cpp:433] conv4 -> conv4
I1026 01:51:41.937259  2533 net.cpp:155] Setting up conv4
I1026 01:51:41.937280  2533 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1026 01:51:41.937294  2533 layer_factory.hpp:76] Creating layer relu4
I1026 01:51:41.937307  2533 net.cpp:110] Creating Layer relu4
I1026 01:51:41.937317  2533 net.cpp:477] relu4 <- conv4
I1026 01:51:41.937330  2533 net.cpp:419] relu4 -> conv4 (in-place)
I1026 01:51:41.937341  2533 net.cpp:155] Setting up relu4
I1026 01:51:41.937353  2533 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1026 01:51:41.937363  2533 layer_factory.hpp:76] Creating layer conv5
I1026 01:51:41.937376  2533 net.cpp:110] Creating Layer conv5
I1026 01:51:41.937386  2533 net.cpp:477] conv5 <- conv4
I1026 01:51:41.937397  2533 net.cpp:433] conv5 -> conv5
I1026 01:51:41.939447  2533 net.cpp:155] Setting up conv5
I1026 01:51:41.939467  2533 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1026 01:51:41.939484  2533 layer_factory.hpp:76] Creating layer relu5
I1026 01:51:41.939497  2533 net.cpp:110] Creating Layer relu5
I1026 01:51:41.939507  2533 net.cpp:477] relu5 <- conv5
I1026 01:51:41.939518  2533 net.cpp:419] relu5 -> conv5 (in-place)
I1026 01:51:41.939532  2533 net.cpp:155] Setting up relu5
I1026 01:51:41.939543  2533 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1026 01:51:41.939553  2533 layer_factory.hpp:76] Creating layer pool5
I1026 01:51:41.939565  2533 net.cpp:110] Creating Layer pool5
I1026 01:51:41.939575  2533 net.cpp:477] pool5 <- conv5
I1026 01:51:41.939586  2533 net.cpp:433] pool5 -> pool5
I1026 01:51:41.939601  2533 net.cpp:155] Setting up pool5
I1026 01:51:41.939613  2533 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1026 01:51:41.939623  2533 layer_factory.hpp:76] Creating layer fc6
I1026 01:51:41.939635  2533 net.cpp:110] Creating Layer fc6
I1026 01:51:41.939646  2533 net.cpp:477] fc6 <- pool5
I1026 01:51:41.939657  2533 net.cpp:433] fc6 -> fc6
I1026 01:51:42.102095  2533 net.cpp:155] Setting up fc6
I1026 01:51:42.102172  2533 net.cpp:163] Top shape: 10 4096 (40960)
I1026 01:51:42.102195  2533 layer_factory.hpp:76] Creating layer relu6
I1026 01:51:42.102218  2533 net.cpp:110] Creating Layer relu6
I1026 01:51:42.102231  2533 net.cpp:477] relu6 <- fc6
I1026 01:51:42.102246  2533 net.cpp:419] relu6 -> fc6 (in-place)
I1026 01:51:42.102264  2533 net.cpp:155] Setting up relu6
I1026 01:51:42.102275  2533 net.cpp:163] Top shape: 10 4096 (40960)
I1026 01:51:42.102285  2533 layer_factory.hpp:76] Creating layer drop6
I1026 01:51:42.102300  2533 net.cpp:110] Creating Layer drop6
I1026 01:51:42.102310  2533 net.cpp:477] drop6 <- fc6
I1026 01:51:42.102322  2533 net.cpp:419] drop6 -> fc6 (in-place)
I1026 01:51:42.102337  2533 net.cpp:155] Setting up drop6
I1026 01:51:42.102349  2533 net.cpp:163] Top shape: 10 4096 (40960)
I1026 01:51:42.102360  2533 layer_factory.hpp:76] Creating layer fc7
I1026 01:51:42.102407  2533 net.cpp:110] Creating Layer fc7
I1026 01:51:42.102419  2533 net.cpp:477] fc7 <- fc6
I1026 01:51:42.102432  2533 net.cpp:433] fc7 -> fc7
I1026 01:51:42.173223  2533 net.cpp:155] Setting up fc7
I1026 01:51:42.173296  2533 net.cpp:163] Top shape: 10 4096 (40960)
I1026 01:51:42.173316  2533 layer_factory.hpp:76] Creating layer relu7
I1026 01:51:42.173337  2533 net.cpp:110] Creating Layer relu7
I1026 01:51:42.173349  2533 net.cpp:477] relu7 <- fc7
I1026 01:51:42.173363  2533 net.cpp:419] relu7 -> fc7 (in-place)
I1026 01:51:42.173382  2533 net.cpp:155] Setting up relu7
I1026 01:51:42.173393  2533 net.cpp:163] Top shape: 10 4096 (40960)
I1026 01:51:42.173403  2533 layer_factory.hpp:76] Creating layer drop7
I1026 01:51:42.173416  2533 net.cpp:110] Creating Layer drop7
I1026 01:51:42.173426  2533 net.cpp:477] drop7 <- fc7
I1026 01:51:42.173439  2533 net.cpp:419] drop7 -> fc7 (in-place)
I1026 01:51:42.173452  2533 net.cpp:155] Setting up drop7
I1026 01:51:42.173465  2533 net.cpp:163] Top shape: 10 4096 (40960)
I1026 01:51:42.173475  2533 layer_factory.hpp:76] Creating layer fc8
I1026 01:51:42.173488  2533 net.cpp:110] Creating Layer fc8
I1026 01:51:42.173498  2533 net.cpp:477] fc8 <- fc7
I1026 01:51:42.173511  2533 net.cpp:433] fc8 -> fc8
I1026 01:51:42.190668  2533 net.cpp:155] Setting up fc8
I1026 01:51:42.190709  2533 net.cpp:163] Top shape: 10 1000 (10000)
I1026 01:51:42.190726  2533 layer_factory.hpp:76] Creating layer prob
I1026 01:51:42.190743  2533 net.cpp:110] Creating Layer prob
I1026 01:51:42.190754  2533 net.cpp:477] prob <- fc8
I1026 01:51:42.190768  2533 net.cpp:433] prob -> prob
I1026 01:51:42.190788  2533 net.cpp:155] Setting up prob
I1026 01:51:42.190801  2533 net.cpp:163] Top shape: 10 1000 (10000)
I1026 01:51:42.190811  2533 net.cpp:240] prob does not need backward computation.
I1026 01:51:42.190821  2533 net.cpp:240] fc8 does not need backward computation.
I1026 01:51:42.190830  2533 net.cpp:240] drop7 does not need backward computation.
I1026 01:51:42.190840  2533 net.cpp:240] relu7 does not need backward computation.
I1026 01:51:42.190850  2533 net.cpp:240] fc7 does not need backward computation.
I1026 01:51:42.190860  2533 net.cpp:240] drop6 does not need backward computation.
I1026 01:51:42.190870  2533 net.cpp:240] relu6 does not need backward computation.
I1026 01:51:42.190879  2533 net.cpp:240] fc6 does not need backward computation.
I1026 01:51:42.190889  2533 net.cpp:240] pool5 does not need backward computation.
I1026 01:51:42.190899  2533 net.cpp:240] relu5 does not need backward computation.
I1026 01:51:42.190909  2533 net.cpp:240] conv5 does not need backward computation.
I1026 01:51:42.190919  2533 net.cpp:240] relu4 does not need backward computation.
I1026 01:51:42.190929  2533 net.cpp:240] conv4 does not need backward computation.
I1026 01:51:42.190939  2533 net.cpp:240] relu3 does not need backward computation.
I1026 01:51:42.190949  2533 net.cpp:240] conv3 does not need backward computation.
I1026 01:51:42.190959  2533 net.cpp:240] norm2 does not need backward computation.
I1026 01:51:42.190970  2533 net.cpp:240] pool2 does not need backward computation.
I1026 01:51:42.190979  2533 net.cpp:240] relu2 does not need backward computation.
I1026 01:51:42.190989  2533 net.cpp:240] conv2 does not need backward computation.
I1026 01:51:42.190999  2533 net.cpp:240] norm1 does not need backward computation.
I1026 01:51:42.191010  2533 net.cpp:240] pool1 does not need backward computation.
I1026 01:51:42.191020  2533 net.cpp:240] relu1 does not need backward computation.
I1026 01:51:42.191030  2533 net.cpp:240] conv1 does not need backward computation.
I1026 01:51:42.191040  2533 net.cpp:283] This network produces output prob
I1026 01:51:42.191061  2533 net.cpp:297] Network initialization done.
I1026 01:51:42.191069  2533 net.cpp:298] Memory required for data: 62497920
I1026 01:51:43.166880  2533 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1026 01:51:43.166975  2533 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1026 01:51:43.166986  2533 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1026 01:51:43.166996  2533 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1026 01:51:43.674612  2533 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
58.152.249.17:39482 - - [26/Oct/2015 01:51:44] "HTTP/1.1 POST /resources/1" - 200 OK
I1026 01:58:05.474735  2534 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1026 01:58:05.474829  2534 net.cpp:435] Input 0 -> data
I1026 01:58:05.474863  2534 layer_factory.hpp:76] Creating layer conv1
I1026 01:58:05.474881  2534 net.cpp:110] Creating Layer conv1
I1026 01:58:05.474894  2534 net.cpp:477] conv1 <- data
I1026 01:58:05.474906  2534 net.cpp:433] conv1 -> conv1
I1026 01:58:05.474968  2534 net.cpp:155] Setting up conv1
I1026 01:58:05.474990  2534 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1026 01:58:05.475024  2534 layer_factory.hpp:76] Creating layer relu1
I1026 01:58:05.475042  2534 net.cpp:110] Creating Layer relu1
I1026 01:58:05.475054  2534 net.cpp:477] relu1 <- conv1
I1026 01:58:05.475064  2534 net.cpp:419] relu1 -> conv1 (in-place)
I1026 01:58:05.475080  2534 net.cpp:155] Setting up relu1
I1026 01:58:05.475091  2534 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1026 01:58:05.475101  2534 layer_factory.hpp:76] Creating layer pool1
I1026 01:58:05.475114  2534 net.cpp:110] Creating Layer pool1
I1026 01:58:05.475124  2534 net.cpp:477] pool1 <- conv1
I1026 01:58:05.475136  2534 net.cpp:433] pool1 -> pool1
I1026 01:58:05.475154  2534 net.cpp:155] Setting up pool1
I1026 01:58:05.475167  2534 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1026 01:58:05.475178  2534 layer_factory.hpp:76] Creating layer norm1
I1026 01:58:05.475190  2534 net.cpp:110] Creating Layer norm1
I1026 01:58:05.475200  2534 net.cpp:477] norm1 <- pool1
I1026 01:58:05.475213  2534 net.cpp:433] norm1 -> norm1
I1026 01:58:05.475227  2534 net.cpp:155] Setting up norm1
I1026 01:58:05.475239  2534 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1026 01:58:05.475250  2534 layer_factory.hpp:76] Creating layer conv2
I1026 01:58:05.475262  2534 net.cpp:110] Creating Layer conv2
I1026 01:58:05.475272  2534 net.cpp:477] conv2 <- norm1
I1026 01:58:05.475285  2534 net.cpp:433] conv2 -> conv2
I1026 01:58:05.476363  2534 net.cpp:155] Setting up conv2
I1026 01:58:05.476382  2534 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1026 01:58:05.476399  2534 layer_factory.hpp:76] Creating layer relu2
I1026 01:58:05.476413  2534 net.cpp:110] Creating Layer relu2
I1026 01:58:05.476423  2534 net.cpp:477] relu2 <- conv2
I1026 01:58:05.476434  2534 net.cpp:419] relu2 -> conv2 (in-place)
I1026 01:58:05.476447  2534 net.cpp:155] Setting up relu2
I1026 01:58:05.476459  2534 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1026 01:58:05.476469  2534 layer_factory.hpp:76] Creating layer pool2
I1026 01:58:05.476480  2534 net.cpp:110] Creating Layer pool2
I1026 01:58:05.476490  2534 net.cpp:477] pool2 <- conv2
I1026 01:58:05.476502  2534 net.cpp:433] pool2 -> pool2
I1026 01:58:05.476517  2534 net.cpp:155] Setting up pool2
I1026 01:58:05.476529  2534 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1026 01:58:05.476539  2534 layer_factory.hpp:76] Creating layer norm2
I1026 01:58:05.476552  2534 net.cpp:110] Creating Layer norm2
I1026 01:58:05.476562  2534 net.cpp:477] norm2 <- pool2
I1026 01:58:05.476572  2534 net.cpp:433] norm2 -> norm2
I1026 01:58:05.476586  2534 net.cpp:155] Setting up norm2
I1026 01:58:05.476598  2534 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1026 01:58:05.476608  2534 layer_factory.hpp:76] Creating layer conv3
I1026 01:58:05.476621  2534 net.cpp:110] Creating Layer conv3
I1026 01:58:05.476631  2534 net.cpp:477] conv3 <- norm2
I1026 01:58:05.476644  2534 net.cpp:433] conv3 -> conv3
I1026 01:58:05.480432  2534 net.cpp:155] Setting up conv3
I1026 01:58:05.480453  2534 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1026 01:58:05.480470  2534 layer_factory.hpp:76] Creating layer relu3
I1026 01:58:05.480484  2534 net.cpp:110] Creating Layer relu3
I1026 01:58:05.480494  2534 net.cpp:477] relu3 <- conv3
I1026 01:58:05.480506  2534 net.cpp:419] relu3 -> conv3 (in-place)
I1026 01:58:05.480520  2534 net.cpp:155] Setting up relu3
I1026 01:58:05.480531  2534 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1026 01:58:05.480541  2534 layer_factory.hpp:76] Creating layer conv4
I1026 01:58:05.480553  2534 net.cpp:110] Creating Layer conv4
I1026 01:58:05.480563  2534 net.cpp:477] conv4 <- conv3
I1026 01:58:05.480576  2534 net.cpp:433] conv4 -> conv4
I1026 01:58:05.483417  2534 net.cpp:155] Setting up conv4
I1026 01:58:05.483438  2534 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1026 01:58:05.483453  2534 layer_factory.hpp:76] Creating layer relu4
I1026 01:58:05.483465  2534 net.cpp:110] Creating Layer relu4
I1026 01:58:05.483476  2534 net.cpp:477] relu4 <- conv4
I1026 01:58:05.483489  2534 net.cpp:419] relu4 -> conv4 (in-place)
I1026 01:58:05.483513  2534 net.cpp:155] Setting up relu4
I1026 01:58:05.483526  2534 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1026 01:58:05.483536  2534 layer_factory.hpp:76] Creating layer conv5
I1026 01:58:05.483551  2534 net.cpp:110] Creating Layer conv5
I1026 01:58:05.483559  2534 net.cpp:477] conv5 <- conv4
I1026 01:58:05.483572  2534 net.cpp:433] conv5 -> conv5
I1026 01:58:05.485499  2534 net.cpp:155] Setting up conv5
I1026 01:58:05.485518  2534 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1026 01:58:05.485535  2534 layer_factory.hpp:76] Creating layer relu5
I1026 01:58:05.485548  2534 net.cpp:110] Creating Layer relu5
I1026 01:58:05.485558  2534 net.cpp:477] relu5 <- conv5
I1026 01:58:05.485570  2534 net.cpp:419] relu5 -> conv5 (in-place)
I1026 01:58:05.485584  2534 net.cpp:155] Setting up relu5
I1026 01:58:05.485594  2534 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1026 01:58:05.485605  2534 layer_factory.hpp:76] Creating layer pool5
I1026 01:58:05.485616  2534 net.cpp:110] Creating Layer pool5
I1026 01:58:05.485626  2534 net.cpp:477] pool5 <- conv5
I1026 01:58:05.485638  2534 net.cpp:433] pool5 -> pool5
I1026 01:58:05.485653  2534 net.cpp:155] Setting up pool5
I1026 01:58:05.485666  2534 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1026 01:58:05.485676  2534 layer_factory.hpp:76] Creating layer fc6
I1026 01:58:05.485688  2534 net.cpp:110] Creating Layer fc6
I1026 01:58:05.485699  2534 net.cpp:477] fc6 <- pool5
I1026 01:58:05.485710  2534 net.cpp:433] fc6 -> fc6
I1026 01:58:05.645404  2534 net.cpp:155] Setting up fc6
I1026 01:58:05.645481  2534 net.cpp:163] Top shape: 10 4096 (40960)
I1026 01:58:05.645503  2534 layer_factory.hpp:76] Creating layer relu6
I1026 01:58:05.645527  2534 net.cpp:110] Creating Layer relu6
I1026 01:58:05.645539  2534 net.cpp:477] relu6 <- fc6
I1026 01:58:05.645555  2534 net.cpp:419] relu6 -> fc6 (in-place)
I1026 01:58:05.645573  2534 net.cpp:155] Setting up relu6
I1026 01:58:05.645584  2534 net.cpp:163] Top shape: 10 4096 (40960)
I1026 01:58:05.645594  2534 layer_factory.hpp:76] Creating layer drop6
I1026 01:58:05.645609  2534 net.cpp:110] Creating Layer drop6
I1026 01:58:05.645619  2534 net.cpp:477] drop6 <- fc6
I1026 01:58:05.645632  2534 net.cpp:419] drop6 -> fc6 (in-place)
I1026 01:58:05.645647  2534 net.cpp:155] Setting up drop6
I1026 01:58:05.645658  2534 net.cpp:163] Top shape: 10 4096 (40960)
I1026 01:58:05.645668  2534 layer_factory.hpp:76] Creating layer fc7
I1026 01:58:05.645681  2534 net.cpp:110] Creating Layer fc7
I1026 01:58:05.645692  2534 net.cpp:477] fc7 <- fc6
I1026 01:58:05.645705  2534 net.cpp:433] fc7 -> fc7
I1026 01:58:05.716394  2534 net.cpp:155] Setting up fc7
I1026 01:58:05.716470  2534 net.cpp:163] Top shape: 10 4096 (40960)
I1026 01:58:05.716491  2534 layer_factory.hpp:76] Creating layer relu7
I1026 01:58:05.716511  2534 net.cpp:110] Creating Layer relu7
I1026 01:58:05.716523  2534 net.cpp:477] relu7 <- fc7
I1026 01:58:05.716538  2534 net.cpp:419] relu7 -> fc7 (in-place)
I1026 01:58:05.716557  2534 net.cpp:155] Setting up relu7
I1026 01:58:05.716567  2534 net.cpp:163] Top shape: 10 4096 (40960)
I1026 01:58:05.716578  2534 layer_factory.hpp:76] Creating layer drop7
I1026 01:58:05.716593  2534 net.cpp:110] Creating Layer drop7
I1026 01:58:05.716603  2534 net.cpp:477] drop7 <- fc7
I1026 01:58:05.716615  2534 net.cpp:419] drop7 -> fc7 (in-place)
I1026 01:58:05.716629  2534 net.cpp:155] Setting up drop7
I1026 01:58:05.716641  2534 net.cpp:163] Top shape: 10 4096 (40960)
I1026 01:58:05.716652  2534 layer_factory.hpp:76] Creating layer fc8
I1026 01:58:05.716666  2534 net.cpp:110] Creating Layer fc8
I1026 01:58:05.716677  2534 net.cpp:477] fc8 <- fc7
I1026 01:58:05.716691  2534 net.cpp:433] fc8 -> fc8
I1026 01:58:05.733870  2534 net.cpp:155] Setting up fc8
I1026 01:58:05.733921  2534 net.cpp:163] Top shape: 10 1000 (10000)
I1026 01:58:05.733939  2534 layer_factory.hpp:76] Creating layer prob
I1026 01:58:05.733957  2534 net.cpp:110] Creating Layer prob
I1026 01:58:05.733968  2534 net.cpp:477] prob <- fc8
I1026 01:58:05.733983  2534 net.cpp:433] prob -> prob
I1026 01:58:05.734035  2534 net.cpp:155] Setting up prob
I1026 01:58:05.734050  2534 net.cpp:163] Top shape: 10 1000 (10000)
I1026 01:58:05.734061  2534 net.cpp:240] prob does not need backward computation.
I1026 01:58:05.734071  2534 net.cpp:240] fc8 does not need backward computation.
I1026 01:58:05.734081  2534 net.cpp:240] drop7 does not need backward computation.
I1026 01:58:05.734091  2534 net.cpp:240] relu7 does not need backward computation.
I1026 01:58:05.734099  2534 net.cpp:240] fc7 does not need backward computation.
I1026 01:58:05.734110  2534 net.cpp:240] drop6 does not need backward computation.
I1026 01:58:05.734120  2534 net.cpp:240] relu6 does not need backward computation.
I1026 01:58:05.734129  2534 net.cpp:240] fc6 does not need backward computation.
I1026 01:58:05.734140  2534 net.cpp:240] pool5 does not need backward computation.
I1026 01:58:05.734150  2534 net.cpp:240] relu5 does not need backward computation.
I1026 01:58:05.734160  2534 net.cpp:240] conv5 does not need backward computation.
I1026 01:58:05.734170  2534 net.cpp:240] relu4 does not need backward computation.
I1026 01:58:05.734179  2534 net.cpp:240] conv4 does not need backward computation.
I1026 01:58:05.734190  2534 net.cpp:240] relu3 does not need backward computation.
I1026 01:58:05.734200  2534 net.cpp:240] conv3 does not need backward computation.
I1026 01:58:05.734210  2534 net.cpp:240] norm2 does not need backward computation.
I1026 01:58:05.734220  2534 net.cpp:240] pool2 does not need backward computation.
I1026 01:58:05.734230  2534 net.cpp:240] relu2 does not need backward computation.
I1026 01:58:05.734241  2534 net.cpp:240] conv2 does not need backward computation.
I1026 01:58:05.734249  2534 net.cpp:240] norm1 does not need backward computation.
I1026 01:58:05.734261  2534 net.cpp:240] pool1 does not need backward computation.
I1026 01:58:05.734271  2534 net.cpp:240] relu1 does not need backward computation.
I1026 01:58:05.734279  2534 net.cpp:240] conv1 does not need backward computation.
I1026 01:58:05.734289  2534 net.cpp:283] This network produces output prob
I1026 01:58:05.734310  2534 net.cpp:297] Network initialization done.
I1026 01:58:05.734320  2534 net.cpp:298] Memory required for data: 62497920
I1026 01:58:06.710981  2534 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1026 01:58:06.711052  2534 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1026 01:58:06.711063  2534 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1026 01:58:06.711072  2534 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1026 01:58:07.218149  2534 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
58.152.249.17:46952 - - [26/Oct/2015 01:58:08] "HTTP/1.1 POST /resources/1" - 200 OK
52.91.237.137:47919 - - [26/Oct/2015 01:58:21] "HTTP/1.1 GET /resources/1" - 405 Method Not Allowed
I1026 02:34:10.987078  2536 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1026 02:34:10.987185  2536 net.cpp:435] Input 0 -> data
I1026 02:34:10.987216  2536 layer_factory.hpp:76] Creating layer conv1
I1026 02:34:10.987236  2536 net.cpp:110] Creating Layer conv1
I1026 02:34:10.987247  2536 net.cpp:477] conv1 <- data
I1026 02:34:10.987262  2536 net.cpp:433] conv1 -> conv1
I1026 02:34:10.987323  2536 net.cpp:155] Setting up conv1
I1026 02:34:10.987344  2536 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1026 02:34:10.987365  2536 layer_factory.hpp:76] Creating layer relu1
I1026 02:34:10.987380  2536 net.cpp:110] Creating Layer relu1
I1026 02:34:10.987391  2536 net.cpp:477] relu1 <- conv1
I1026 02:34:10.987403  2536 net.cpp:419] relu1 -> conv1 (in-place)
I1026 02:34:10.987417  2536 net.cpp:155] Setting up relu1
I1026 02:34:10.987428  2536 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1026 02:34:10.987438  2536 layer_factory.hpp:76] Creating layer pool1
I1026 02:34:10.987452  2536 net.cpp:110] Creating Layer pool1
I1026 02:34:10.987462  2536 net.cpp:477] pool1 <- conv1
I1026 02:34:10.987473  2536 net.cpp:433] pool1 -> pool1
I1026 02:34:10.987490  2536 net.cpp:155] Setting up pool1
I1026 02:34:10.987504  2536 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1026 02:34:10.987514  2536 layer_factory.hpp:76] Creating layer norm1
I1026 02:34:10.987525  2536 net.cpp:110] Creating Layer norm1
I1026 02:34:10.987535  2536 net.cpp:477] norm1 <- pool1
I1026 02:34:10.987546  2536 net.cpp:433] norm1 -> norm1
I1026 02:34:10.987561  2536 net.cpp:155] Setting up norm1
I1026 02:34:10.987573  2536 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1026 02:34:10.987583  2536 layer_factory.hpp:76] Creating layer conv2
I1026 02:34:10.987596  2536 net.cpp:110] Creating Layer conv2
I1026 02:34:10.987607  2536 net.cpp:477] conv2 <- norm1
I1026 02:34:10.987618  2536 net.cpp:433] conv2 -> conv2
I1026 02:34:10.988577  2536 net.cpp:155] Setting up conv2
I1026 02:34:10.988596  2536 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1026 02:34:10.988612  2536 layer_factory.hpp:76] Creating layer relu2
I1026 02:34:10.988646  2536 net.cpp:110] Creating Layer relu2
I1026 02:34:10.988657  2536 net.cpp:477] relu2 <- conv2
I1026 02:34:10.988669  2536 net.cpp:419] relu2 -> conv2 (in-place)
I1026 02:34:10.988682  2536 net.cpp:155] Setting up relu2
I1026 02:34:10.988694  2536 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1026 02:34:10.988703  2536 layer_factory.hpp:76] Creating layer pool2
I1026 02:34:10.988715  2536 net.cpp:110] Creating Layer pool2
I1026 02:34:10.988725  2536 net.cpp:477] pool2 <- conv2
I1026 02:34:10.988737  2536 net.cpp:433] pool2 -> pool2
I1026 02:34:10.988751  2536 net.cpp:155] Setting up pool2
I1026 02:34:10.988764  2536 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1026 02:34:10.988773  2536 layer_factory.hpp:76] Creating layer norm2
I1026 02:34:10.988785  2536 net.cpp:110] Creating Layer norm2
I1026 02:34:10.988795  2536 net.cpp:477] norm2 <- pool2
I1026 02:34:10.988806  2536 net.cpp:433] norm2 -> norm2
I1026 02:34:10.988821  2536 net.cpp:155] Setting up norm2
I1026 02:34:10.988832  2536 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1026 02:34:10.988842  2536 layer_factory.hpp:76] Creating layer conv3
I1026 02:34:10.988855  2536 net.cpp:110] Creating Layer conv3
I1026 02:34:10.988865  2536 net.cpp:477] conv3 <- norm2
I1026 02:34:10.988876  2536 net.cpp:433] conv3 -> conv3
I1026 02:34:10.992754  2536 net.cpp:155] Setting up conv3
I1026 02:34:10.992777  2536 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1026 02:34:10.992794  2536 layer_factory.hpp:76] Creating layer relu3
I1026 02:34:10.992807  2536 net.cpp:110] Creating Layer relu3
I1026 02:34:10.992818  2536 net.cpp:477] relu3 <- conv3
I1026 02:34:10.992830  2536 net.cpp:419] relu3 -> conv3 (in-place)
I1026 02:34:10.992843  2536 net.cpp:155] Setting up relu3
I1026 02:34:10.992854  2536 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1026 02:34:10.992864  2536 layer_factory.hpp:76] Creating layer conv4
I1026 02:34:10.992877  2536 net.cpp:110] Creating Layer conv4
I1026 02:34:10.992887  2536 net.cpp:477] conv4 <- conv3
I1026 02:34:10.992899  2536 net.cpp:433] conv4 -> conv4
I1026 02:34:10.995815  2536 net.cpp:155] Setting up conv4
I1026 02:34:10.995836  2536 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1026 02:34:10.995849  2536 layer_factory.hpp:76] Creating layer relu4
I1026 02:34:10.995862  2536 net.cpp:110] Creating Layer relu4
I1026 02:34:10.995872  2536 net.cpp:477] relu4 <- conv4
I1026 02:34:10.995884  2536 net.cpp:419] relu4 -> conv4 (in-place)
I1026 02:34:10.995896  2536 net.cpp:155] Setting up relu4
I1026 02:34:10.995908  2536 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1026 02:34:10.995918  2536 layer_factory.hpp:76] Creating layer conv5
I1026 02:34:10.995930  2536 net.cpp:110] Creating Layer conv5
I1026 02:34:10.995940  2536 net.cpp:477] conv5 <- conv4
I1026 02:34:10.995951  2536 net.cpp:433] conv5 -> conv5
I1026 02:34:10.997902  2536 net.cpp:155] Setting up conv5
I1026 02:34:10.997921  2536 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1026 02:34:10.997938  2536 layer_factory.hpp:76] Creating layer relu5
I1026 02:34:10.997951  2536 net.cpp:110] Creating Layer relu5
I1026 02:34:10.997961  2536 net.cpp:477] relu5 <- conv5
I1026 02:34:10.997972  2536 net.cpp:419] relu5 -> conv5 (in-place)
I1026 02:34:10.997985  2536 net.cpp:155] Setting up relu5
I1026 02:34:10.997997  2536 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1026 02:34:10.998006  2536 layer_factory.hpp:76] Creating layer pool5
I1026 02:34:10.998019  2536 net.cpp:110] Creating Layer pool5
I1026 02:34:10.998029  2536 net.cpp:477] pool5 <- conv5
I1026 02:34:10.998040  2536 net.cpp:433] pool5 -> pool5
I1026 02:34:10.998056  2536 net.cpp:155] Setting up pool5
I1026 02:34:10.998069  2536 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1026 02:34:10.998078  2536 layer_factory.hpp:76] Creating layer fc6
I1026 02:34:10.998090  2536 net.cpp:110] Creating Layer fc6
I1026 02:34:10.998100  2536 net.cpp:477] fc6 <- pool5
I1026 02:34:10.998112  2536 net.cpp:433] fc6 -> fc6
I1026 02:34:11.157917  2536 net.cpp:155] Setting up fc6
I1026 02:34:11.157995  2536 net.cpp:163] Top shape: 10 4096 (40960)
I1026 02:34:11.158051  2536 layer_factory.hpp:76] Creating layer relu6
I1026 02:34:11.158077  2536 net.cpp:110] Creating Layer relu6
I1026 02:34:11.158090  2536 net.cpp:477] relu6 <- fc6
I1026 02:34:11.158105  2536 net.cpp:419] relu6 -> fc6 (in-place)
I1026 02:34:11.158124  2536 net.cpp:155] Setting up relu6
I1026 02:34:11.158135  2536 net.cpp:163] Top shape: 10 4096 (40960)
I1026 02:34:11.158145  2536 layer_factory.hpp:76] Creating layer drop6
I1026 02:34:11.158159  2536 net.cpp:110] Creating Layer drop6
I1026 02:34:11.158169  2536 net.cpp:477] drop6 <- fc6
I1026 02:34:11.158181  2536 net.cpp:419] drop6 -> fc6 (in-place)
I1026 02:34:11.158196  2536 net.cpp:155] Setting up drop6
I1026 02:34:11.158208  2536 net.cpp:163] Top shape: 10 4096 (40960)
I1026 02:34:11.158218  2536 layer_factory.hpp:76] Creating layer fc7
I1026 02:34:11.158233  2536 net.cpp:110] Creating Layer fc7
I1026 02:34:11.158243  2536 net.cpp:477] fc7 <- fc6
I1026 02:34:11.158257  2536 net.cpp:433] fc7 -> fc7
I1026 02:34:11.228904  2536 net.cpp:155] Setting up fc7
I1026 02:34:11.228979  2536 net.cpp:163] Top shape: 10 4096 (40960)
I1026 02:34:11.229001  2536 layer_factory.hpp:76] Creating layer relu7
I1026 02:34:11.229022  2536 net.cpp:110] Creating Layer relu7
I1026 02:34:11.229033  2536 net.cpp:477] relu7 <- fc7
I1026 02:34:11.229048  2536 net.cpp:419] relu7 -> fc7 (in-place)
I1026 02:34:11.229066  2536 net.cpp:155] Setting up relu7
I1026 02:34:11.229077  2536 net.cpp:163] Top shape: 10 4096 (40960)
I1026 02:34:11.229087  2536 layer_factory.hpp:76] Creating layer drop7
I1026 02:34:11.229102  2536 net.cpp:110] Creating Layer drop7
I1026 02:34:11.229112  2536 net.cpp:477] drop7 <- fc7
I1026 02:34:11.229125  2536 net.cpp:419] drop7 -> fc7 (in-place)
I1026 02:34:11.229140  2536 net.cpp:155] Setting up drop7
I1026 02:34:11.229151  2536 net.cpp:163] Top shape: 10 4096 (40960)
I1026 02:34:11.229161  2536 layer_factory.hpp:76] Creating layer fc8
I1026 02:34:11.229176  2536 net.cpp:110] Creating Layer fc8
I1026 02:34:11.229187  2536 net.cpp:477] fc8 <- fc7
I1026 02:34:11.229200  2536 net.cpp:433] fc8 -> fc8
I1026 02:34:11.246387  2536 net.cpp:155] Setting up fc8
I1026 02:34:11.246431  2536 net.cpp:163] Top shape: 10 1000 (10000)
I1026 02:34:11.246448  2536 layer_factory.hpp:76] Creating layer prob
I1026 02:34:11.246464  2536 net.cpp:110] Creating Layer prob
I1026 02:34:11.246476  2536 net.cpp:477] prob <- fc8
I1026 02:34:11.246490  2536 net.cpp:433] prob -> prob
I1026 02:34:11.246511  2536 net.cpp:155] Setting up prob
I1026 02:34:11.246523  2536 net.cpp:163] Top shape: 10 1000 (10000)
I1026 02:34:11.246533  2536 net.cpp:240] prob does not need backward computation.
I1026 02:34:11.246543  2536 net.cpp:240] fc8 does not need backward computation.
I1026 02:34:11.246553  2536 net.cpp:240] drop7 does not need backward computation.
I1026 02:34:11.246563  2536 net.cpp:240] relu7 does not need backward computation.
I1026 02:34:11.246585  2536 net.cpp:240] fc7 does not need backward computation.
I1026 02:34:11.246598  2536 net.cpp:240] drop6 does not need backward computation.
I1026 02:34:11.246608  2536 net.cpp:240] relu6 does not need backward computation.
I1026 02:34:11.246618  2536 net.cpp:240] fc6 does not need backward computation.
I1026 02:34:11.246628  2536 net.cpp:240] pool5 does not need backward computation.
I1026 02:34:11.246639  2536 net.cpp:240] relu5 does not need backward computation.
I1026 02:34:11.246649  2536 net.cpp:240] conv5 does not need backward computation.
I1026 02:34:11.246659  2536 net.cpp:240] relu4 does not need backward computation.
I1026 02:34:11.246670  2536 net.cpp:240] conv4 does not need backward computation.
I1026 02:34:11.246680  2536 net.cpp:240] relu3 does not need backward computation.
I1026 02:34:11.246688  2536 net.cpp:240] conv3 does not need backward computation.
I1026 02:34:11.246700  2536 net.cpp:240] norm2 does not need backward computation.
I1026 02:34:11.246709  2536 net.cpp:240] pool2 does not need backward computation.
I1026 02:34:11.246719  2536 net.cpp:240] relu2 does not need backward computation.
I1026 02:34:11.246757  2536 net.cpp:240] conv2 does not need backward computation.
I1026 02:34:11.246768  2536 net.cpp:240] norm1 does not need backward computation.
I1026 02:34:11.246778  2536 net.cpp:240] pool1 does not need backward computation.
I1026 02:34:11.246788  2536 net.cpp:240] relu1 does not need backward computation.
I1026 02:34:11.246798  2536 net.cpp:240] conv1 does not need backward computation.
I1026 02:34:11.246809  2536 net.cpp:283] This network produces output prob
I1026 02:34:11.246829  2536 net.cpp:297] Network initialization done.
I1026 02:34:11.246839  2536 net.cpp:298] Memory required for data: 62497920
I1026 02:34:12.223383  2536 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1026 02:34:12.223454  2536 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1026 02:34:12.223465  2536 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1026 02:34:12.223474  2536 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1026 02:34:12.730932  2536 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
58.152.249.17:37652 - - [26/Oct/2015 02:34:13] "HTTP/1.1 POST /resources/1" - 200 OK
I1026 23:12:16.611428  2538 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1026 23:12:16.611582  2538 net.cpp:435] Input 0 -> data
I1026 23:12:16.611616  2538 layer_factory.hpp:76] Creating layer conv1
I1026 23:12:16.611636  2538 net.cpp:110] Creating Layer conv1
I1026 23:12:16.611647  2538 net.cpp:477] conv1 <- data
I1026 23:12:16.611661  2538 net.cpp:433] conv1 -> conv1
I1026 23:12:16.611894  2538 net.cpp:155] Setting up conv1
I1026 23:12:16.611915  2538 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1026 23:12:16.611937  2538 layer_factory.hpp:76] Creating layer relu1
I1026 23:12:16.611953  2538 net.cpp:110] Creating Layer relu1
I1026 23:12:16.611963  2538 net.cpp:477] relu1 <- conv1
I1026 23:12:16.611985  2538 net.cpp:419] relu1 -> conv1 (in-place)
I1026 23:12:16.612001  2538 net.cpp:155] Setting up relu1
I1026 23:12:16.612012  2538 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1026 23:12:16.612023  2538 layer_factory.hpp:76] Creating layer pool1
I1026 23:12:16.612036  2538 net.cpp:110] Creating Layer pool1
I1026 23:12:16.612046  2538 net.cpp:477] pool1 <- conv1
I1026 23:12:16.612064  2538 net.cpp:433] pool1 -> pool1
I1026 23:12:16.612083  2538 net.cpp:155] Setting up pool1
I1026 23:12:16.612095  2538 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1026 23:12:16.612107  2538 layer_factory.hpp:76] Creating layer norm1
I1026 23:12:16.612118  2538 net.cpp:110] Creating Layer norm1
I1026 23:12:16.612128  2538 net.cpp:477] norm1 <- pool1
I1026 23:12:16.612149  2538 net.cpp:433] norm1 -> norm1
I1026 23:12:16.612166  2538 net.cpp:155] Setting up norm1
I1026 23:12:16.612179  2538 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1026 23:12:16.612188  2538 layer_factory.hpp:76] Creating layer conv2
I1026 23:12:16.612207  2538 net.cpp:110] Creating Layer conv2
I1026 23:12:16.612218  2538 net.cpp:477] conv2 <- norm1
I1026 23:12:16.612231  2538 net.cpp:433] conv2 -> conv2
I1026 23:12:16.613627  2538 net.cpp:155] Setting up conv2
I1026 23:12:16.613646  2538 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1026 23:12:16.613662  2538 layer_factory.hpp:76] Creating layer relu2
I1026 23:12:16.613674  2538 net.cpp:110] Creating Layer relu2
I1026 23:12:16.613684  2538 net.cpp:477] relu2 <- conv2
I1026 23:12:16.613704  2538 net.cpp:419] relu2 -> conv2 (in-place)
I1026 23:12:16.613718  2538 net.cpp:155] Setting up relu2
I1026 23:12:16.613730  2538 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1026 23:12:16.613740  2538 layer_factory.hpp:76] Creating layer pool2
I1026 23:12:16.613752  2538 net.cpp:110] Creating Layer pool2
I1026 23:12:16.613761  2538 net.cpp:477] pool2 <- conv2
I1026 23:12:16.613772  2538 net.cpp:433] pool2 -> pool2
I1026 23:12:16.613795  2538 net.cpp:155] Setting up pool2
I1026 23:12:16.613806  2538 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1026 23:12:16.613816  2538 layer_factory.hpp:76] Creating layer norm2
I1026 23:12:16.613828  2538 net.cpp:110] Creating Layer norm2
I1026 23:12:16.613838  2538 net.cpp:477] norm2 <- pool2
I1026 23:12:16.613857  2538 net.cpp:433] norm2 -> norm2
I1026 23:12:16.613873  2538 net.cpp:155] Setting up norm2
I1026 23:12:16.613884  2538 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1026 23:12:16.613894  2538 layer_factory.hpp:76] Creating layer conv3
I1026 23:12:16.613914  2538 net.cpp:110] Creating Layer conv3
I1026 23:12:16.613924  2538 net.cpp:477] conv3 <- norm2
I1026 23:12:16.613936  2538 net.cpp:433] conv3 -> conv3
I1026 23:12:16.617786  2538 net.cpp:155] Setting up conv3
I1026 23:12:16.617806  2538 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1026 23:12:16.617823  2538 layer_factory.hpp:76] Creating layer relu3
I1026 23:12:16.617843  2538 net.cpp:110] Creating Layer relu3
I1026 23:12:16.617854  2538 net.cpp:477] relu3 <- conv3
I1026 23:12:16.617866  2538 net.cpp:419] relu3 -> conv3 (in-place)
I1026 23:12:16.617897  2538 net.cpp:155] Setting up relu3
I1026 23:12:16.617910  2538 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1026 23:12:16.617920  2538 layer_factory.hpp:76] Creating layer conv4
I1026 23:12:16.617933  2538 net.cpp:110] Creating Layer conv4
I1026 23:12:16.617943  2538 net.cpp:477] conv4 <- conv3
I1026 23:12:16.617964  2538 net.cpp:433] conv4 -> conv4
I1026 23:12:16.620772  2538 net.cpp:155] Setting up conv4
I1026 23:12:16.620796  2538 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1026 23:12:16.620810  2538 layer_factory.hpp:76] Creating layer relu4
I1026 23:12:16.620823  2538 net.cpp:110] Creating Layer relu4
I1026 23:12:16.620833  2538 net.cpp:477] relu4 <- conv4
I1026 23:12:16.620844  2538 net.cpp:419] relu4 -> conv4 (in-place)
I1026 23:12:16.620857  2538 net.cpp:155] Setting up relu4
I1026 23:12:16.620868  2538 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1026 23:12:16.620877  2538 layer_factory.hpp:76] Creating layer conv5
I1026 23:12:16.620899  2538 net.cpp:110] Creating Layer conv5
I1026 23:12:16.620910  2538 net.cpp:477] conv5 <- conv4
I1026 23:12:16.620923  2538 net.cpp:433] conv5 -> conv5
I1026 23:12:16.622805  2538 net.cpp:155] Setting up conv5
I1026 23:12:16.622825  2538 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1026 23:12:16.622841  2538 layer_factory.hpp:76] Creating layer relu5
I1026 23:12:16.622854  2538 net.cpp:110] Creating Layer relu5
I1026 23:12:16.622864  2538 net.cpp:477] relu5 <- conv5
I1026 23:12:16.622875  2538 net.cpp:419] relu5 -> conv5 (in-place)
I1026 23:12:16.622889  2538 net.cpp:155] Setting up relu5
I1026 23:12:16.622900  2538 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1026 23:12:16.622910  2538 layer_factory.hpp:76] Creating layer pool5
I1026 23:12:16.622931  2538 net.cpp:110] Creating Layer pool5
I1026 23:12:16.622941  2538 net.cpp:477] pool5 <- conv5
I1026 23:12:16.622953  2538 net.cpp:433] pool5 -> pool5
I1026 23:12:16.622973  2538 net.cpp:155] Setting up pool5
I1026 23:12:16.622987  2538 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1026 23:12:16.622997  2538 layer_factory.hpp:76] Creating layer fc6
I1026 23:12:16.623009  2538 net.cpp:110] Creating Layer fc6
I1026 23:12:16.623019  2538 net.cpp:477] fc6 <- pool5
I1026 23:12:16.623030  2538 net.cpp:433] fc6 -> fc6
I1026 23:12:16.782348  2538 net.cpp:155] Setting up fc6
I1026 23:12:16.782420  2538 net.cpp:163] Top shape: 10 4096 (40960)
I1026 23:12:16.782441  2538 layer_factory.hpp:76] Creating layer relu6
I1026 23:12:16.782472  2538 net.cpp:110] Creating Layer relu6
I1026 23:12:16.782485  2538 net.cpp:477] relu6 <- fc6
I1026 23:12:16.782500  2538 net.cpp:419] relu6 -> fc6 (in-place)
I1026 23:12:16.782516  2538 net.cpp:155] Setting up relu6
I1026 23:12:16.782528  2538 net.cpp:163] Top shape: 10 4096 (40960)
I1026 23:12:16.782538  2538 layer_factory.hpp:76] Creating layer drop6
I1026 23:12:16.782552  2538 net.cpp:110] Creating Layer drop6
I1026 23:12:16.782562  2538 net.cpp:477] drop6 <- fc6
I1026 23:12:16.782608  2538 net.cpp:419] drop6 -> fc6 (in-place)
I1026 23:12:16.782629  2538 net.cpp:155] Setting up drop6
I1026 23:12:16.782641  2538 net.cpp:163] Top shape: 10 4096 (40960)
I1026 23:12:16.782651  2538 layer_factory.hpp:76] Creating layer fc7
I1026 23:12:16.782665  2538 net.cpp:110] Creating Layer fc7
I1026 23:12:16.782675  2538 net.cpp:477] fc7 <- fc6
I1026 23:12:16.782687  2538 net.cpp:433] fc7 -> fc7
I1026 23:12:16.853305  2538 net.cpp:155] Setting up fc7
I1026 23:12:16.853377  2538 net.cpp:163] Top shape: 10 4096 (40960)
I1026 23:12:16.853397  2538 layer_factory.hpp:76] Creating layer relu7
I1026 23:12:16.853417  2538 net.cpp:110] Creating Layer relu7
I1026 23:12:16.853428  2538 net.cpp:477] relu7 <- fc7
I1026 23:12:16.853451  2538 net.cpp:419] relu7 -> fc7 (in-place)
I1026 23:12:16.853471  2538 net.cpp:155] Setting up relu7
I1026 23:12:16.853482  2538 net.cpp:163] Top shape: 10 4096 (40960)
I1026 23:12:16.853492  2538 layer_factory.hpp:76] Creating layer drop7
I1026 23:12:16.853507  2538 net.cpp:110] Creating Layer drop7
I1026 23:12:16.853516  2538 net.cpp:477] drop7 <- fc7
I1026 23:12:16.853561  2538 net.cpp:419] drop7 -> fc7 (in-place)
I1026 23:12:16.853579  2538 net.cpp:155] Setting up drop7
I1026 23:12:16.853591  2538 net.cpp:163] Top shape: 10 4096 (40960)
I1026 23:12:16.853601  2538 layer_factory.hpp:76] Creating layer fc8
I1026 23:12:16.853615  2538 net.cpp:110] Creating Layer fc8
I1026 23:12:16.853626  2538 net.cpp:477] fc8 <- fc7
I1026 23:12:16.853637  2538 net.cpp:433] fc8 -> fc8
I1026 23:12:16.870801  2538 net.cpp:155] Setting up fc8
I1026 23:12:16.870834  2538 net.cpp:163] Top shape: 10 1000 (10000)
I1026 23:12:16.870851  2538 layer_factory.hpp:76] Creating layer prob
I1026 23:12:16.870873  2538 net.cpp:110] Creating Layer prob
I1026 23:12:16.870884  2538 net.cpp:477] prob <- fc8
I1026 23:12:16.870898  2538 net.cpp:433] prob -> prob
I1026 23:12:16.870929  2538 net.cpp:155] Setting up prob
I1026 23:12:16.870941  2538 net.cpp:163] Top shape: 10 1000 (10000)
I1026 23:12:16.870952  2538 net.cpp:240] prob does not need backward computation.
I1026 23:12:16.870962  2538 net.cpp:240] fc8 does not need backward computation.
I1026 23:12:16.870971  2538 net.cpp:240] drop7 does not need backward computation.
I1026 23:12:16.870981  2538 net.cpp:240] relu7 does not need backward computation.
I1026 23:12:16.870990  2538 net.cpp:240] fc7 does not need backward computation.
I1026 23:12:16.871001  2538 net.cpp:240] drop6 does not need backward computation.
I1026 23:12:16.871011  2538 net.cpp:240] relu6 does not need backward computation.
I1026 23:12:16.871019  2538 net.cpp:240] fc6 does not need backward computation.
I1026 23:12:16.871029  2538 net.cpp:240] pool5 does not need backward computation.
I1026 23:12:16.871040  2538 net.cpp:240] relu5 does not need backward computation.
I1026 23:12:16.871049  2538 net.cpp:240] conv5 does not need backward computation.
I1026 23:12:16.871059  2538 net.cpp:240] relu4 does not need backward computation.
I1026 23:12:16.871069  2538 net.cpp:240] conv4 does not need backward computation.
I1026 23:12:16.871079  2538 net.cpp:240] relu3 does not need backward computation.
I1026 23:12:16.871089  2538 net.cpp:240] conv3 does not need backward computation.
I1026 23:12:16.871099  2538 net.cpp:240] norm2 does not need backward computation.
I1026 23:12:16.871109  2538 net.cpp:240] pool2 does not need backward computation.
I1026 23:12:16.871119  2538 net.cpp:240] relu2 does not need backward computation.
I1026 23:12:16.871129  2538 net.cpp:240] conv2 does not need backward computation.
I1026 23:12:16.871139  2538 net.cpp:240] norm1 does not need backward computation.
I1026 23:12:16.871148  2538 net.cpp:240] pool1 does not need backward computation.
I1026 23:12:16.871158  2538 net.cpp:240] relu1 does not need backward computation.
I1026 23:12:16.871168  2538 net.cpp:240] conv1 does not need backward computation.
I1026 23:12:16.871177  2538 net.cpp:283] This network produces output prob
I1026 23:12:16.871209  2538 net.cpp:297] Network initialization done.
I1026 23:12:16.871219  2538 net.cpp:298] Memory required for data: 62497920
I1026 23:12:17.850677  2538 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1026 23:12:17.850746  2538 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1026 23:12:17.850757  2538 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1026 23:12:17.850767  2538 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1026 23:12:18.358000  2538 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1027 00:37:08.826972  6320 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1027 00:37:08.827139  6320 net.cpp:435] Input 0 -> data
I1027 00:37:08.827210  6320 layer_factory.hpp:76] Creating layer conv1
I1027 00:37:08.827240  6320 net.cpp:110] Creating Layer conv1
I1027 00:37:08.827252  6320 net.cpp:477] conv1 <- data
I1027 00:37:08.827271  6320 net.cpp:433] conv1 -> conv1
I1027 00:37:08.827390  6320 net.cpp:155] Setting up conv1
I1027 00:37:08.827419  6320 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1027 00:37:08.827451  6320 layer_factory.hpp:76] Creating layer relu1
I1027 00:37:08.827467  6320 net.cpp:110] Creating Layer relu1
I1027 00:37:08.827478  6320 net.cpp:477] relu1 <- conv1
I1027 00:37:08.827489  6320 net.cpp:419] relu1 -> conv1 (in-place)
I1027 00:37:08.827510  6320 net.cpp:155] Setting up relu1
I1027 00:37:08.827523  6320 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1027 00:37:08.827533  6320 layer_factory.hpp:76] Creating layer pool1
I1027 00:37:08.827546  6320 net.cpp:110] Creating Layer pool1
I1027 00:37:08.827556  6320 net.cpp:477] pool1 <- conv1
I1027 00:37:08.827567  6320 net.cpp:433] pool1 -> pool1
I1027 00:37:08.827594  6320 net.cpp:155] Setting up pool1
I1027 00:37:08.827606  6320 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1027 00:37:08.827616  6320 layer_factory.hpp:76] Creating layer norm1
I1027 00:37:08.827628  6320 net.cpp:110] Creating Layer norm1
I1027 00:37:08.827649  6320 net.cpp:477] norm1 <- pool1
I1027 00:37:08.827662  6320 net.cpp:433] norm1 -> norm1
I1027 00:37:08.827690  6320 net.cpp:155] Setting up norm1
I1027 00:37:08.827703  6320 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1027 00:37:08.827713  6320 layer_factory.hpp:76] Creating layer conv2
I1027 00:37:08.827728  6320 net.cpp:110] Creating Layer conv2
I1027 00:37:08.827738  6320 net.cpp:477] conv2 <- norm1
I1027 00:37:08.827749  6320 net.cpp:433] conv2 -> conv2
I1027 00:37:08.828763  6320 net.cpp:155] Setting up conv2
I1027 00:37:08.828780  6320 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1027 00:37:08.828796  6320 layer_factory.hpp:76] Creating layer relu2
I1027 00:37:08.828809  6320 net.cpp:110] Creating Layer relu2
I1027 00:37:08.828819  6320 net.cpp:477] relu2 <- conv2
I1027 00:37:08.828830  6320 net.cpp:419] relu2 -> conv2 (in-place)
I1027 00:37:08.828842  6320 net.cpp:155] Setting up relu2
I1027 00:37:08.828855  6320 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1027 00:37:08.828863  6320 layer_factory.hpp:76] Creating layer pool2
I1027 00:37:08.828876  6320 net.cpp:110] Creating Layer pool2
I1027 00:37:08.828884  6320 net.cpp:477] pool2 <- conv2
I1027 00:37:08.828896  6320 net.cpp:433] pool2 -> pool2
I1027 00:37:08.828912  6320 net.cpp:155] Setting up pool2
I1027 00:37:08.828922  6320 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1027 00:37:08.828933  6320 layer_factory.hpp:76] Creating layer norm2
I1027 00:37:08.828944  6320 net.cpp:110] Creating Layer norm2
I1027 00:37:08.828953  6320 net.cpp:477] norm2 <- pool2
I1027 00:37:08.828965  6320 net.cpp:433] norm2 -> norm2
I1027 00:37:08.828979  6320 net.cpp:155] Setting up norm2
I1027 00:37:08.828990  6320 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1027 00:37:08.829000  6320 layer_factory.hpp:76] Creating layer conv3
I1027 00:37:08.829013  6320 net.cpp:110] Creating Layer conv3
I1027 00:37:08.829023  6320 net.cpp:477] conv3 <- norm2
I1027 00:37:08.829035  6320 net.cpp:433] conv3 -> conv3
I1027 00:37:08.832749  6320 net.cpp:155] Setting up conv3
I1027 00:37:08.832770  6320 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1027 00:37:08.832787  6320 layer_factory.hpp:76] Creating layer relu3
I1027 00:37:08.832799  6320 net.cpp:110] Creating Layer relu3
I1027 00:37:08.832809  6320 net.cpp:477] relu3 <- conv3
I1027 00:37:08.832821  6320 net.cpp:419] relu3 -> conv3 (in-place)
I1027 00:37:08.832834  6320 net.cpp:155] Setting up relu3
I1027 00:37:08.832845  6320 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1027 00:37:08.832854  6320 layer_factory.hpp:76] Creating layer conv4
I1027 00:37:08.832866  6320 net.cpp:110] Creating Layer conv4
I1027 00:37:08.832876  6320 net.cpp:477] conv4 <- conv3
I1027 00:37:08.832887  6320 net.cpp:433] conv4 -> conv4
I1027 00:37:08.835688  6320 net.cpp:155] Setting up conv4
I1027 00:37:08.835710  6320 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1027 00:37:08.835723  6320 layer_factory.hpp:76] Creating layer relu4
I1027 00:37:08.835736  6320 net.cpp:110] Creating Layer relu4
I1027 00:37:08.835747  6320 net.cpp:477] relu4 <- conv4
I1027 00:37:08.835757  6320 net.cpp:419] relu4 -> conv4 (in-place)
I1027 00:37:08.835770  6320 net.cpp:155] Setting up relu4
I1027 00:37:08.835782  6320 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1027 00:37:08.835791  6320 layer_factory.hpp:76] Creating layer conv5
I1027 00:37:08.835803  6320 net.cpp:110] Creating Layer conv5
I1027 00:37:08.835813  6320 net.cpp:477] conv5 <- conv4
I1027 00:37:08.835825  6320 net.cpp:433] conv5 -> conv5
I1027 00:37:08.837687  6320 net.cpp:155] Setting up conv5
I1027 00:37:08.837705  6320 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1027 00:37:08.837721  6320 layer_factory.hpp:76] Creating layer relu5
I1027 00:37:08.837734  6320 net.cpp:110] Creating Layer relu5
I1027 00:37:08.837744  6320 net.cpp:477] relu5 <- conv5
I1027 00:37:08.837755  6320 net.cpp:419] relu5 -> conv5 (in-place)
I1027 00:37:08.837769  6320 net.cpp:155] Setting up relu5
I1027 00:37:08.837779  6320 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1027 00:37:08.837790  6320 layer_factory.hpp:76] Creating layer pool5
I1027 00:37:08.837812  6320 net.cpp:110] Creating Layer pool5
I1027 00:37:08.837823  6320 net.cpp:477] pool5 <- conv5
I1027 00:37:08.837836  6320 net.cpp:433] pool5 -> pool5
I1027 00:37:08.837851  6320 net.cpp:155] Setting up pool5
I1027 00:37:08.837862  6320 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1027 00:37:08.837872  6320 layer_factory.hpp:76] Creating layer fc6
I1027 00:37:08.837894  6320 net.cpp:110] Creating Layer fc6
I1027 00:37:08.837905  6320 net.cpp:477] fc6 <- pool5
I1027 00:37:08.837918  6320 net.cpp:433] fc6 -> fc6
I1027 00:37:08.997373  6320 net.cpp:155] Setting up fc6
I1027 00:37:08.997447  6320 net.cpp:163] Top shape: 10 4096 (40960)
I1027 00:37:08.997467  6320 layer_factory.hpp:76] Creating layer relu6
I1027 00:37:08.997491  6320 net.cpp:110] Creating Layer relu6
I1027 00:37:08.997503  6320 net.cpp:477] relu6 <- fc6
I1027 00:37:08.997517  6320 net.cpp:419] relu6 -> fc6 (in-place)
I1027 00:37:08.997535  6320 net.cpp:155] Setting up relu6
I1027 00:37:08.997547  6320 net.cpp:163] Top shape: 10 4096 (40960)
I1027 00:37:08.997556  6320 layer_factory.hpp:76] Creating layer drop6
I1027 00:37:08.997594  6320 net.cpp:110] Creating Layer drop6
I1027 00:37:08.997606  6320 net.cpp:477] drop6 <- fc6
I1027 00:37:08.997617  6320 net.cpp:419] drop6 -> fc6 (in-place)
I1027 00:37:08.997635  6320 net.cpp:155] Setting up drop6
I1027 00:37:08.997648  6320 net.cpp:163] Top shape: 10 4096 (40960)
I1027 00:37:08.997658  6320 layer_factory.hpp:76] Creating layer fc7
I1027 00:37:08.997673  6320 net.cpp:110] Creating Layer fc7
I1027 00:37:08.997683  6320 net.cpp:477] fc7 <- fc6
I1027 00:37:08.997695  6320 net.cpp:433] fc7 -> fc7
I1027 00:37:09.068567  6320 net.cpp:155] Setting up fc7
I1027 00:37:09.068639  6320 net.cpp:163] Top shape: 10 4096 (40960)
I1027 00:37:09.068660  6320 layer_factory.hpp:76] Creating layer relu7
I1027 00:37:09.068680  6320 net.cpp:110] Creating Layer relu7
I1027 00:37:09.068691  6320 net.cpp:477] relu7 <- fc7
I1027 00:37:09.068706  6320 net.cpp:419] relu7 -> fc7 (in-place)
I1027 00:37:09.068724  6320 net.cpp:155] Setting up relu7
I1027 00:37:09.068737  6320 net.cpp:163] Top shape: 10 4096 (40960)
I1027 00:37:09.068745  6320 layer_factory.hpp:76] Creating layer drop7
I1027 00:37:09.068760  6320 net.cpp:110] Creating Layer drop7
I1027 00:37:09.068769  6320 net.cpp:477] drop7 <- fc7
I1027 00:37:09.068781  6320 net.cpp:419] drop7 -> fc7 (in-place)
I1027 00:37:09.068796  6320 net.cpp:155] Setting up drop7
I1027 00:37:09.068809  6320 net.cpp:163] Top shape: 10 4096 (40960)
I1027 00:37:09.068819  6320 layer_factory.hpp:76] Creating layer fc8
I1027 00:37:09.068832  6320 net.cpp:110] Creating Layer fc8
I1027 00:37:09.068842  6320 net.cpp:477] fc8 <- fc7
I1027 00:37:09.068855  6320 net.cpp:433] fc8 -> fc8
I1027 00:37:09.086133  6320 net.cpp:155] Setting up fc8
I1027 00:37:09.086174  6320 net.cpp:163] Top shape: 10 1000 (10000)
I1027 00:37:09.086192  6320 layer_factory.hpp:76] Creating layer prob
I1027 00:37:09.086210  6320 net.cpp:110] Creating Layer prob
I1027 00:37:09.086220  6320 net.cpp:477] prob <- fc8
I1027 00:37:09.086235  6320 net.cpp:433] prob -> prob
I1027 00:37:09.086272  6320 net.cpp:155] Setting up prob
I1027 00:37:09.086284  6320 net.cpp:163] Top shape: 10 1000 (10000)
I1027 00:37:09.086294  6320 net.cpp:240] prob does not need backward computation.
I1027 00:37:09.086304  6320 net.cpp:240] fc8 does not need backward computation.
I1027 00:37:09.086314  6320 net.cpp:240] drop7 does not need backward computation.
I1027 00:37:09.086324  6320 net.cpp:240] relu7 does not need backward computation.
I1027 00:37:09.086334  6320 net.cpp:240] fc7 does not need backward computation.
I1027 00:37:09.086344  6320 net.cpp:240] drop6 does not need backward computation.
I1027 00:37:09.086354  6320 net.cpp:240] relu6 does not need backward computation.
I1027 00:37:09.086364  6320 net.cpp:240] fc6 does not need backward computation.
I1027 00:37:09.086374  6320 net.cpp:240] pool5 does not need backward computation.
I1027 00:37:09.086383  6320 net.cpp:240] relu5 does not need backward computation.
I1027 00:37:09.086423  6320 net.cpp:240] conv5 does not need backward computation.
I1027 00:37:09.086434  6320 net.cpp:240] relu4 does not need backward computation.
I1027 00:37:09.086444  6320 net.cpp:240] conv4 does not need backward computation.
I1027 00:37:09.086454  6320 net.cpp:240] relu3 does not need backward computation.
I1027 00:37:09.086464  6320 net.cpp:240] conv3 does not need backward computation.
I1027 00:37:09.086474  6320 net.cpp:240] norm2 does not need backward computation.
I1027 00:37:09.086484  6320 net.cpp:240] pool2 does not need backward computation.
I1027 00:37:09.086494  6320 net.cpp:240] relu2 does not need backward computation.
I1027 00:37:09.086503  6320 net.cpp:240] conv2 does not need backward computation.
I1027 00:37:09.086513  6320 net.cpp:240] norm1 does not need backward computation.
I1027 00:37:09.086524  6320 net.cpp:240] pool1 does not need backward computation.
I1027 00:37:09.086534  6320 net.cpp:240] relu1 does not need backward computation.
I1027 00:37:09.086544  6320 net.cpp:240] conv1 does not need backward computation.
I1027 00:37:09.086554  6320 net.cpp:283] This network produces output prob
I1027 00:37:09.086596  6320 net.cpp:297] Network initialization done.
I1027 00:37:09.086607  6320 net.cpp:298] Memory required for data: 62497920
I1027 00:37:10.068542  6320 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1027 00:37:10.068630  6320 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1027 00:37:10.068650  6320 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1027 00:37:10.068660  6320 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1027 00:37:10.575492  6320 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
58.152.249.17:48353 - - [27/Oct/2015 00:37:11] "HTTP/1.1 POST /resources/1" - 200 OK
I1027 02:05:54.827055  6321 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1027 02:05:54.827167  6321 net.cpp:435] Input 0 -> data
I1027 02:05:54.827201  6321 layer_factory.hpp:76] Creating layer conv1
I1027 02:05:54.827220  6321 net.cpp:110] Creating Layer conv1
I1027 02:05:54.827231  6321 net.cpp:477] conv1 <- data
I1027 02:05:54.827244  6321 net.cpp:433] conv1 -> conv1
I1027 02:05:54.827304  6321 net.cpp:155] Setting up conv1
I1027 02:05:54.827325  6321 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1027 02:05:54.827347  6321 layer_factory.hpp:76] Creating layer relu1
I1027 02:05:54.827363  6321 net.cpp:110] Creating Layer relu1
I1027 02:05:54.827373  6321 net.cpp:477] relu1 <- conv1
I1027 02:05:54.827384  6321 net.cpp:419] relu1 -> conv1 (in-place)
I1027 02:05:54.827397  6321 net.cpp:155] Setting up relu1
I1027 02:05:54.827409  6321 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1027 02:05:54.827419  6321 layer_factory.hpp:76] Creating layer pool1
I1027 02:05:54.827432  6321 net.cpp:110] Creating Layer pool1
I1027 02:05:54.827441  6321 net.cpp:477] pool1 <- conv1
I1027 02:05:54.827453  6321 net.cpp:433] pool1 -> pool1
I1027 02:05:54.827471  6321 net.cpp:155] Setting up pool1
I1027 02:05:54.827483  6321 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1027 02:05:54.827493  6321 layer_factory.hpp:76] Creating layer norm1
I1027 02:05:54.827505  6321 net.cpp:110] Creating Layer norm1
I1027 02:05:54.827515  6321 net.cpp:477] norm1 <- pool1
I1027 02:05:54.827527  6321 net.cpp:433] norm1 -> norm1
I1027 02:05:54.827541  6321 net.cpp:155] Setting up norm1
I1027 02:05:54.827553  6321 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1027 02:05:54.827563  6321 layer_factory.hpp:76] Creating layer conv2
I1027 02:05:54.827575  6321 net.cpp:110] Creating Layer conv2
I1027 02:05:54.827585  6321 net.cpp:477] conv2 <- norm1
I1027 02:05:54.827596  6321 net.cpp:433] conv2 -> conv2
I1027 02:05:54.828683  6321 net.cpp:155] Setting up conv2
I1027 02:05:54.828701  6321 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1027 02:05:54.828717  6321 layer_factory.hpp:76] Creating layer relu2
I1027 02:05:54.828730  6321 net.cpp:110] Creating Layer relu2
I1027 02:05:54.828740  6321 net.cpp:477] relu2 <- conv2
I1027 02:05:54.828752  6321 net.cpp:419] relu2 -> conv2 (in-place)
I1027 02:05:54.828764  6321 net.cpp:155] Setting up relu2
I1027 02:05:54.828775  6321 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1027 02:05:54.828785  6321 layer_factory.hpp:76] Creating layer pool2
I1027 02:05:54.828796  6321 net.cpp:110] Creating Layer pool2
I1027 02:05:54.828806  6321 net.cpp:477] pool2 <- conv2
I1027 02:05:54.828817  6321 net.cpp:433] pool2 -> pool2
I1027 02:05:54.828831  6321 net.cpp:155] Setting up pool2
I1027 02:05:54.828843  6321 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1027 02:05:54.828853  6321 layer_factory.hpp:76] Creating layer norm2
I1027 02:05:54.828865  6321 net.cpp:110] Creating Layer norm2
I1027 02:05:54.828874  6321 net.cpp:477] norm2 <- pool2
I1027 02:05:54.828886  6321 net.cpp:433] norm2 -> norm2
I1027 02:05:54.828898  6321 net.cpp:155] Setting up norm2
I1027 02:05:54.828922  6321 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1027 02:05:54.828933  6321 layer_factory.hpp:76] Creating layer conv3
I1027 02:05:54.828946  6321 net.cpp:110] Creating Layer conv3
I1027 02:05:54.828956  6321 net.cpp:477] conv3 <- norm2
I1027 02:05:54.828969  6321 net.cpp:433] conv3 -> conv3
I1027 02:05:54.832911  6321 net.cpp:155] Setting up conv3
I1027 02:05:54.832931  6321 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1027 02:05:54.832947  6321 layer_factory.hpp:76] Creating layer relu3
I1027 02:05:54.832960  6321 net.cpp:110] Creating Layer relu3
I1027 02:05:54.832970  6321 net.cpp:477] relu3 <- conv3
I1027 02:05:54.832981  6321 net.cpp:419] relu3 -> conv3 (in-place)
I1027 02:05:54.832994  6321 net.cpp:155] Setting up relu3
I1027 02:05:54.833005  6321 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1027 02:05:54.833015  6321 layer_factory.hpp:76] Creating layer conv4
I1027 02:05:54.833029  6321 net.cpp:110] Creating Layer conv4
I1027 02:05:54.833037  6321 net.cpp:477] conv4 <- conv3
I1027 02:05:54.833050  6321 net.cpp:433] conv4 -> conv4
I1027 02:05:54.835841  6321 net.cpp:155] Setting up conv4
I1027 02:05:54.835862  6321 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1027 02:05:54.835876  6321 layer_factory.hpp:76] Creating layer relu4
I1027 02:05:54.835889  6321 net.cpp:110] Creating Layer relu4
I1027 02:05:54.835899  6321 net.cpp:477] relu4 <- conv4
I1027 02:05:54.835911  6321 net.cpp:419] relu4 -> conv4 (in-place)
I1027 02:05:54.835923  6321 net.cpp:155] Setting up relu4
I1027 02:05:54.835934  6321 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1027 02:05:54.835944  6321 layer_factory.hpp:76] Creating layer conv5
I1027 02:05:54.835955  6321 net.cpp:110] Creating Layer conv5
I1027 02:05:54.835965  6321 net.cpp:477] conv5 <- conv4
I1027 02:05:54.835978  6321 net.cpp:433] conv5 -> conv5
I1027 02:05:54.837844  6321 net.cpp:155] Setting up conv5
I1027 02:05:54.837863  6321 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1027 02:05:54.837880  6321 layer_factory.hpp:76] Creating layer relu5
I1027 02:05:54.837893  6321 net.cpp:110] Creating Layer relu5
I1027 02:05:54.837903  6321 net.cpp:477] relu5 <- conv5
I1027 02:05:54.837914  6321 net.cpp:419] relu5 -> conv5 (in-place)
I1027 02:05:54.837926  6321 net.cpp:155] Setting up relu5
I1027 02:05:54.837937  6321 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1027 02:05:54.837947  6321 layer_factory.hpp:76] Creating layer pool5
I1027 02:05:54.837960  6321 net.cpp:110] Creating Layer pool5
I1027 02:05:54.837970  6321 net.cpp:477] pool5 <- conv5
I1027 02:05:54.837980  6321 net.cpp:433] pool5 -> pool5
I1027 02:05:54.837995  6321 net.cpp:155] Setting up pool5
I1027 02:05:54.838006  6321 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1027 02:05:54.838016  6321 layer_factory.hpp:76] Creating layer fc6
I1027 02:05:54.838029  6321 net.cpp:110] Creating Layer fc6
I1027 02:05:54.838038  6321 net.cpp:477] fc6 <- pool5
I1027 02:05:54.838050  6321 net.cpp:433] fc6 -> fc6
I1027 02:05:54.997117  6321 net.cpp:155] Setting up fc6
I1027 02:05:54.997191  6321 net.cpp:163] Top shape: 10 4096 (40960)
I1027 02:05:54.997211  6321 layer_factory.hpp:76] Creating layer relu6
I1027 02:05:54.997236  6321 net.cpp:110] Creating Layer relu6
I1027 02:05:54.997248  6321 net.cpp:477] relu6 <- fc6
I1027 02:05:54.997262  6321 net.cpp:419] relu6 -> fc6 (in-place)
I1027 02:05:54.997280  6321 net.cpp:155] Setting up relu6
I1027 02:05:54.997292  6321 net.cpp:163] Top shape: 10 4096 (40960)
I1027 02:05:54.997301  6321 layer_factory.hpp:76] Creating layer drop6
I1027 02:05:54.997315  6321 net.cpp:110] Creating Layer drop6
I1027 02:05:54.997325  6321 net.cpp:477] drop6 <- fc6
I1027 02:05:54.997336  6321 net.cpp:419] drop6 -> fc6 (in-place)
I1027 02:05:54.997351  6321 net.cpp:155] Setting up drop6
I1027 02:05:54.997362  6321 net.cpp:163] Top shape: 10 4096 (40960)
I1027 02:05:54.997372  6321 layer_factory.hpp:76] Creating layer fc7
I1027 02:05:54.997386  6321 net.cpp:110] Creating Layer fc7
I1027 02:05:54.997396  6321 net.cpp:477] fc7 <- fc6
I1027 02:05:54.997409  6321 net.cpp:433] fc7 -> fc7
I1027 02:05:55.068066  6321 net.cpp:155] Setting up fc7
I1027 02:05:55.068141  6321 net.cpp:163] Top shape: 10 4096 (40960)
I1027 02:05:55.068162  6321 layer_factory.hpp:76] Creating layer relu7
I1027 02:05:55.068183  6321 net.cpp:110] Creating Layer relu7
I1027 02:05:55.068195  6321 net.cpp:477] relu7 <- fc7
I1027 02:05:55.068210  6321 net.cpp:419] relu7 -> fc7 (in-place)
I1027 02:05:55.068228  6321 net.cpp:155] Setting up relu7
I1027 02:05:55.068239  6321 net.cpp:163] Top shape: 10 4096 (40960)
I1027 02:05:55.068249  6321 layer_factory.hpp:76] Creating layer drop7
I1027 02:05:55.068264  6321 net.cpp:110] Creating Layer drop7
I1027 02:05:55.068274  6321 net.cpp:477] drop7 <- fc7
I1027 02:05:55.068285  6321 net.cpp:419] drop7 -> fc7 (in-place)
I1027 02:05:55.068300  6321 net.cpp:155] Setting up drop7
I1027 02:05:55.068311  6321 net.cpp:163] Top shape: 10 4096 (40960)
I1027 02:05:55.068321  6321 layer_factory.hpp:76] Creating layer fc8
I1027 02:05:55.068336  6321 net.cpp:110] Creating Layer fc8
I1027 02:05:55.068346  6321 net.cpp:477] fc8 <- fc7
I1027 02:05:55.068359  6321 net.cpp:433] fc8 -> fc8
I1027 02:05:55.085471  6321 net.cpp:155] Setting up fc8
I1027 02:05:55.085508  6321 net.cpp:163] Top shape: 10 1000 (10000)
I1027 02:05:55.085523  6321 layer_factory.hpp:76] Creating layer prob
I1027 02:05:55.085541  6321 net.cpp:110] Creating Layer prob
I1027 02:05:55.085551  6321 net.cpp:477] prob <- fc8
I1027 02:05:55.085564  6321 net.cpp:433] prob -> prob
I1027 02:05:55.085583  6321 net.cpp:155] Setting up prob
I1027 02:05:55.085595  6321 net.cpp:163] Top shape: 10 1000 (10000)
I1027 02:05:55.085605  6321 net.cpp:240] prob does not need backward computation.
I1027 02:05:55.085618  6321 net.cpp:240] fc8 does not need backward computation.
I1027 02:05:55.085628  6321 net.cpp:240] drop7 does not need backward computation.
I1027 02:05:55.085636  6321 net.cpp:240] relu7 does not need backward computation.
I1027 02:05:55.085646  6321 net.cpp:240] fc7 does not need backward computation.
I1027 02:05:55.085656  6321 net.cpp:240] drop6 does not need backward computation.
I1027 02:05:55.085665  6321 net.cpp:240] relu6 does not need backward computation.
I1027 02:05:55.085675  6321 net.cpp:240] fc6 does not need backward computation.
I1027 02:05:55.085685  6321 net.cpp:240] pool5 does not need backward computation.
I1027 02:05:55.085695  6321 net.cpp:240] relu5 does not need backward computation.
I1027 02:05:55.085705  6321 net.cpp:240] conv5 does not need backward computation.
I1027 02:05:55.085716  6321 net.cpp:240] relu4 does not need backward computation.
I1027 02:05:55.085726  6321 net.cpp:240] conv4 does not need backward computation.
I1027 02:05:55.085736  6321 net.cpp:240] relu3 does not need backward computation.
I1027 02:05:55.085746  6321 net.cpp:240] conv3 does not need backward computation.
I1027 02:05:55.085755  6321 net.cpp:240] norm2 does not need backward computation.
I1027 02:05:55.085765  6321 net.cpp:240] pool2 does not need backward computation.
I1027 02:05:55.085775  6321 net.cpp:240] relu2 does not need backward computation.
I1027 02:05:55.085785  6321 net.cpp:240] conv2 does not need backward computation.
I1027 02:05:55.085795  6321 net.cpp:240] norm1 does not need backward computation.
I1027 02:05:55.085805  6321 net.cpp:240] pool1 does not need backward computation.
I1027 02:05:55.085815  6321 net.cpp:240] relu1 does not need backward computation.
I1027 02:05:55.085824  6321 net.cpp:240] conv1 does not need backward computation.
I1027 02:05:55.085834  6321 net.cpp:283] This network produces output prob
I1027 02:05:55.085855  6321 net.cpp:297] Network initialization done.
I1027 02:05:55.085865  6321 net.cpp:298] Memory required for data: 62497920
I1027 02:05:56.059703  6321 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1027 02:05:56.059773  6321 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1027 02:05:56.059808  6321 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1027 02:05:56.059818  6321 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1027 02:05:56.563881  6321 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
58.152.249.17:36867 - - [27/Oct/2015 02:05:57] "HTTP/1.1 POST /resources/1" - 200 OK
I1102 22:03:15.809288  6322 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1102 22:03:15.809391  6322 net.cpp:435] Input 0 -> data
I1102 22:03:15.809422  6322 layer_factory.hpp:76] Creating layer conv1
I1102 22:03:15.809442  6322 net.cpp:110] Creating Layer conv1
I1102 22:03:15.809453  6322 net.cpp:477] conv1 <- data
I1102 22:03:15.809465  6322 net.cpp:433] conv1 -> conv1
I1102 22:03:15.809528  6322 net.cpp:155] Setting up conv1
I1102 22:03:15.809550  6322 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1102 22:03:15.809571  6322 layer_factory.hpp:76] Creating layer relu1
I1102 22:03:15.809587  6322 net.cpp:110] Creating Layer relu1
I1102 22:03:15.809597  6322 net.cpp:477] relu1 <- conv1
I1102 22:03:15.809626  6322 net.cpp:419] relu1 -> conv1 (in-place)
I1102 22:03:15.809641  6322 net.cpp:155] Setting up relu1
I1102 22:03:15.809653  6322 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1102 22:03:15.809664  6322 layer_factory.hpp:76] Creating layer pool1
I1102 22:03:15.809677  6322 net.cpp:110] Creating Layer pool1
I1102 22:03:15.809686  6322 net.cpp:477] pool1 <- conv1
I1102 22:03:15.809698  6322 net.cpp:433] pool1 -> pool1
I1102 22:03:15.809716  6322 net.cpp:155] Setting up pool1
I1102 22:03:15.809728  6322 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1102 22:03:15.809738  6322 layer_factory.hpp:76] Creating layer norm1
I1102 22:03:15.809751  6322 net.cpp:110] Creating Layer norm1
I1102 22:03:15.809761  6322 net.cpp:477] norm1 <- pool1
I1102 22:03:15.809772  6322 net.cpp:433] norm1 -> norm1
I1102 22:03:15.809787  6322 net.cpp:155] Setting up norm1
I1102 22:03:15.809798  6322 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1102 22:03:15.809808  6322 layer_factory.hpp:76] Creating layer conv2
I1102 22:03:15.809821  6322 net.cpp:110] Creating Layer conv2
I1102 22:03:15.809831  6322 net.cpp:477] conv2 <- norm1
I1102 22:03:15.809844  6322 net.cpp:433] conv2 -> conv2
I1102 22:03:15.811326  6322 net.cpp:155] Setting up conv2
I1102 22:03:15.811348  6322 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1102 22:03:15.811365  6322 layer_factory.hpp:76] Creating layer relu2
I1102 22:03:15.811378  6322 net.cpp:110] Creating Layer relu2
I1102 22:03:15.811388  6322 net.cpp:477] relu2 <- conv2
I1102 22:03:15.811400  6322 net.cpp:419] relu2 -> conv2 (in-place)
I1102 22:03:15.811414  6322 net.cpp:155] Setting up relu2
I1102 22:03:15.811424  6322 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1102 22:03:15.811434  6322 layer_factory.hpp:76] Creating layer pool2
I1102 22:03:15.811446  6322 net.cpp:110] Creating Layer pool2
I1102 22:03:15.811455  6322 net.cpp:477] pool2 <- conv2
I1102 22:03:15.811467  6322 net.cpp:433] pool2 -> pool2
I1102 22:03:15.811481  6322 net.cpp:155] Setting up pool2
I1102 22:03:15.811493  6322 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1102 22:03:15.811503  6322 layer_factory.hpp:76] Creating layer norm2
I1102 22:03:15.811517  6322 net.cpp:110] Creating Layer norm2
I1102 22:03:15.811525  6322 net.cpp:477] norm2 <- pool2
I1102 22:03:15.811537  6322 net.cpp:433] norm2 -> norm2
I1102 22:03:15.811550  6322 net.cpp:155] Setting up norm2
I1102 22:03:15.811563  6322 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1102 22:03:15.811571  6322 layer_factory.hpp:76] Creating layer conv3
I1102 22:03:15.811585  6322 net.cpp:110] Creating Layer conv3
I1102 22:03:15.811594  6322 net.cpp:477] conv3 <- norm2
I1102 22:03:15.811606  6322 net.cpp:433] conv3 -> conv3
I1102 22:03:15.815556  6322 net.cpp:155] Setting up conv3
I1102 22:03:15.815577  6322 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1102 22:03:15.815593  6322 layer_factory.hpp:76] Creating layer relu3
I1102 22:03:15.815606  6322 net.cpp:110] Creating Layer relu3
I1102 22:03:15.815616  6322 net.cpp:477] relu3 <- conv3
I1102 22:03:15.815629  6322 net.cpp:419] relu3 -> conv3 (in-place)
I1102 22:03:15.815640  6322 net.cpp:155] Setting up relu3
I1102 22:03:15.815652  6322 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1102 22:03:15.815661  6322 layer_factory.hpp:76] Creating layer conv4
I1102 22:03:15.815675  6322 net.cpp:110] Creating Layer conv4
I1102 22:03:15.815685  6322 net.cpp:477] conv4 <- conv3
I1102 22:03:15.815696  6322 net.cpp:433] conv4 -> conv4
I1102 22:03:15.818522  6322 net.cpp:155] Setting up conv4
I1102 22:03:15.818542  6322 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1102 22:03:15.818555  6322 layer_factory.hpp:76] Creating layer relu4
I1102 22:03:15.818568  6322 net.cpp:110] Creating Layer relu4
I1102 22:03:15.818589  6322 net.cpp:477] relu4 <- conv4
I1102 22:03:15.818603  6322 net.cpp:419] relu4 -> conv4 (in-place)
I1102 22:03:15.818616  6322 net.cpp:155] Setting up relu4
I1102 22:03:15.818629  6322 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1102 22:03:15.818639  6322 layer_factory.hpp:76] Creating layer conv5
I1102 22:03:15.818663  6322 net.cpp:110] Creating Layer conv5
I1102 22:03:15.818675  6322 net.cpp:477] conv5 <- conv4
I1102 22:03:15.818687  6322 net.cpp:433] conv5 -> conv5
I1102 22:03:15.820528  6322 net.cpp:155] Setting up conv5
I1102 22:03:15.820545  6322 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1102 22:03:15.820562  6322 layer_factory.hpp:76] Creating layer relu5
I1102 22:03:15.820576  6322 net.cpp:110] Creating Layer relu5
I1102 22:03:15.820586  6322 net.cpp:477] relu5 <- conv5
I1102 22:03:15.820597  6322 net.cpp:419] relu5 -> conv5 (in-place)
I1102 22:03:15.820611  6322 net.cpp:155] Setting up relu5
I1102 22:03:15.820626  6322 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1102 22:03:15.820636  6322 layer_factory.hpp:76] Creating layer pool5
I1102 22:03:15.820647  6322 net.cpp:110] Creating Layer pool5
I1102 22:03:15.820657  6322 net.cpp:477] pool5 <- conv5
I1102 22:03:15.820669  6322 net.cpp:433] pool5 -> pool5
I1102 22:03:15.820684  6322 net.cpp:155] Setting up pool5
I1102 22:03:15.820695  6322 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1102 22:03:15.820705  6322 layer_factory.hpp:76] Creating layer fc6
I1102 22:03:15.820719  6322 net.cpp:110] Creating Layer fc6
I1102 22:03:15.820729  6322 net.cpp:477] fc6 <- pool5
I1102 22:03:15.820739  6322 net.cpp:433] fc6 -> fc6
I1102 22:03:15.979630  6322 net.cpp:155] Setting up fc6
I1102 22:03:15.979701  6322 net.cpp:163] Top shape: 10 4096 (40960)
I1102 22:03:15.979722  6322 layer_factory.hpp:76] Creating layer relu6
I1102 22:03:15.979745  6322 net.cpp:110] Creating Layer relu6
I1102 22:03:15.979758  6322 net.cpp:477] relu6 <- fc6
I1102 22:03:15.979773  6322 net.cpp:419] relu6 -> fc6 (in-place)
I1102 22:03:15.979791  6322 net.cpp:155] Setting up relu6
I1102 22:03:15.979802  6322 net.cpp:163] Top shape: 10 4096 (40960)
I1102 22:03:15.979812  6322 layer_factory.hpp:76] Creating layer drop6
I1102 22:03:15.979826  6322 net.cpp:110] Creating Layer drop6
I1102 22:03:15.979836  6322 net.cpp:477] drop6 <- fc6
I1102 22:03:15.979848  6322 net.cpp:419] drop6 -> fc6 (in-place)
I1102 22:03:15.979863  6322 net.cpp:155] Setting up drop6
I1102 22:03:15.979874  6322 net.cpp:163] Top shape: 10 4096 (40960)
I1102 22:03:15.979884  6322 layer_factory.hpp:76] Creating layer fc7
I1102 22:03:15.979898  6322 net.cpp:110] Creating Layer fc7
I1102 22:03:15.979909  6322 net.cpp:477] fc7 <- fc6
I1102 22:03:15.979921  6322 net.cpp:433] fc7 -> fc7
I1102 22:03:16.050508  6322 net.cpp:155] Setting up fc7
I1102 22:03:16.050609  6322 net.cpp:163] Top shape: 10 4096 (40960)
I1102 22:03:16.050632  6322 layer_factory.hpp:76] Creating layer relu7
I1102 22:03:16.050653  6322 net.cpp:110] Creating Layer relu7
I1102 22:03:16.050665  6322 net.cpp:477] relu7 <- fc7
I1102 22:03:16.050679  6322 net.cpp:419] relu7 -> fc7 (in-place)
I1102 22:03:16.050698  6322 net.cpp:155] Setting up relu7
I1102 22:03:16.050709  6322 net.cpp:163] Top shape: 10 4096 (40960)
I1102 22:03:16.050719  6322 layer_factory.hpp:76] Creating layer drop7
I1102 22:03:16.050732  6322 net.cpp:110] Creating Layer drop7
I1102 22:03:16.050742  6322 net.cpp:477] drop7 <- fc7
I1102 22:03:16.050753  6322 net.cpp:419] drop7 -> fc7 (in-place)
I1102 22:03:16.050768  6322 net.cpp:155] Setting up drop7
I1102 22:03:16.050779  6322 net.cpp:163] Top shape: 10 4096 (40960)
I1102 22:03:16.050789  6322 layer_factory.hpp:76] Creating layer fc8
I1102 22:03:16.050803  6322 net.cpp:110] Creating Layer fc8
I1102 22:03:16.050813  6322 net.cpp:477] fc8 <- fc7
I1102 22:03:16.050827  6322 net.cpp:433] fc8 -> fc8
I1102 22:03:16.068002  6322 net.cpp:155] Setting up fc8
I1102 22:03:16.068050  6322 net.cpp:163] Top shape: 10 1000 (10000)
I1102 22:03:16.068068  6322 layer_factory.hpp:76] Creating layer prob
I1102 22:03:16.068086  6322 net.cpp:110] Creating Layer prob
I1102 22:03:16.068097  6322 net.cpp:477] prob <- fc8
I1102 22:03:16.068111  6322 net.cpp:433] prob -> prob
I1102 22:03:16.068132  6322 net.cpp:155] Setting up prob
I1102 22:03:16.068145  6322 net.cpp:163] Top shape: 10 1000 (10000)
I1102 22:03:16.068156  6322 net.cpp:240] prob does not need backward computation.
I1102 22:03:16.068195  6322 net.cpp:240] fc8 does not need backward computation.
I1102 22:03:16.068207  6322 net.cpp:240] drop7 does not need backward computation.
I1102 22:03:16.068217  6322 net.cpp:240] relu7 does not need backward computation.
I1102 22:03:16.068225  6322 net.cpp:240] fc7 does not need backward computation.
I1102 22:03:16.068235  6322 net.cpp:240] drop6 does not need backward computation.
I1102 22:03:16.068244  6322 net.cpp:240] relu6 does not need backward computation.
I1102 22:03:16.068253  6322 net.cpp:240] fc6 does not need backward computation.
I1102 22:03:16.068264  6322 net.cpp:240] pool5 does not need backward computation.
I1102 22:03:16.068274  6322 net.cpp:240] relu5 does not need backward computation.
I1102 22:03:16.068284  6322 net.cpp:240] conv5 does not need backward computation.
I1102 22:03:16.068294  6322 net.cpp:240] relu4 does not need backward computation.
I1102 22:03:16.068302  6322 net.cpp:240] conv4 does not need backward computation.
I1102 22:03:16.068312  6322 net.cpp:240] relu3 does not need backward computation.
I1102 22:03:16.068322  6322 net.cpp:240] conv3 does not need backward computation.
I1102 22:03:16.068332  6322 net.cpp:240] norm2 does not need backward computation.
I1102 22:03:16.068342  6322 net.cpp:240] pool2 does not need backward computation.
I1102 22:03:16.068352  6322 net.cpp:240] relu2 does not need backward computation.
I1102 22:03:16.068361  6322 net.cpp:240] conv2 does not need backward computation.
I1102 22:03:16.068372  6322 net.cpp:240] norm1 does not need backward computation.
I1102 22:03:16.068382  6322 net.cpp:240] pool1 does not need backward computation.
I1102 22:03:16.068392  6322 net.cpp:240] relu1 does not need backward computation.
I1102 22:03:16.068400  6322 net.cpp:240] conv1 does not need backward computation.
I1102 22:03:16.068409  6322 net.cpp:283] This network produces output prob
I1102 22:03:16.068429  6322 net.cpp:297] Network initialization done.
I1102 22:03:16.068439  6322 net.cpp:298] Memory required for data: 62497920
I1102 22:03:17.034904  6322 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1102 22:03:17.034973  6322 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1102 22:03:17.034984  6322 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1102 22:03:17.034993  6322 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1102 22:03:17.539767  6322 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
Traceback (most recent call last):
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 239, in process
    return self.handle()
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 230, in handle
    return self._delegate(fn, self.fvars, args)
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 420, in _delegate
    return handle_class(cls)
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 396, in handle_class
    return tocall(*args)
  File "/root/ds210_capstone/caffe_script/service/controller.py", line 16, in POST
    return self.baseline()
  File "/root/ds210_capstone/caffe_script/service/app.py", line 19, in baseline
    respond = b.baseline_run(request)
  File "/root/ds210_capstone/caffe_script/service/baseline.py", line 29, in baseline_run
    self.caffe_predict()
  File "/root/ds210_capstone/caffe_script/service/baseline.py", line 124, in caffe_predict
    caffe.io.load_image(img_path))
  File "/root/caffe/python/caffe/io.py", line 295, in load_image
    img = skimage.img_as_float(skimage.io.imread(filename)).astype(np.float32)
  File "/root/anaconda/lib/python2.7/site-packages/skimage/io/_io.py", line 100, in imread
    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)
  File "/root/anaconda/lib/python2.7/site-packages/skimage/io/manage_plugins.py", line 207, in call_plugin
    return func(*args, **kwargs)
  File "/root/anaconda/lib/python2.7/site-packages/skimage/io/_plugins/pil_plugin.py", line 46, in imread
    im = Image.open(fname)
  File "/root/anaconda/lib/python2.7/site-packages/PIL/Image.py", line 2248, in open
    fp = builtins.open(fp, "rb")
IOError: [Errno 2] No such file or directory: u'../../../dataset/temp/12071132_117024925320109_1448778029_n.jpg'

50.152.203.175:61151 - - [02/Nov/2015 22:03:17] "HTTP/1.1 POST /resources/1" - 500 Internal Server Error
I1102 22:03:25.836611  6323 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1102 22:03:25.836709  6323 net.cpp:435] Input 0 -> data
I1102 22:03:25.836740  6323 layer_factory.hpp:76] Creating layer conv1
I1102 22:03:25.836758  6323 net.cpp:110] Creating Layer conv1
I1102 22:03:25.836769  6323 net.cpp:477] conv1 <- data
I1102 22:03:25.836782  6323 net.cpp:433] conv1 -> conv1
I1102 22:03:25.836843  6323 net.cpp:155] Setting up conv1
I1102 22:03:25.836864  6323 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1102 22:03:25.836885  6323 layer_factory.hpp:76] Creating layer relu1
I1102 22:03:25.836917  6323 net.cpp:110] Creating Layer relu1
I1102 22:03:25.836928  6323 net.cpp:477] relu1 <- conv1
I1102 22:03:25.836941  6323 net.cpp:419] relu1 -> conv1 (in-place)
I1102 22:03:25.836954  6323 net.cpp:155] Setting up relu1
I1102 22:03:25.836966  6323 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1102 22:03:25.836976  6323 layer_factory.hpp:76] Creating layer pool1
I1102 22:03:25.836988  6323 net.cpp:110] Creating Layer pool1
I1102 22:03:25.836998  6323 net.cpp:477] pool1 <- conv1
I1102 22:03:25.837009  6323 net.cpp:433] pool1 -> pool1
I1102 22:03:25.837028  6323 net.cpp:155] Setting up pool1
I1102 22:03:25.837039  6323 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1102 22:03:25.837049  6323 layer_factory.hpp:76] Creating layer norm1
I1102 22:03:25.837062  6323 net.cpp:110] Creating Layer norm1
I1102 22:03:25.837071  6323 net.cpp:477] norm1 <- pool1
I1102 22:03:25.837082  6323 net.cpp:433] norm1 -> norm1
I1102 22:03:25.837097  6323 net.cpp:155] Setting up norm1
I1102 22:03:25.837110  6323 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1102 22:03:25.837118  6323 layer_factory.hpp:76] Creating layer conv2
I1102 22:03:25.837131  6323 net.cpp:110] Creating Layer conv2
I1102 22:03:25.837141  6323 net.cpp:477] conv2 <- norm1
I1102 22:03:25.837152  6323 net.cpp:433] conv2 -> conv2
I1102 22:03:25.838393  6323 net.cpp:155] Setting up conv2
I1102 22:03:25.838413  6323 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1102 22:03:25.838429  6323 layer_factory.hpp:76] Creating layer relu2
I1102 22:03:25.838443  6323 net.cpp:110] Creating Layer relu2
I1102 22:03:25.838452  6323 net.cpp:477] relu2 <- conv2
I1102 22:03:25.838464  6323 net.cpp:419] relu2 -> conv2 (in-place)
I1102 22:03:25.838476  6323 net.cpp:155] Setting up relu2
I1102 22:03:25.838488  6323 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1102 22:03:25.838497  6323 layer_factory.hpp:76] Creating layer pool2
I1102 22:03:25.838510  6323 net.cpp:110] Creating Layer pool2
I1102 22:03:25.838518  6323 net.cpp:477] pool2 <- conv2
I1102 22:03:25.838531  6323 net.cpp:433] pool2 -> pool2
I1102 22:03:25.838544  6323 net.cpp:155] Setting up pool2
I1102 22:03:25.838557  6323 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1102 22:03:25.838567  6323 layer_factory.hpp:76] Creating layer norm2
I1102 22:03:25.838590  6323 net.cpp:110] Creating Layer norm2
I1102 22:03:25.838603  6323 net.cpp:477] norm2 <- pool2
I1102 22:03:25.838614  6323 net.cpp:433] norm2 -> norm2
I1102 22:03:25.838629  6323 net.cpp:155] Setting up norm2
I1102 22:03:25.838640  6323 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1102 22:03:25.838649  6323 layer_factory.hpp:76] Creating layer conv3
I1102 22:03:25.838662  6323 net.cpp:110] Creating Layer conv3
I1102 22:03:25.838672  6323 net.cpp:477] conv3 <- norm2
I1102 22:03:25.838685  6323 net.cpp:433] conv3 -> conv3
I1102 22:03:25.842381  6323 net.cpp:155] Setting up conv3
I1102 22:03:25.842401  6323 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1102 22:03:25.842417  6323 layer_factory.hpp:76] Creating layer relu3
I1102 22:03:25.842429  6323 net.cpp:110] Creating Layer relu3
I1102 22:03:25.842439  6323 net.cpp:477] relu3 <- conv3
I1102 22:03:25.842450  6323 net.cpp:419] relu3 -> conv3 (in-place)
I1102 22:03:25.842463  6323 net.cpp:155] Setting up relu3
I1102 22:03:25.842475  6323 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1102 22:03:25.842485  6323 layer_factory.hpp:76] Creating layer conv4
I1102 22:03:25.842497  6323 net.cpp:110] Creating Layer conv4
I1102 22:03:25.842507  6323 net.cpp:477] conv4 <- conv3
I1102 22:03:25.842519  6323 net.cpp:433] conv4 -> conv4
I1102 22:03:25.845288  6323 net.cpp:155] Setting up conv4
I1102 22:03:25.845309  6323 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1102 22:03:25.845324  6323 layer_factory.hpp:76] Creating layer relu4
I1102 22:03:25.845335  6323 net.cpp:110] Creating Layer relu4
I1102 22:03:25.845345  6323 net.cpp:477] relu4 <- conv4
I1102 22:03:25.845357  6323 net.cpp:419] relu4 -> conv4 (in-place)
I1102 22:03:25.845369  6323 net.cpp:155] Setting up relu4
I1102 22:03:25.845393  6323 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1102 22:03:25.845404  6323 layer_factory.hpp:76] Creating layer conv5
I1102 22:03:25.845417  6323 net.cpp:110] Creating Layer conv5
I1102 22:03:25.845427  6323 net.cpp:477] conv5 <- conv4
I1102 22:03:25.845438  6323 net.cpp:433] conv5 -> conv5
I1102 22:03:25.847301  6323 net.cpp:155] Setting up conv5
I1102 22:03:25.847321  6323 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1102 22:03:25.847339  6323 layer_factory.hpp:76] Creating layer relu5
I1102 22:03:25.847352  6323 net.cpp:110] Creating Layer relu5
I1102 22:03:25.847362  6323 net.cpp:477] relu5 <- conv5
I1102 22:03:25.847373  6323 net.cpp:419] relu5 -> conv5 (in-place)
I1102 22:03:25.847386  6323 net.cpp:155] Setting up relu5
I1102 22:03:25.847398  6323 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1102 22:03:25.847406  6323 layer_factory.hpp:76] Creating layer pool5
I1102 22:03:25.847419  6323 net.cpp:110] Creating Layer pool5
I1102 22:03:25.847429  6323 net.cpp:477] pool5 <- conv5
I1102 22:03:25.847440  6323 net.cpp:433] pool5 -> pool5
I1102 22:03:25.847453  6323 net.cpp:155] Setting up pool5
I1102 22:03:25.847465  6323 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1102 22:03:25.847476  6323 layer_factory.hpp:76] Creating layer fc6
I1102 22:03:25.847487  6323 net.cpp:110] Creating Layer fc6
I1102 22:03:25.847497  6323 net.cpp:477] fc6 <- pool5
I1102 22:03:25.847508  6323 net.cpp:433] fc6 -> fc6
I1102 22:03:26.006444  6323 net.cpp:155] Setting up fc6
I1102 22:03:26.006518  6323 net.cpp:163] Top shape: 10 4096 (40960)
I1102 22:03:26.006539  6323 layer_factory.hpp:76] Creating layer relu6
I1102 22:03:26.006564  6323 net.cpp:110] Creating Layer relu6
I1102 22:03:26.006604  6323 net.cpp:477] relu6 <- fc6
I1102 22:03:26.006621  6323 net.cpp:419] relu6 -> fc6 (in-place)
I1102 22:03:26.006639  6323 net.cpp:155] Setting up relu6
I1102 22:03:26.006651  6323 net.cpp:163] Top shape: 10 4096 (40960)
I1102 22:03:26.006660  6323 layer_factory.hpp:76] Creating layer drop6
I1102 22:03:26.006675  6323 net.cpp:110] Creating Layer drop6
I1102 22:03:26.006685  6323 net.cpp:477] drop6 <- fc6
I1102 22:03:26.006696  6323 net.cpp:419] drop6 -> fc6 (in-place)
I1102 22:03:26.006711  6323 net.cpp:155] Setting up drop6
I1102 22:03:26.006723  6323 net.cpp:163] Top shape: 10 4096 (40960)
I1102 22:03:26.006733  6323 layer_factory.hpp:76] Creating layer fc7
I1102 22:03:26.006747  6323 net.cpp:110] Creating Layer fc7
I1102 22:03:26.006758  6323 net.cpp:477] fc7 <- fc6
I1102 22:03:26.006770  6323 net.cpp:433] fc7 -> fc7
I1102 22:03:26.077339  6323 net.cpp:155] Setting up fc7
I1102 22:03:26.077414  6323 net.cpp:163] Top shape: 10 4096 (40960)
I1102 22:03:26.077432  6323 layer_factory.hpp:76] Creating layer relu7
I1102 22:03:26.077453  6323 net.cpp:110] Creating Layer relu7
I1102 22:03:26.077464  6323 net.cpp:477] relu7 <- fc7
I1102 22:03:26.077479  6323 net.cpp:419] relu7 -> fc7 (in-place)
I1102 22:03:26.077497  6323 net.cpp:155] Setting up relu7
I1102 22:03:26.077507  6323 net.cpp:163] Top shape: 10 4096 (40960)
I1102 22:03:26.077517  6323 layer_factory.hpp:76] Creating layer drop7
I1102 22:03:26.077532  6323 net.cpp:110] Creating Layer drop7
I1102 22:03:26.077541  6323 net.cpp:477] drop7 <- fc7
I1102 22:03:26.077553  6323 net.cpp:419] drop7 -> fc7 (in-place)
I1102 22:03:26.077566  6323 net.cpp:155] Setting up drop7
I1102 22:03:26.077579  6323 net.cpp:163] Top shape: 10 4096 (40960)
I1102 22:03:26.077589  6323 layer_factory.hpp:76] Creating layer fc8
I1102 22:03:26.077605  6323 net.cpp:110] Creating Layer fc8
I1102 22:03:26.077615  6323 net.cpp:477] fc8 <- fc7
I1102 22:03:26.077626  6323 net.cpp:433] fc8 -> fc8
I1102 22:03:26.094671  6323 net.cpp:155] Setting up fc8
I1102 22:03:26.094715  6323 net.cpp:163] Top shape: 10 1000 (10000)
I1102 22:03:26.094732  6323 layer_factory.hpp:76] Creating layer prob
I1102 22:03:26.094748  6323 net.cpp:110] Creating Layer prob
I1102 22:03:26.094758  6323 net.cpp:477] prob <- fc8
I1102 22:03:26.094772  6323 net.cpp:433] prob -> prob
I1102 22:03:26.094792  6323 net.cpp:155] Setting up prob
I1102 22:03:26.094843  6323 net.cpp:163] Top shape: 10 1000 (10000)
I1102 22:03:26.094856  6323 net.cpp:240] prob does not need backward computation.
I1102 22:03:26.094866  6323 net.cpp:240] fc8 does not need backward computation.
I1102 22:03:26.094876  6323 net.cpp:240] drop7 does not need backward computation.
I1102 22:03:26.094884  6323 net.cpp:240] relu7 does not need backward computation.
I1102 22:03:26.094894  6323 net.cpp:240] fc7 does not need backward computation.
I1102 22:03:26.094903  6323 net.cpp:240] drop6 does not need backward computation.
I1102 22:03:26.094913  6323 net.cpp:240] relu6 does not need backward computation.
I1102 22:03:26.094923  6323 net.cpp:240] fc6 does not need backward computation.
I1102 22:03:26.094933  6323 net.cpp:240] pool5 does not need backward computation.
I1102 22:03:26.094943  6323 net.cpp:240] relu5 does not need backward computation.
I1102 22:03:26.094952  6323 net.cpp:240] conv5 does not need backward computation.
I1102 22:03:26.094962  6323 net.cpp:240] relu4 does not need backward computation.
I1102 22:03:26.094972  6323 net.cpp:240] conv4 does not need backward computation.
I1102 22:03:26.094982  6323 net.cpp:240] relu3 does not need backward computation.
I1102 22:03:26.094991  6323 net.cpp:240] conv3 does not need backward computation.
I1102 22:03:26.095002  6323 net.cpp:240] norm2 does not need backward computation.
I1102 22:03:26.095012  6323 net.cpp:240] pool2 does not need backward computation.
I1102 22:03:26.095022  6323 net.cpp:240] relu2 does not need backward computation.
I1102 22:03:26.095031  6323 net.cpp:240] conv2 does not need backward computation.
I1102 22:03:26.095041  6323 net.cpp:240] norm1 does not need backward computation.
I1102 22:03:26.095052  6323 net.cpp:240] pool1 does not need backward computation.
I1102 22:03:26.095062  6323 net.cpp:240] relu1 does not need backward computation.
I1102 22:03:26.095072  6323 net.cpp:240] conv1 does not need backward computation.
I1102 22:03:26.095080  6323 net.cpp:283] This network produces output prob
I1102 22:03:26.095100  6323 net.cpp:297] Network initialization done.
I1102 22:03:26.095110  6323 net.cpp:298] Memory required for data: 62497920
I1102 22:03:27.056658  6323 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1102 22:03:27.056727  6323 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1102 22:03:27.056737  6323 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1102 22:03:27.056747  6323 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1102 22:03:27.560206  6323 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
Traceback (most recent call last):
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 239, in process
    return self.handle()
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 230, in handle
    return self._delegate(fn, self.fvars, args)
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 420, in _delegate
    return handle_class(cls)
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 396, in handle_class
    return tocall(*args)
  File "/root/ds210_capstone/caffe_script/service/controller.py", line 16, in POST
    return self.baseline()
  File "/root/ds210_capstone/caffe_script/service/app.py", line 19, in baseline
    respond = b.baseline_run(request)
  File "/root/ds210_capstone/caffe_script/service/baseline.py", line 29, in baseline_run
    self.caffe_predict()
  File "/root/ds210_capstone/caffe_script/service/baseline.py", line 124, in caffe_predict
    caffe.io.load_image(img_path))
  File "/root/caffe/python/caffe/io.py", line 295, in load_image
    img = skimage.img_as_float(skimage.io.imread(filename)).astype(np.float32)
  File "/root/anaconda/lib/python2.7/site-packages/skimage/io/_io.py", line 100, in imread
    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)
  File "/root/anaconda/lib/python2.7/site-packages/skimage/io/manage_plugins.py", line 207, in call_plugin
    return func(*args, **kwargs)
  File "/root/anaconda/lib/python2.7/site-packages/skimage/io/_plugins/pil_plugin.py", line 46, in imread
    im = Image.open(fname)
  File "/root/anaconda/lib/python2.7/site-packages/PIL/Image.py", line 2248, in open
    fp = builtins.open(fp, "rb")
IOError: [Errno 2] No such file or directory: u'../../../dataset/temp/12071132_117024925320109_1448778029_n.jpg'

50.152.203.175:61153 - - [02/Nov/2015 22:03:27] "HTTP/1.1 POST /resources/1" - 500 Internal Server Error
I1102 22:14:01.943388  6324 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1102 22:14:01.943517  6324 net.cpp:435] Input 0 -> data
I1102 22:14:01.943549  6324 layer_factory.hpp:76] Creating layer conv1
I1102 22:14:01.943568  6324 net.cpp:110] Creating Layer conv1
I1102 22:14:01.943579  6324 net.cpp:477] conv1 <- data
I1102 22:14:01.943593  6324 net.cpp:433] conv1 -> conv1
I1102 22:14:01.943827  6324 net.cpp:155] Setting up conv1
I1102 22:14:01.943850  6324 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1102 22:14:01.943877  6324 layer_factory.hpp:76] Creating layer relu1
I1102 22:14:01.943894  6324 net.cpp:110] Creating Layer relu1
I1102 22:14:01.943904  6324 net.cpp:477] relu1 <- conv1
I1102 22:14:01.943922  6324 net.cpp:419] relu1 -> conv1 (in-place)
I1102 22:14:01.943936  6324 net.cpp:155] Setting up relu1
I1102 22:14:01.943948  6324 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1102 22:14:01.943958  6324 layer_factory.hpp:76] Creating layer pool1
I1102 22:14:01.943970  6324 net.cpp:110] Creating Layer pool1
I1102 22:14:01.943980  6324 net.cpp:477] pool1 <- conv1
I1102 22:14:01.943992  6324 net.cpp:433] pool1 -> pool1
I1102 22:14:01.944010  6324 net.cpp:155] Setting up pool1
I1102 22:14:01.944021  6324 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1102 22:14:01.944031  6324 layer_factory.hpp:76] Creating layer norm1
I1102 22:14:01.944053  6324 net.cpp:110] Creating Layer norm1
I1102 22:14:01.944064  6324 net.cpp:477] norm1 <- pool1
I1102 22:14:01.944080  6324 net.cpp:433] norm1 -> norm1
I1102 22:14:01.944097  6324 net.cpp:155] Setting up norm1
I1102 22:14:01.944108  6324 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1102 22:14:01.944118  6324 layer_factory.hpp:76] Creating layer conv2
I1102 22:14:01.944139  6324 net.cpp:110] Creating Layer conv2
I1102 22:14:01.944150  6324 net.cpp:477] conv2 <- norm1
I1102 22:14:01.944162  6324 net.cpp:433] conv2 -> conv2
I1102 22:14:01.945500  6324 net.cpp:155] Setting up conv2
I1102 22:14:01.945518  6324 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1102 22:14:01.945533  6324 layer_factory.hpp:76] Creating layer relu2
I1102 22:14:01.945547  6324 net.cpp:110] Creating Layer relu2
I1102 22:14:01.945557  6324 net.cpp:477] relu2 <- conv2
I1102 22:14:01.945574  6324 net.cpp:419] relu2 -> conv2 (in-place)
I1102 22:14:01.945588  6324 net.cpp:155] Setting up relu2
I1102 22:14:01.945600  6324 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1102 22:14:01.945608  6324 layer_factory.hpp:76] Creating layer pool2
I1102 22:14:01.945621  6324 net.cpp:110] Creating Layer pool2
I1102 22:14:01.945629  6324 net.cpp:477] pool2 <- conv2
I1102 22:14:01.945641  6324 net.cpp:433] pool2 -> pool2
I1102 22:14:01.945654  6324 net.cpp:155] Setting up pool2
I1102 22:14:01.945665  6324 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1102 22:14:01.945675  6324 layer_factory.hpp:76] Creating layer norm2
I1102 22:14:01.945695  6324 net.cpp:110] Creating Layer norm2
I1102 22:14:01.945706  6324 net.cpp:477] norm2 <- pool2
I1102 22:14:01.945722  6324 net.cpp:433] norm2 -> norm2
I1102 22:14:01.945737  6324 net.cpp:155] Setting up norm2
I1102 22:14:01.945749  6324 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1102 22:14:01.945758  6324 layer_factory.hpp:76] Creating layer conv3
I1102 22:14:01.945771  6324 net.cpp:110] Creating Layer conv3
I1102 22:14:01.945781  6324 net.cpp:477] conv3 <- norm2
I1102 22:14:01.945802  6324 net.cpp:433] conv3 -> conv3
I1102 22:14:01.949529  6324 net.cpp:155] Setting up conv3
I1102 22:14:01.949549  6324 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1102 22:14:01.949566  6324 layer_factory.hpp:76] Creating layer relu3
I1102 22:14:01.949579  6324 net.cpp:110] Creating Layer relu3
I1102 22:14:01.949589  6324 net.cpp:477] relu3 <- conv3
I1102 22:14:01.949600  6324 net.cpp:419] relu3 -> conv3 (in-place)
I1102 22:14:01.949614  6324 net.cpp:155] Setting up relu3
I1102 22:14:01.949625  6324 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1102 22:14:01.949635  6324 layer_factory.hpp:76] Creating layer conv4
I1102 22:14:01.949656  6324 net.cpp:110] Creating Layer conv4
I1102 22:14:01.949667  6324 net.cpp:477] conv4 <- conv3
I1102 22:14:01.949684  6324 net.cpp:433] conv4 -> conv4
I1102 22:14:01.952489  6324 net.cpp:155] Setting up conv4
I1102 22:14:01.952509  6324 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1102 22:14:01.952523  6324 layer_factory.hpp:76] Creating layer relu4
I1102 22:14:01.952545  6324 net.cpp:110] Creating Layer relu4
I1102 22:14:01.952556  6324 net.cpp:477] relu4 <- conv4
I1102 22:14:01.952580  6324 net.cpp:419] relu4 -> conv4 (in-place)
I1102 22:14:01.952594  6324 net.cpp:155] Setting up relu4
I1102 22:14:01.952605  6324 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1102 22:14:01.952615  6324 layer_factory.hpp:76] Creating layer conv5
I1102 22:14:01.952633  6324 net.cpp:110] Creating Layer conv5
I1102 22:14:01.952643  6324 net.cpp:477] conv5 <- conv4
I1102 22:14:01.952654  6324 net.cpp:433] conv5 -> conv5
I1102 22:14:01.954516  6324 net.cpp:155] Setting up conv5
I1102 22:14:01.954535  6324 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1102 22:14:01.954560  6324 layer_factory.hpp:76] Creating layer relu5
I1102 22:14:01.954583  6324 net.cpp:110] Creating Layer relu5
I1102 22:14:01.954596  6324 net.cpp:477] relu5 <- conv5
I1102 22:14:01.954607  6324 net.cpp:419] relu5 -> conv5 (in-place)
I1102 22:14:01.954620  6324 net.cpp:155] Setting up relu5
I1102 22:14:01.954632  6324 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1102 22:14:01.954643  6324 layer_factory.hpp:76] Creating layer pool5
I1102 22:14:01.954660  6324 net.cpp:110] Creating Layer pool5
I1102 22:14:01.954671  6324 net.cpp:477] pool5 <- conv5
I1102 22:14:01.954682  6324 net.cpp:433] pool5 -> pool5
I1102 22:14:01.954697  6324 net.cpp:155] Setting up pool5
I1102 22:14:01.954709  6324 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1102 22:14:01.954718  6324 layer_factory.hpp:76] Creating layer fc6
I1102 22:14:01.954740  6324 net.cpp:110] Creating Layer fc6
I1102 22:14:01.954751  6324 net.cpp:477] fc6 <- pool5
I1102 22:14:01.954761  6324 net.cpp:433] fc6 -> fc6
I1102 22:14:02.113873  6324 net.cpp:155] Setting up fc6
I1102 22:14:02.113944  6324 net.cpp:163] Top shape: 10 4096 (40960)
I1102 22:14:02.113965  6324 layer_factory.hpp:76] Creating layer relu6
I1102 22:14:02.113987  6324 net.cpp:110] Creating Layer relu6
I1102 22:14:02.114001  6324 net.cpp:477] relu6 <- fc6
I1102 22:14:02.114027  6324 net.cpp:419] relu6 -> fc6 (in-place)
I1102 22:14:02.114047  6324 net.cpp:155] Setting up relu6
I1102 22:14:02.114058  6324 net.cpp:163] Top shape: 10 4096 (40960)
I1102 22:14:02.114068  6324 layer_factory.hpp:76] Creating layer drop6
I1102 22:14:02.114083  6324 net.cpp:110] Creating Layer drop6
I1102 22:14:02.114091  6324 net.cpp:477] drop6 <- fc6
I1102 22:14:02.114104  6324 net.cpp:419] drop6 -> fc6 (in-place)
I1102 22:14:02.114117  6324 net.cpp:155] Setting up drop6
I1102 22:14:02.114128  6324 net.cpp:163] Top shape: 10 4096 (40960)
I1102 22:14:02.114138  6324 layer_factory.hpp:76] Creating layer fc7
I1102 22:14:02.114152  6324 net.cpp:110] Creating Layer fc7
I1102 22:14:02.114161  6324 net.cpp:477] fc7 <- fc6
I1102 22:14:02.114173  6324 net.cpp:433] fc7 -> fc7
I1102 22:14:02.184921  6324 net.cpp:155] Setting up fc7
I1102 22:14:02.184990  6324 net.cpp:163] Top shape: 10 4096 (40960)
I1102 22:14:02.185011  6324 layer_factory.hpp:76] Creating layer relu7
I1102 22:14:02.185030  6324 net.cpp:110] Creating Layer relu7
I1102 22:14:02.185042  6324 net.cpp:477] relu7 <- fc7
I1102 22:14:02.185062  6324 net.cpp:419] relu7 -> fc7 (in-place)
I1102 22:14:02.185081  6324 net.cpp:155] Setting up relu7
I1102 22:14:02.185093  6324 net.cpp:163] Top shape: 10 4096 (40960)
I1102 22:14:02.185103  6324 layer_factory.hpp:76] Creating layer drop7
I1102 22:14:02.185117  6324 net.cpp:110] Creating Layer drop7
I1102 22:14:02.185127  6324 net.cpp:477] drop7 <- fc7
I1102 22:14:02.185137  6324 net.cpp:419] drop7 -> fc7 (in-place)
I1102 22:14:02.185153  6324 net.cpp:155] Setting up drop7
I1102 22:14:02.185163  6324 net.cpp:163] Top shape: 10 4096 (40960)
I1102 22:14:02.185173  6324 layer_factory.hpp:76] Creating layer fc8
I1102 22:14:02.185194  6324 net.cpp:110] Creating Layer fc8
I1102 22:14:02.185205  6324 net.cpp:477] fc8 <- fc7
I1102 22:14:02.185217  6324 net.cpp:433] fc8 -> fc8
I1102 22:14:02.202224  6324 net.cpp:155] Setting up fc8
I1102 22:14:02.202265  6324 net.cpp:163] Top shape: 10 1000 (10000)
I1102 22:14:02.202282  6324 layer_factory.hpp:76] Creating layer prob
I1102 22:14:02.202297  6324 net.cpp:110] Creating Layer prob
I1102 22:14:02.202308  6324 net.cpp:477] prob <- fc8
I1102 22:14:02.202358  6324 net.cpp:433] prob -> prob
I1102 22:14:02.202392  6324 net.cpp:155] Setting up prob
I1102 22:14:02.202405  6324 net.cpp:163] Top shape: 10 1000 (10000)
I1102 22:14:02.202415  6324 net.cpp:240] prob does not need backward computation.
I1102 22:14:02.202425  6324 net.cpp:240] fc8 does not need backward computation.
I1102 22:14:02.202435  6324 net.cpp:240] drop7 does not need backward computation.
I1102 22:14:02.202445  6324 net.cpp:240] relu7 does not need backward computation.
I1102 22:14:02.202453  6324 net.cpp:240] fc7 does not need backward computation.
I1102 22:14:02.202463  6324 net.cpp:240] drop6 does not need backward computation.
I1102 22:14:02.202472  6324 net.cpp:240] relu6 does not need backward computation.
I1102 22:14:02.202481  6324 net.cpp:240] fc6 does not need backward computation.
I1102 22:14:02.202491  6324 net.cpp:240] pool5 does not need backward computation.
I1102 22:14:02.202500  6324 net.cpp:240] relu5 does not need backward computation.
I1102 22:14:02.202510  6324 net.cpp:240] conv5 does not need backward computation.
I1102 22:14:02.202520  6324 net.cpp:240] relu4 does not need backward computation.
I1102 22:14:02.202529  6324 net.cpp:240] conv4 does not need backward computation.
I1102 22:14:02.202539  6324 net.cpp:240] relu3 does not need backward computation.
I1102 22:14:02.202548  6324 net.cpp:240] conv3 does not need backward computation.
I1102 22:14:02.202558  6324 net.cpp:240] norm2 does not need backward computation.
I1102 22:14:02.202569  6324 net.cpp:240] pool2 does not need backward computation.
I1102 22:14:02.202592  6324 net.cpp:240] relu2 does not need backward computation.
I1102 22:14:02.202605  6324 net.cpp:240] conv2 does not need backward computation.
I1102 22:14:02.202613  6324 net.cpp:240] norm1 does not need backward computation.
I1102 22:14:02.202623  6324 net.cpp:240] pool1 does not need backward computation.
I1102 22:14:02.202632  6324 net.cpp:240] relu1 does not need backward computation.
I1102 22:14:02.202641  6324 net.cpp:240] conv1 does not need backward computation.
I1102 22:14:02.202651  6324 net.cpp:283] This network produces output prob
I1102 22:14:02.202677  6324 net.cpp:297] Network initialization done.
I1102 22:14:02.202687  6324 net.cpp:298] Memory required for data: 62497920
I1102 22:14:03.167301  6324 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1102 22:14:03.167376  6324 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1102 22:14:03.167387  6324 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1102 22:14:03.167395  6324 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1102 22:14:03.669910  6324 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
58.152.249.17:38669 - - [03/Nov/2015 08:05:10] "HTTP/1.1 GET /" - 404 Not Found
58.152.249.17:41371 - - [03/Nov/2015 08:05:10] "HTTP/1.1 GET /favicon.ico" - 404 Not Found
58.152.249.17:33546 - - [03/Nov/2015 08:05:26] "HTTP/1.1 GET /" - 404 Not Found
Traceback (most recent call last):
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 239, in process
    return self.handle()
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 230, in handle
    return self._delegate(fn, self.fvars, args)
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 420, in _delegate
    return handle_class(cls)
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 396, in handle_class
    return tocall(*args)
  File "/root/ds210_capstone/caffe_script/service/controller.py", line 16, in POST
    return self.baseline()
  File "/root/ds210_capstone/caffe_script/service/app.py", line 17, in baseline
    request = json.loads(web.data())
  File "/root/anaconda/lib/python2.7/json/__init__.py", line 338, in loads
    return _default_decoder.decode(s)
  File "/root/anaconda/lib/python2.7/json/decoder.py", line 366, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/root/anaconda/lib/python2.7/json/decoder.py", line 384, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded

58.152.249.17:42761 - - [03/Nov/2015 08:06:09] "HTTP/1.1 POST /resources/1" - 500 Internal Server Error
Traceback (most recent call last):
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 239, in process
    return self.handle()
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 230, in handle
    return self._delegate(fn, self.fvars, args)
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 420, in _delegate
    return handle_class(cls)
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 396, in handle_class
    return tocall(*args)
  File "/root/ds210_capstone/caffe_script/service/controller.py", line 16, in POST
    return self.baseline()
  File "/root/ds210_capstone/caffe_script/service/app.py", line 19, in baseline
    respond = b.baseline_run(request)
  File "/root/ds210_capstone/caffe_script/service/baseline.py", line 27, in baseline_run
    self.generate_image(request)
  File "/root/ds210_capstone/caffe_script/service/baseline.py", line 48, in generate_image
    urllib.urlretrieve(image_url,image_path)
  File "/root/anaconda/lib/python2.7/urllib.py", line 98, in urlretrieve
    return opener.retrieve(url, filename, reporthook, data)
  File "/root/anaconda/lib/python2.7/urllib.py", line 245, in retrieve
    fp = self.open(url, data)
  File "/root/anaconda/lib/python2.7/urllib.py", line 213, in open
    return getattr(self, name)(url)
  File "/root/anaconda/lib/python2.7/urllib.py", line 469, in open_file
    return self.open_local_file(url)
  File "/root/anaconda/lib/python2.7/urllib.py", line 483, in open_local_file
    raise IOError(e.errno, e.strerror, e.filename)
IOError: [Errno 2] No such file or directory: 'an author'

58.152.249.17:36735 - - [03/Nov/2015 08:06:46] "HTTP/1.1 POST /resources/1" - 500 Internal Server Error
http://0.0.0.0:3000/
http://0.0.0.0:3000/
Traceback (most recent call last):
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 239, in process
    return self.handle()
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 230, in handle
    return self._delegate(fn, self.fvars, args)
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 420, in _delegate
    return handle_class(cls)
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 396, in handle_class
    return tocall(*args)
  File "/root/ds210_capstone/caffe_script/service/controller.py", line 16, in POST
    return self.baseline()
  File "/root/ds210_capstone/caffe_script/service/app.py", line 17, in baseline
    request = json.loads(web.data())
  File "/root/anaconda/lib/python2.7/json/__init__.py", line 338, in loads
    return _default_decoder.decode(s)
  File "/root/anaconda/lib/python2.7/json/decoder.py", line 366, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/root/anaconda/lib/python2.7/json/decoder.py", line 384, in raw_decode
    raise ValueError("No JSON object could be decoded")
ValueError: No JSON object could be decoded

58.152.249.17:34632 - - [03/Nov/2015 08:18:08] "HTTP/1.1 POST /resources/1" - 500 Internal Server Error
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1103 08:18:16.537510   942 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1103 08:18:16.537674   942 net.cpp:435] Input 0 -> data
I1103 08:18:16.537745   942 layer_factory.hpp:76] Creating layer conv1
I1103 08:18:16.537775   942 net.cpp:110] Creating Layer conv1
I1103 08:18:16.537786   942 net.cpp:477] conv1 <- data
I1103 08:18:16.537807   942 net.cpp:433] conv1 -> conv1
I1103 08:18:16.537925   942 net.cpp:155] Setting up conv1
I1103 08:18:16.537953   942 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1103 08:18:16.537986   942 layer_factory.hpp:76] Creating layer relu1
I1103 08:18:16.538002   942 net.cpp:110] Creating Layer relu1
I1103 08:18:16.538013   942 net.cpp:477] relu1 <- conv1
I1103 08:18:16.538025   942 net.cpp:419] relu1 -> conv1 (in-place)
I1103 08:18:16.538048   942 net.cpp:155] Setting up relu1
I1103 08:18:16.538059   942 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1103 08:18:16.538070   942 layer_factory.hpp:76] Creating layer pool1
I1103 08:18:16.538084   942 net.cpp:110] Creating Layer pool1
I1103 08:18:16.538094   942 net.cpp:477] pool1 <- conv1
I1103 08:18:16.538105   942 net.cpp:433] pool1 -> pool1
I1103 08:18:16.538131   942 net.cpp:155] Setting up pool1
I1103 08:18:16.538144   942 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1103 08:18:16.538156   942 layer_factory.hpp:76] Creating layer norm1
I1103 08:18:16.538168   942 net.cpp:110] Creating Layer norm1
I1103 08:18:16.538178   942 net.cpp:477] norm1 <- pool1
I1103 08:18:16.538190   942 net.cpp:433] norm1 -> norm1
I1103 08:18:16.538218   942 net.cpp:155] Setting up norm1
I1103 08:18:16.538242   942 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1103 08:18:16.538254   942 layer_factory.hpp:76] Creating layer conv2
I1103 08:18:16.538267   942 net.cpp:110] Creating Layer conv2
I1103 08:18:16.538278   942 net.cpp:477] conv2 <- norm1
I1103 08:18:16.538290   942 net.cpp:433] conv2 -> conv2
I1103 08:18:16.539369   942 net.cpp:155] Setting up conv2
I1103 08:18:16.539391   942 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1103 08:18:16.539407   942 layer_factory.hpp:76] Creating layer relu2
I1103 08:18:16.539422   942 net.cpp:110] Creating Layer relu2
I1103 08:18:16.539432   942 net.cpp:477] relu2 <- conv2
I1103 08:18:16.539443   942 net.cpp:419] relu2 -> conv2 (in-place)
I1103 08:18:16.539458   942 net.cpp:155] Setting up relu2
I1103 08:18:16.539469   942 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1103 08:18:16.539479   942 layer_factory.hpp:76] Creating layer pool2
I1103 08:18:16.539491   942 net.cpp:110] Creating Layer pool2
I1103 08:18:16.539501   942 net.cpp:477] pool2 <- conv2
I1103 08:18:16.539513   942 net.cpp:433] pool2 -> pool2
I1103 08:18:16.539528   942 net.cpp:155] Setting up pool2
I1103 08:18:16.539541   942 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1103 08:18:16.539551   942 layer_factory.hpp:76] Creating layer norm2
I1103 08:18:16.539564   942 net.cpp:110] Creating Layer norm2
I1103 08:18:16.539574   942 net.cpp:477] norm2 <- pool2
I1103 08:18:16.539585   942 net.cpp:433] norm2 -> norm2
I1103 08:18:16.539599   942 net.cpp:155] Setting up norm2
I1103 08:18:16.539611   942 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1103 08:18:16.539623   942 layer_factory.hpp:76] Creating layer conv3
I1103 08:18:16.539635   942 net.cpp:110] Creating Layer conv3
I1103 08:18:16.539646   942 net.cpp:477] conv3 <- norm2
I1103 08:18:16.539659   942 net.cpp:433] conv3 -> conv3
I1103 08:18:16.543418   942 net.cpp:155] Setting up conv3
I1103 08:18:16.543439   942 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1103 08:18:16.543457   942 layer_factory.hpp:76] Creating layer relu3
I1103 08:18:16.543470   942 net.cpp:110] Creating Layer relu3
I1103 08:18:16.543480   942 net.cpp:477] relu3 <- conv3
I1103 08:18:16.543493   942 net.cpp:419] relu3 -> conv3 (in-place)
I1103 08:18:16.543505   942 net.cpp:155] Setting up relu3
I1103 08:18:16.543517   942 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1103 08:18:16.543527   942 layer_factory.hpp:76] Creating layer conv4
I1103 08:18:16.543540   942 net.cpp:110] Creating Layer conv4
I1103 08:18:16.543550   942 net.cpp:477] conv4 <- conv3
I1103 08:18:16.543562   942 net.cpp:433] conv4 -> conv4
I1103 08:18:16.546350   942 net.cpp:155] Setting up conv4
I1103 08:18:16.546370   942 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1103 08:18:16.546385   942 layer_factory.hpp:76] Creating layer relu4
I1103 08:18:16.546397   942 net.cpp:110] Creating Layer relu4
I1103 08:18:16.546407   942 net.cpp:477] relu4 <- conv4
I1103 08:18:16.546419   942 net.cpp:419] relu4 -> conv4 (in-place)
I1103 08:18:16.546432   942 net.cpp:155] Setting up relu4
I1103 08:18:16.546444   942 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1103 08:18:16.546454   942 layer_factory.hpp:76] Creating layer conv5
I1103 08:18:16.546466   942 net.cpp:110] Creating Layer conv5
I1103 08:18:16.546478   942 net.cpp:477] conv5 <- conv4
I1103 08:18:16.546489   942 net.cpp:433] conv5 -> conv5
I1103 08:18:16.548367   942 net.cpp:155] Setting up conv5
I1103 08:18:16.548387   942 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1103 08:18:16.548404   942 layer_factory.hpp:76] Creating layer relu5
I1103 08:18:16.548418   942 net.cpp:110] Creating Layer relu5
I1103 08:18:16.548427   942 net.cpp:477] relu5 <- conv5
I1103 08:18:16.548439   942 net.cpp:419] relu5 -> conv5 (in-place)
I1103 08:18:16.548452   942 net.cpp:155] Setting up relu5
I1103 08:18:16.548465   942 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1103 08:18:16.548475   942 layer_factory.hpp:76] Creating layer pool5
I1103 08:18:16.548486   942 net.cpp:110] Creating Layer pool5
I1103 08:18:16.548496   942 net.cpp:477] pool5 <- conv5
I1103 08:18:16.548521   942 net.cpp:433] pool5 -> pool5
I1103 08:18:16.548538   942 net.cpp:155] Setting up pool5
I1103 08:18:16.548552   942 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1103 08:18:16.548563   942 layer_factory.hpp:76] Creating layer fc6
I1103 08:18:16.548584   942 net.cpp:110] Creating Layer fc6
I1103 08:18:16.548595   942 net.cpp:477] fc6 <- pool5
I1103 08:18:16.548607   942 net.cpp:433] fc6 -> fc6
I1103 08:18:16.708096   942 net.cpp:155] Setting up fc6
I1103 08:18:16.708170   942 net.cpp:163] Top shape: 10 4096 (40960)
I1103 08:18:16.708192   942 layer_factory.hpp:76] Creating layer relu6
I1103 08:18:16.708217   942 net.cpp:110] Creating Layer relu6
I1103 08:18:16.708230   942 net.cpp:477] relu6 <- fc6
I1103 08:18:16.708245   942 net.cpp:419] relu6 -> fc6 (in-place)
I1103 08:18:16.708262   942 net.cpp:155] Setting up relu6
I1103 08:18:16.708274   942 net.cpp:163] Top shape: 10 4096 (40960)
I1103 08:18:16.708284   942 layer_factory.hpp:76] Creating layer drop6
I1103 08:18:16.708322   942 net.cpp:110] Creating Layer drop6
I1103 08:18:16.708333   942 net.cpp:477] drop6 <- fc6
I1103 08:18:16.708345   942 net.cpp:419] drop6 -> fc6 (in-place)
I1103 08:18:16.708364   942 net.cpp:155] Setting up drop6
I1103 08:18:16.708377   942 net.cpp:163] Top shape: 10 4096 (40960)
I1103 08:18:16.708389   942 layer_factory.hpp:76] Creating layer fc7
I1103 08:18:16.708403   942 net.cpp:110] Creating Layer fc7
I1103 08:18:16.708413   942 net.cpp:477] fc7 <- fc6
I1103 08:18:16.708426   942 net.cpp:433] fc7 -> fc7
I1103 08:18:16.779276   942 net.cpp:155] Setting up fc7
I1103 08:18:16.779348   942 net.cpp:163] Top shape: 10 4096 (40960)
I1103 08:18:16.779369   942 layer_factory.hpp:76] Creating layer relu7
I1103 08:18:16.779389   942 net.cpp:110] Creating Layer relu7
I1103 08:18:16.779402   942 net.cpp:477] relu7 <- fc7
I1103 08:18:16.779415   942 net.cpp:419] relu7 -> fc7 (in-place)
I1103 08:18:16.779433   942 net.cpp:155] Setting up relu7
I1103 08:18:16.779444   942 net.cpp:163] Top shape: 10 4096 (40960)
I1103 08:18:16.779455   942 layer_factory.hpp:76] Creating layer drop7
I1103 08:18:16.779469   942 net.cpp:110] Creating Layer drop7
I1103 08:18:16.779479   942 net.cpp:477] drop7 <- fc7
I1103 08:18:16.779492   942 net.cpp:419] drop7 -> fc7 (in-place)
I1103 08:18:16.779506   942 net.cpp:155] Setting up drop7
I1103 08:18:16.779520   942 net.cpp:163] Top shape: 10 4096 (40960)
I1103 08:18:16.779530   942 layer_factory.hpp:76] Creating layer fc8
I1103 08:18:16.779544   942 net.cpp:110] Creating Layer fc8
I1103 08:18:16.779554   942 net.cpp:477] fc8 <- fc7
I1103 08:18:16.779567   942 net.cpp:433] fc8 -> fc8
I1103 08:18:16.796749   942 net.cpp:155] Setting up fc8
I1103 08:18:16.796790   942 net.cpp:163] Top shape: 10 1000 (10000)
I1103 08:18:16.796807   942 layer_factory.hpp:76] Creating layer prob
I1103 08:18:16.796825   942 net.cpp:110] Creating Layer prob
I1103 08:18:16.796836   942 net.cpp:477] prob <- fc8
I1103 08:18:16.796850   942 net.cpp:433] prob -> prob
I1103 08:18:16.796887   942 net.cpp:155] Setting up prob
I1103 08:18:16.796900   942 net.cpp:163] Top shape: 10 1000 (10000)
I1103 08:18:16.796911   942 net.cpp:240] prob does not need backward computation.
I1103 08:18:16.796922   942 net.cpp:240] fc8 does not need backward computation.
I1103 08:18:16.796932   942 net.cpp:240] drop7 does not need backward computation.
I1103 08:18:16.796942   942 net.cpp:240] relu7 does not need backward computation.
I1103 08:18:16.796952   942 net.cpp:240] fc7 does not need backward computation.
I1103 08:18:16.796962   942 net.cpp:240] drop6 does not need backward computation.
I1103 08:18:16.796972   942 net.cpp:240] relu6 does not need backward computation.
I1103 08:18:16.796982   942 net.cpp:240] fc6 does not need backward computation.
I1103 08:18:16.796993   942 net.cpp:240] pool5 does not need backward computation.
I1103 08:18:16.797003   942 net.cpp:240] relu5 does not need backward computation.
I1103 08:18:16.797013   942 net.cpp:240] conv5 does not need backward computation.
I1103 08:18:16.797024   942 net.cpp:240] relu4 does not need backward computation.
I1103 08:18:16.797062   942 net.cpp:240] conv4 does not need backward computation.
I1103 08:18:16.797075   942 net.cpp:240] relu3 does not need backward computation.
I1103 08:18:16.797085   942 net.cpp:240] conv3 does not need backward computation.
I1103 08:18:16.797096   942 net.cpp:240] norm2 does not need backward computation.
I1103 08:18:16.797106   942 net.cpp:240] pool2 does not need backward computation.
I1103 08:18:16.797116   942 net.cpp:240] relu2 does not need backward computation.
I1103 08:18:16.797127   942 net.cpp:240] conv2 does not need backward computation.
I1103 08:18:16.797137   942 net.cpp:240] norm1 does not need backward computation.
I1103 08:18:16.797147   942 net.cpp:240] pool1 does not need backward computation.
I1103 08:18:16.797158   942 net.cpp:240] relu1 does not need backward computation.
I1103 08:18:16.797168   942 net.cpp:240] conv1 does not need backward computation.
I1103 08:18:16.797178   942 net.cpp:283] This network produces output prob
I1103 08:18:16.797205   942 net.cpp:297] Network initialization done.
I1103 08:18:16.797216   942 net.cpp:298] Memory required for data: 62497920
I1103 08:18:17.776969   942 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1103 08:18:17.777048   942 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1103 08:18:17.777060   942 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1103 08:18:17.777070   942 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1103 08:18:18.288205   942 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
58.152.249.17:37294 - - [03/Nov/2015 08:18:19] "HTTP/1.1 POST /resources/1" - 200 OK
I1103 23:41:39.450150   943 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1103 23:41:39.450260   943 net.cpp:435] Input 0 -> data
I1103 23:41:39.450294   943 layer_factory.hpp:76] Creating layer conv1
I1103 23:41:39.450314   943 net.cpp:110] Creating Layer conv1
I1103 23:41:39.450325   943 net.cpp:477] conv1 <- data
I1103 23:41:39.450337   943 net.cpp:433] conv1 -> conv1
I1103 23:41:39.450399   943 net.cpp:155] Setting up conv1
I1103 23:41:39.450420   943 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1103 23:41:39.450444   943 layer_factory.hpp:76] Creating layer relu1
I1103 23:41:39.450460   943 net.cpp:110] Creating Layer relu1
I1103 23:41:39.450471   943 net.cpp:477] relu1 <- conv1
I1103 23:41:39.450484   943 net.cpp:419] relu1 -> conv1 (in-place)
I1103 23:41:39.450497   943 net.cpp:155] Setting up relu1
I1103 23:41:39.450510   943 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1103 23:41:39.450520   943 layer_factory.hpp:76] Creating layer pool1
I1103 23:41:39.450532   943 net.cpp:110] Creating Layer pool1
I1103 23:41:39.450542   943 net.cpp:477] pool1 <- conv1
I1103 23:41:39.450587   943 net.cpp:433] pool1 -> pool1
I1103 23:41:39.450610   943 net.cpp:155] Setting up pool1
I1103 23:41:39.450624   943 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1103 23:41:39.450635   943 layer_factory.hpp:76] Creating layer norm1
I1103 23:41:39.450649   943 net.cpp:110] Creating Layer norm1
I1103 23:41:39.450659   943 net.cpp:477] norm1 <- pool1
I1103 23:41:39.450670   943 net.cpp:433] norm1 -> norm1
I1103 23:41:39.450685   943 net.cpp:155] Setting up norm1
I1103 23:41:39.450698   943 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1103 23:41:39.450708   943 layer_factory.hpp:76] Creating layer conv2
I1103 23:41:39.450721   943 net.cpp:110] Creating Layer conv2
I1103 23:41:39.450732   943 net.cpp:477] conv2 <- norm1
I1103 23:41:39.450743   943 net.cpp:433] conv2 -> conv2
I1103 23:41:39.451766   943 net.cpp:155] Setting up conv2
I1103 23:41:39.451784   943 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1103 23:41:39.451800   943 layer_factory.hpp:76] Creating layer relu2
I1103 23:41:39.451813   943 net.cpp:110] Creating Layer relu2
I1103 23:41:39.451824   943 net.cpp:477] relu2 <- conv2
I1103 23:41:39.451835   943 net.cpp:419] relu2 -> conv2 (in-place)
I1103 23:41:39.451849   943 net.cpp:155] Setting up relu2
I1103 23:41:39.451860   943 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1103 23:41:39.451871   943 layer_factory.hpp:76] Creating layer pool2
I1103 23:41:39.451884   943 net.cpp:110] Creating Layer pool2
I1103 23:41:39.451894   943 net.cpp:477] pool2 <- conv2
I1103 23:41:39.451905   943 net.cpp:433] pool2 -> pool2
I1103 23:41:39.451920   943 net.cpp:155] Setting up pool2
I1103 23:41:39.451932   943 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1103 23:41:39.451943   943 layer_factory.hpp:76] Creating layer norm2
I1103 23:41:39.451956   943 net.cpp:110] Creating Layer norm2
I1103 23:41:39.451966   943 net.cpp:477] norm2 <- pool2
I1103 23:41:39.451977   943 net.cpp:433] norm2 -> norm2
I1103 23:41:39.451992   943 net.cpp:155] Setting up norm2
I1103 23:41:39.452003   943 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1103 23:41:39.452013   943 layer_factory.hpp:76] Creating layer conv3
I1103 23:41:39.452039   943 net.cpp:110] Creating Layer conv3
I1103 23:41:39.452051   943 net.cpp:477] conv3 <- norm2
I1103 23:41:39.452064   943 net.cpp:433] conv3 -> conv3
I1103 23:41:39.455843   943 net.cpp:155] Setting up conv3
I1103 23:41:39.455864   943 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1103 23:41:39.455883   943 layer_factory.hpp:76] Creating layer relu3
I1103 23:41:39.455895   943 net.cpp:110] Creating Layer relu3
I1103 23:41:39.455905   943 net.cpp:477] relu3 <- conv3
I1103 23:41:39.455917   943 net.cpp:419] relu3 -> conv3 (in-place)
I1103 23:41:39.455930   943 net.cpp:155] Setting up relu3
I1103 23:41:39.455942   943 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1103 23:41:39.455952   943 layer_factory.hpp:76] Creating layer conv4
I1103 23:41:39.455965   943 net.cpp:110] Creating Layer conv4
I1103 23:41:39.455974   943 net.cpp:477] conv4 <- conv3
I1103 23:41:39.455987   943 net.cpp:433] conv4 -> conv4
I1103 23:41:39.458760   943 net.cpp:155] Setting up conv4
I1103 23:41:39.458781   943 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1103 23:41:39.458794   943 layer_factory.hpp:76] Creating layer relu4
I1103 23:41:39.458807   943 net.cpp:110] Creating Layer relu4
I1103 23:41:39.458817   943 net.cpp:477] relu4 <- conv4
I1103 23:41:39.458829   943 net.cpp:419] relu4 -> conv4 (in-place)
I1103 23:41:39.458843   943 net.cpp:155] Setting up relu4
I1103 23:41:39.458854   943 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1103 23:41:39.458864   943 layer_factory.hpp:76] Creating layer conv5
I1103 23:41:39.458878   943 net.cpp:110] Creating Layer conv5
I1103 23:41:39.458887   943 net.cpp:477] conv5 <- conv4
I1103 23:41:39.458900   943 net.cpp:433] conv5 -> conv5
I1103 23:41:39.460775   943 net.cpp:155] Setting up conv5
I1103 23:41:39.460794   943 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1103 23:41:39.460811   943 layer_factory.hpp:76] Creating layer relu5
I1103 23:41:39.460825   943 net.cpp:110] Creating Layer relu5
I1103 23:41:39.460835   943 net.cpp:477] relu5 <- conv5
I1103 23:41:39.460847   943 net.cpp:419] relu5 -> conv5 (in-place)
I1103 23:41:39.460860   943 net.cpp:155] Setting up relu5
I1103 23:41:39.460871   943 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1103 23:41:39.460881   943 layer_factory.hpp:76] Creating layer pool5
I1103 23:41:39.460893   943 net.cpp:110] Creating Layer pool5
I1103 23:41:39.460903   943 net.cpp:477] pool5 <- conv5
I1103 23:41:39.460916   943 net.cpp:433] pool5 -> pool5
I1103 23:41:39.460932   943 net.cpp:155] Setting up pool5
I1103 23:41:39.460943   943 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1103 23:41:39.460954   943 layer_factory.hpp:76] Creating layer fc6
I1103 23:41:39.460968   943 net.cpp:110] Creating Layer fc6
I1103 23:41:39.460978   943 net.cpp:477] fc6 <- pool5
I1103 23:41:39.460989   943 net.cpp:433] fc6 -> fc6
I1103 23:41:39.620728   943 net.cpp:155] Setting up fc6
I1103 23:41:39.620802   943 net.cpp:163] Top shape: 10 4096 (40960)
I1103 23:41:39.620823   943 layer_factory.hpp:76] Creating layer relu6
I1103 23:41:39.620848   943 net.cpp:110] Creating Layer relu6
I1103 23:41:39.620861   943 net.cpp:477] relu6 <- fc6
I1103 23:41:39.620875   943 net.cpp:419] relu6 -> fc6 (in-place)
I1103 23:41:39.620894   943 net.cpp:155] Setting up relu6
I1103 23:41:39.620905   943 net.cpp:163] Top shape: 10 4096 (40960)
I1103 23:41:39.620916   943 layer_factory.hpp:76] Creating layer drop6
I1103 23:41:39.620931   943 net.cpp:110] Creating Layer drop6
I1103 23:41:39.620941   943 net.cpp:477] drop6 <- fc6
I1103 23:41:39.620954   943 net.cpp:419] drop6 -> fc6 (in-place)
I1103 23:41:39.620968   943 net.cpp:155] Setting up drop6
I1103 23:41:39.620980   943 net.cpp:163] Top shape: 10 4096 (40960)
I1103 23:41:39.620991   943 layer_factory.hpp:76] Creating layer fc7
I1103 23:41:39.621006   943 net.cpp:110] Creating Layer fc7
I1103 23:41:39.621016   943 net.cpp:477] fc7 <- fc6
I1103 23:41:39.621029   943 net.cpp:433] fc7 -> fc7
I1103 23:41:39.691880   943 net.cpp:155] Setting up fc7
I1103 23:41:39.691951   943 net.cpp:163] Top shape: 10 4096 (40960)
I1103 23:41:39.691972   943 layer_factory.hpp:76] Creating layer relu7
I1103 23:41:39.692025   943 net.cpp:110] Creating Layer relu7
I1103 23:41:39.692039   943 net.cpp:477] relu7 <- fc7
I1103 23:41:39.692054   943 net.cpp:419] relu7 -> fc7 (in-place)
I1103 23:41:39.692071   943 net.cpp:155] Setting up relu7
I1103 23:41:39.692083   943 net.cpp:163] Top shape: 10 4096 (40960)
I1103 23:41:39.692093   943 layer_factory.hpp:76] Creating layer drop7
I1103 23:41:39.692107   943 net.cpp:110] Creating Layer drop7
I1103 23:41:39.692117   943 net.cpp:477] drop7 <- fc7
I1103 23:41:39.692129   943 net.cpp:419] drop7 -> fc7 (in-place)
I1103 23:41:39.692144   943 net.cpp:155] Setting up drop7
I1103 23:41:39.692157   943 net.cpp:163] Top shape: 10 4096 (40960)
I1103 23:41:39.692167   943 layer_factory.hpp:76] Creating layer fc8
I1103 23:41:39.692181   943 net.cpp:110] Creating Layer fc8
I1103 23:41:39.692193   943 net.cpp:477] fc8 <- fc7
I1103 23:41:39.692204   943 net.cpp:433] fc8 -> fc8
I1103 23:41:39.709297   943 net.cpp:155] Setting up fc8
I1103 23:41:39.709342   943 net.cpp:163] Top shape: 10 1000 (10000)
I1103 23:41:39.709360   943 layer_factory.hpp:76] Creating layer prob
I1103 23:41:39.709378   943 net.cpp:110] Creating Layer prob
I1103 23:41:39.709388   943 net.cpp:477] prob <- fc8
I1103 23:41:39.709403   943 net.cpp:433] prob -> prob
I1103 23:41:39.709424   943 net.cpp:155] Setting up prob
I1103 23:41:39.709436   943 net.cpp:163] Top shape: 10 1000 (10000)
I1103 23:41:39.709446   943 net.cpp:240] prob does not need backward computation.
I1103 23:41:39.709457   943 net.cpp:240] fc8 does not need backward computation.
I1103 23:41:39.709467   943 net.cpp:240] drop7 does not need backward computation.
I1103 23:41:39.709477   943 net.cpp:240] relu7 does not need backward computation.
I1103 23:41:39.709487   943 net.cpp:240] fc7 does not need backward computation.
I1103 23:41:39.709497   943 net.cpp:240] drop6 does not need backward computation.
I1103 23:41:39.709507   943 net.cpp:240] relu6 does not need backward computation.
I1103 23:41:39.709517   943 net.cpp:240] fc6 does not need backward computation.
I1103 23:41:39.709528   943 net.cpp:240] pool5 does not need backward computation.
I1103 23:41:39.709539   943 net.cpp:240] relu5 does not need backward computation.
I1103 23:41:39.709549   943 net.cpp:240] conv5 does not need backward computation.
I1103 23:41:39.709559   943 net.cpp:240] relu4 does not need backward computation.
I1103 23:41:39.709569   943 net.cpp:240] conv4 does not need backward computation.
I1103 23:41:39.709579   943 net.cpp:240] relu3 does not need backward computation.
I1103 23:41:39.709589   943 net.cpp:240] conv3 does not need backward computation.
I1103 23:41:39.709600   943 net.cpp:240] norm2 does not need backward computation.
I1103 23:41:39.709610   943 net.cpp:240] pool2 does not need backward computation.
I1103 23:41:39.709620   943 net.cpp:240] relu2 does not need backward computation.
I1103 23:41:39.709630   943 net.cpp:240] conv2 does not need backward computation.
I1103 23:41:39.709640   943 net.cpp:240] norm1 does not need backward computation.
I1103 23:41:39.709651   943 net.cpp:240] pool1 does not need backward computation.
I1103 23:41:39.709661   943 net.cpp:240] relu1 does not need backward computation.
I1103 23:41:39.709671   943 net.cpp:240] conv1 does not need backward computation.
I1103 23:41:39.709681   943 net.cpp:283] This network produces output prob
I1103 23:41:39.709703   943 net.cpp:297] Network initialization done.
I1103 23:41:39.709712   943 net.cpp:298] Memory required for data: 62497920
I1103 23:41:40.686421   943 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1103 23:41:40.686491   943 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1103 23:41:40.686501   943 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1103 23:41:40.686511   943 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1103 23:41:41.193141   943 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
50.152.203.175:49265 - - [03/Nov/2015 23:41:42] "HTTP/1.1 POST /resources/1" - 200 OK
141.212.122.112:9147 - - [06/Nov/2015 12:13:18] "HTTP/1.1 GET /" - 404 Not Found
I1111 04:40:45.015305   946 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1111 04:40:45.015406   946 net.cpp:435] Input 0 -> data
I1111 04:40:45.015444   946 layer_factory.hpp:76] Creating layer conv1
I1111 04:40:45.015465   946 net.cpp:110] Creating Layer conv1
I1111 04:40:45.015476   946 net.cpp:477] conv1 <- data
I1111 04:40:45.015491   946 net.cpp:433] conv1 -> conv1
I1111 04:40:45.015558   946 net.cpp:155] Setting up conv1
I1111 04:40:45.015580   946 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1111 04:40:45.015604   946 layer_factory.hpp:76] Creating layer relu1
I1111 04:40:45.015619   946 net.cpp:110] Creating Layer relu1
I1111 04:40:45.015630   946 net.cpp:477] relu1 <- conv1
I1111 04:40:45.015642   946 net.cpp:419] relu1 -> conv1 (in-place)
I1111 04:40:45.020746   946 net.cpp:155] Setting up relu1
I1111 04:40:45.020766   946 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1111 04:40:45.020776   946 layer_factory.hpp:76] Creating layer pool1
I1111 04:40:45.020790   946 net.cpp:110] Creating Layer pool1
I1111 04:40:45.020802   946 net.cpp:477] pool1 <- conv1
I1111 04:40:45.020813   946 net.cpp:433] pool1 -> pool1
I1111 04:40:45.020833   946 net.cpp:155] Setting up pool1
I1111 04:40:45.020846   946 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1111 04:40:45.020856   946 layer_factory.hpp:76] Creating layer norm1
I1111 04:40:45.020870   946 net.cpp:110] Creating Layer norm1
I1111 04:40:45.020880   946 net.cpp:477] norm1 <- pool1
I1111 04:40:45.020892   946 net.cpp:433] norm1 -> norm1
I1111 04:40:45.020908   946 net.cpp:155] Setting up norm1
I1111 04:40:45.020921   946 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1111 04:40:45.020931   946 layer_factory.hpp:76] Creating layer conv2
I1111 04:40:45.020946   946 net.cpp:110] Creating Layer conv2
I1111 04:40:45.020956   946 net.cpp:477] conv2 <- norm1
I1111 04:40:45.020967   946 net.cpp:433] conv2 -> conv2
I1111 04:40:45.022049   946 net.cpp:155] Setting up conv2
I1111 04:40:45.022069   946 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1111 04:40:45.022086   946 layer_factory.hpp:76] Creating layer relu2
I1111 04:40:45.022099   946 net.cpp:110] Creating Layer relu2
I1111 04:40:45.022110   946 net.cpp:477] relu2 <- conv2
I1111 04:40:45.022122   946 net.cpp:419] relu2 -> conv2 (in-place)
I1111 04:40:45.022135   946 net.cpp:155] Setting up relu2
I1111 04:40:45.022147   946 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1111 04:40:45.022157   946 layer_factory.hpp:76] Creating layer pool2
I1111 04:40:45.022171   946 net.cpp:110] Creating Layer pool2
I1111 04:40:45.022181   946 net.cpp:477] pool2 <- conv2
I1111 04:40:45.022192   946 net.cpp:433] pool2 -> pool2
I1111 04:40:45.022207   946 net.cpp:155] Setting up pool2
I1111 04:40:45.022220   946 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 04:40:45.022230   946 layer_factory.hpp:76] Creating layer norm2
I1111 04:40:45.022243   946 net.cpp:110] Creating Layer norm2
I1111 04:40:45.022253   946 net.cpp:477] norm2 <- pool2
I1111 04:40:45.022264   946 net.cpp:433] norm2 -> norm2
I1111 04:40:45.022279   946 net.cpp:155] Setting up norm2
I1111 04:40:45.022291   946 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 04:40:45.022302   946 layer_factory.hpp:76] Creating layer conv3
I1111 04:40:45.022315   946 net.cpp:110] Creating Layer conv3
I1111 04:40:45.022326   946 net.cpp:477] conv3 <- norm2
I1111 04:40:45.022338   946 net.cpp:433] conv3 -> conv3
I1111 04:40:45.026422   946 net.cpp:155] Setting up conv3
I1111 04:40:45.026443   946 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 04:40:45.026461   946 layer_factory.hpp:76] Creating layer relu3
I1111 04:40:45.026475   946 net.cpp:110] Creating Layer relu3
I1111 04:40:45.026485   946 net.cpp:477] relu3 <- conv3
I1111 04:40:45.026497   946 net.cpp:419] relu3 -> conv3 (in-place)
I1111 04:40:45.026510   946 net.cpp:155] Setting up relu3
I1111 04:40:45.026523   946 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 04:40:45.026533   946 layer_factory.hpp:76] Creating layer conv4
I1111 04:40:45.026546   946 net.cpp:110] Creating Layer conv4
I1111 04:40:45.026556   946 net.cpp:477] conv4 <- conv3
I1111 04:40:45.026568   946 net.cpp:433] conv4 -> conv4
I1111 04:40:45.029515   946 net.cpp:155] Setting up conv4
I1111 04:40:45.029534   946 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 04:40:45.029549   946 layer_factory.hpp:76] Creating layer relu4
I1111 04:40:45.029562   946 net.cpp:110] Creating Layer relu4
I1111 04:40:45.029573   946 net.cpp:477] relu4 <- conv4
I1111 04:40:45.029584   946 net.cpp:419] relu4 -> conv4 (in-place)
I1111 04:40:45.029598   946 net.cpp:155] Setting up relu4
I1111 04:40:45.029610   946 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 04:40:45.029620   946 layer_factory.hpp:76] Creating layer conv5
I1111 04:40:45.029633   946 net.cpp:110] Creating Layer conv5
I1111 04:40:45.029644   946 net.cpp:477] conv5 <- conv4
I1111 04:40:45.029669   946 net.cpp:433] conv5 -> conv5
I1111 04:40:45.031604   946 net.cpp:155] Setting up conv5
I1111 04:40:45.031625   946 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 04:40:45.031641   946 layer_factory.hpp:76] Creating layer relu5
I1111 04:40:45.031656   946 net.cpp:110] Creating Layer relu5
I1111 04:40:45.031666   946 net.cpp:477] relu5 <- conv5
I1111 04:40:45.031677   946 net.cpp:419] relu5 -> conv5 (in-place)
I1111 04:40:45.031692   946 net.cpp:155] Setting up relu5
I1111 04:40:45.031703   946 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 04:40:45.031713   946 layer_factory.hpp:76] Creating layer pool5
I1111 04:40:45.031725   946 net.cpp:110] Creating Layer pool5
I1111 04:40:45.031735   946 net.cpp:477] pool5 <- conv5
I1111 04:40:45.031747   946 net.cpp:433] pool5 -> pool5
I1111 04:40:45.031764   946 net.cpp:155] Setting up pool5
I1111 04:40:45.031776   946 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1111 04:40:45.031786   946 layer_factory.hpp:76] Creating layer fc6
I1111 04:40:45.031800   946 net.cpp:110] Creating Layer fc6
I1111 04:40:45.031810   946 net.cpp:477] fc6 <- pool5
I1111 04:40:45.031821   946 net.cpp:433] fc6 -> fc6
I1111 04:40:45.196074   946 net.cpp:155] Setting up fc6
I1111 04:40:45.196144   946 net.cpp:163] Top shape: 10 4096 (40960)
I1111 04:40:45.196166   946 layer_factory.hpp:76] Creating layer relu6
I1111 04:40:45.196192   946 net.cpp:110] Creating Layer relu6
I1111 04:40:45.196203   946 net.cpp:477] relu6 <- fc6
I1111 04:40:45.196219   946 net.cpp:419] relu6 -> fc6 (in-place)
I1111 04:40:45.196238   946 net.cpp:155] Setting up relu6
I1111 04:40:45.196250   946 net.cpp:163] Top shape: 10 4096 (40960)
I1111 04:40:45.196260   946 layer_factory.hpp:76] Creating layer drop6
I1111 04:40:45.196276   946 net.cpp:110] Creating Layer drop6
I1111 04:40:45.196286   946 net.cpp:477] drop6 <- fc6
I1111 04:40:45.196298   946 net.cpp:419] drop6 -> fc6 (in-place)
I1111 04:40:45.196315   946 net.cpp:155] Setting up drop6
I1111 04:40:45.196327   946 net.cpp:163] Top shape: 10 4096 (40960)
I1111 04:40:45.196337   946 layer_factory.hpp:76] Creating layer fc7
I1111 04:40:45.196353   946 net.cpp:110] Creating Layer fc7
I1111 04:40:45.196363   946 net.cpp:477] fc7 <- fc6
I1111 04:40:45.196377   946 net.cpp:433] fc7 -> fc7
I1111 04:40:45.268275   946 net.cpp:155] Setting up fc7
I1111 04:40:45.268349   946 net.cpp:163] Top shape: 10 4096 (40960)
I1111 04:40:45.268373   946 layer_factory.hpp:76] Creating layer relu7
I1111 04:40:45.268395   946 net.cpp:110] Creating Layer relu7
I1111 04:40:45.268409   946 net.cpp:477] relu7 <- fc7
I1111 04:40:45.268424   946 net.cpp:419] relu7 -> fc7 (in-place)
I1111 04:40:45.268445   946 net.cpp:155] Setting up relu7
I1111 04:40:45.268457   946 net.cpp:163] Top shape: 10 4096 (40960)
I1111 04:40:45.268467   946 layer_factory.hpp:76] Creating layer drop7
I1111 04:40:45.268483   946 net.cpp:110] Creating Layer drop7
I1111 04:40:45.268493   946 net.cpp:477] drop7 <- fc7
I1111 04:40:45.268506   946 net.cpp:419] drop7 -> fc7 (in-place)
I1111 04:40:45.268522   946 net.cpp:155] Setting up drop7
I1111 04:40:45.268533   946 net.cpp:163] Top shape: 10 4096 (40960)
I1111 04:40:45.268544   946 layer_factory.hpp:76] Creating layer fc8
I1111 04:40:45.268559   946 net.cpp:110] Creating Layer fc8
I1111 04:40:45.268570   946 net.cpp:477] fc8 <- fc7
I1111 04:40:45.268584   946 net.cpp:433] fc8 -> fc8
I1111 04:40:45.285985   946 net.cpp:155] Setting up fc8
I1111 04:40:45.286026   946 net.cpp:163] Top shape: 10 1000 (10000)
I1111 04:40:45.286044   946 layer_factory.hpp:76] Creating layer prob
I1111 04:40:45.286062   946 net.cpp:110] Creating Layer prob
I1111 04:40:45.286074   946 net.cpp:477] prob <- fc8
I1111 04:40:45.286089   946 net.cpp:433] prob -> prob
I1111 04:40:45.286113   946 net.cpp:155] Setting up prob
I1111 04:40:45.286125   946 net.cpp:163] Top shape: 10 1000 (10000)
I1111 04:40:45.286136   946 net.cpp:240] prob does not need backward computation.
I1111 04:40:45.286146   946 net.cpp:240] fc8 does not need backward computation.
I1111 04:40:45.286185   946 net.cpp:240] drop7 does not need backward computation.
I1111 04:40:45.286197   946 net.cpp:240] relu7 does not need backward computation.
I1111 04:40:45.286207   946 net.cpp:240] fc7 does not need backward computation.
I1111 04:40:45.286217   946 net.cpp:240] drop6 does not need backward computation.
I1111 04:40:45.286227   946 net.cpp:240] relu6 does not need backward computation.
I1111 04:40:45.286237   946 net.cpp:240] fc6 does not need backward computation.
I1111 04:40:45.286248   946 net.cpp:240] pool5 does not need backward computation.
I1111 04:40:45.286258   946 net.cpp:240] relu5 does not need backward computation.
I1111 04:40:45.286268   946 net.cpp:240] conv5 does not need backward computation.
I1111 04:40:45.286279   946 net.cpp:240] relu4 does not need backward computation.
I1111 04:40:45.286289   946 net.cpp:240] conv4 does not need backward computation.
I1111 04:40:45.286299   946 net.cpp:240] relu3 does not need backward computation.
I1111 04:40:45.286309   946 net.cpp:240] conv3 does not need backward computation.
I1111 04:40:45.286320   946 net.cpp:240] norm2 does not need backward computation.
I1111 04:40:45.286331   946 net.cpp:240] pool2 does not need backward computation.
I1111 04:40:45.286341   946 net.cpp:240] relu2 does not need backward computation.
I1111 04:40:45.286351   946 net.cpp:240] conv2 does not need backward computation.
I1111 04:40:45.286362   946 net.cpp:240] norm1 does not need backward computation.
I1111 04:40:45.286373   946 net.cpp:240] pool1 does not need backward computation.
I1111 04:40:45.286383   946 net.cpp:240] relu1 does not need backward computation.
I1111 04:40:45.286393   946 net.cpp:240] conv1 does not need backward computation.
I1111 04:40:45.286403   946 net.cpp:283] This network produces output prob
I1111 04:40:45.286425   946 net.cpp:297] Network initialization done.
I1111 04:40:45.286434   946 net.cpp:298] Memory required for data: 62497920
I1111 04:40:46.284395   946 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1111 04:40:46.284446   946 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1111 04:40:46.284456   946 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1111 04:40:46.284466   946 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1111 04:40:46.792677   946 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
58.152.249.17:43757 - - [11/Nov/2015 04:40:48] "HTTP/1.1 POST /resources/1" - 200 OK
58.152.249.17:46008 - - [11/Nov/2015 04:45:56] "HTTP/1.1 GET /resources/1" - 405 Method Not Allowed
58.152.249.17:46089 - - [11/Nov/2015 04:45:57] "HTTP/1.1 GET /favicon.ico" - 404 Not Found
I1111 05:04:52.032090   949 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1111 05:04:52.032203   949 net.cpp:435] Input 0 -> data
I1111 05:04:52.032239   949 layer_factory.hpp:76] Creating layer conv1
I1111 05:04:52.032258   949 net.cpp:110] Creating Layer conv1
I1111 05:04:52.032269   949 net.cpp:477] conv1 <- data
I1111 05:04:52.032282   949 net.cpp:433] conv1 -> conv1
I1111 05:04:52.032346   949 net.cpp:155] Setting up conv1
I1111 05:04:52.032367   949 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1111 05:04:52.032388   949 layer_factory.hpp:76] Creating layer relu1
I1111 05:04:52.032404   949 net.cpp:110] Creating Layer relu1
I1111 05:04:52.032415   949 net.cpp:477] relu1 <- conv1
I1111 05:04:52.032428   949 net.cpp:419] relu1 -> conv1 (in-place)
I1111 05:04:52.032441   949 net.cpp:155] Setting up relu1
I1111 05:04:52.032454   949 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1111 05:04:52.032464   949 layer_factory.hpp:76] Creating layer pool1
I1111 05:04:52.032477   949 net.cpp:110] Creating Layer pool1
I1111 05:04:52.032487   949 net.cpp:477] pool1 <- conv1
I1111 05:04:52.032500   949 net.cpp:433] pool1 -> pool1
I1111 05:04:52.032517   949 net.cpp:155] Setting up pool1
I1111 05:04:52.032531   949 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1111 05:04:52.032541   949 layer_factory.hpp:76] Creating layer norm1
I1111 05:04:52.032554   949 net.cpp:110] Creating Layer norm1
I1111 05:04:52.032564   949 net.cpp:477] norm1 <- pool1
I1111 05:04:52.032577   949 net.cpp:433] norm1 -> norm1
I1111 05:04:52.032593   949 net.cpp:155] Setting up norm1
I1111 05:04:52.032604   949 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1111 05:04:52.032614   949 layer_factory.hpp:76] Creating layer conv2
I1111 05:04:52.032627   949 net.cpp:110] Creating Layer conv2
I1111 05:04:52.032637   949 net.cpp:477] conv2 <- norm1
I1111 05:04:52.032649   949 net.cpp:433] conv2 -> conv2
I1111 05:04:52.033586   949 net.cpp:155] Setting up conv2
I1111 05:04:52.033604   949 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1111 05:04:52.033620   949 layer_factory.hpp:76] Creating layer relu2
I1111 05:04:52.033634   949 net.cpp:110] Creating Layer relu2
I1111 05:04:52.033644   949 net.cpp:477] relu2 <- conv2
I1111 05:04:52.033656   949 net.cpp:419] relu2 -> conv2 (in-place)
I1111 05:04:52.033681   949 net.cpp:155] Setting up relu2
I1111 05:04:52.033695   949 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1111 05:04:52.033705   949 layer_factory.hpp:76] Creating layer pool2
I1111 05:04:52.033720   949 net.cpp:110] Creating Layer pool2
I1111 05:04:52.033730   949 net.cpp:477] pool2 <- conv2
I1111 05:04:52.033742   949 net.cpp:433] pool2 -> pool2
I1111 05:04:52.033757   949 net.cpp:155] Setting up pool2
I1111 05:04:52.033769   949 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 05:04:52.033779   949 layer_factory.hpp:76] Creating layer norm2
I1111 05:04:52.033792   949 net.cpp:110] Creating Layer norm2
I1111 05:04:52.033802   949 net.cpp:477] norm2 <- pool2
I1111 05:04:52.033813   949 net.cpp:433] norm2 -> norm2
I1111 05:04:52.033828   949 net.cpp:155] Setting up norm2
I1111 05:04:52.033839   949 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 05:04:52.033849   949 layer_factory.hpp:76] Creating layer conv3
I1111 05:04:52.033862   949 net.cpp:110] Creating Layer conv3
I1111 05:04:52.033872   949 net.cpp:477] conv3 <- norm2
I1111 05:04:52.033885   949 net.cpp:433] conv3 -> conv3
I1111 05:04:52.037624   949 net.cpp:155] Setting up conv3
I1111 05:04:52.037647   949 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 05:04:52.037663   949 layer_factory.hpp:76] Creating layer relu3
I1111 05:04:52.037678   949 net.cpp:110] Creating Layer relu3
I1111 05:04:52.037688   949 net.cpp:477] relu3 <- conv3
I1111 05:04:52.037699   949 net.cpp:419] relu3 -> conv3 (in-place)
I1111 05:04:52.037713   949 net.cpp:155] Setting up relu3
I1111 05:04:52.037724   949 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 05:04:52.037734   949 layer_factory.hpp:76] Creating layer conv4
I1111 05:04:52.037747   949 net.cpp:110] Creating Layer conv4
I1111 05:04:52.037757   949 net.cpp:477] conv4 <- conv3
I1111 05:04:52.037770   949 net.cpp:433] conv4 -> conv4
I1111 05:04:52.040593   949 net.cpp:155] Setting up conv4
I1111 05:04:52.040616   949 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 05:04:52.040629   949 layer_factory.hpp:76] Creating layer relu4
I1111 05:04:52.040643   949 net.cpp:110] Creating Layer relu4
I1111 05:04:52.040653   949 net.cpp:477] relu4 <- conv4
I1111 05:04:52.040665   949 net.cpp:419] relu4 -> conv4 (in-place)
I1111 05:04:52.040678   949 net.cpp:155] Setting up relu4
I1111 05:04:52.040690   949 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 05:04:52.040700   949 layer_factory.hpp:76] Creating layer conv5
I1111 05:04:52.040714   949 net.cpp:110] Creating Layer conv5
I1111 05:04:52.040724   949 net.cpp:477] conv5 <- conv4
I1111 05:04:52.040735   949 net.cpp:433] conv5 -> conv5
I1111 05:04:52.042629   949 net.cpp:155] Setting up conv5
I1111 05:04:52.042650   949 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 05:04:52.042667   949 layer_factory.hpp:76] Creating layer relu5
I1111 05:04:52.042681   949 net.cpp:110] Creating Layer relu5
I1111 05:04:52.042692   949 net.cpp:477] relu5 <- conv5
I1111 05:04:52.042703   949 net.cpp:419] relu5 -> conv5 (in-place)
I1111 05:04:52.042716   949 net.cpp:155] Setting up relu5
I1111 05:04:52.042728   949 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 05:04:52.042738   949 layer_factory.hpp:76] Creating layer pool5
I1111 05:04:52.042752   949 net.cpp:110] Creating Layer pool5
I1111 05:04:52.042762   949 net.cpp:477] pool5 <- conv5
I1111 05:04:52.042773   949 net.cpp:433] pool5 -> pool5
I1111 05:04:52.042788   949 net.cpp:155] Setting up pool5
I1111 05:04:52.042800   949 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1111 05:04:52.042810   949 layer_factory.hpp:76] Creating layer fc6
I1111 05:04:52.042824   949 net.cpp:110] Creating Layer fc6
I1111 05:04:52.042834   949 net.cpp:477] fc6 <- pool5
I1111 05:04:52.042845   949 net.cpp:433] fc6 -> fc6
I1111 05:04:52.201954   949 net.cpp:155] Setting up fc6
I1111 05:04:52.202024   949 net.cpp:163] Top shape: 10 4096 (40960)
I1111 05:04:52.202047   949 layer_factory.hpp:76] Creating layer relu6
I1111 05:04:52.202072   949 net.cpp:110] Creating Layer relu6
I1111 05:04:52.202085   949 net.cpp:477] relu6 <- fc6
I1111 05:04:52.202128   949 net.cpp:419] relu6 -> fc6 (in-place)
I1111 05:04:52.202149   949 net.cpp:155] Setting up relu6
I1111 05:04:52.202162   949 net.cpp:163] Top shape: 10 4096 (40960)
I1111 05:04:52.202172   949 layer_factory.hpp:76] Creating layer drop6
I1111 05:04:52.202186   949 net.cpp:110] Creating Layer drop6
I1111 05:04:52.202196   949 net.cpp:477] drop6 <- fc6
I1111 05:04:52.202208   949 net.cpp:419] drop6 -> fc6 (in-place)
I1111 05:04:52.202224   949 net.cpp:155] Setting up drop6
I1111 05:04:52.202236   949 net.cpp:163] Top shape: 10 4096 (40960)
I1111 05:04:52.202247   949 layer_factory.hpp:76] Creating layer fc7
I1111 05:04:52.202261   949 net.cpp:110] Creating Layer fc7
I1111 05:04:52.202272   949 net.cpp:477] fc7 <- fc6
I1111 05:04:52.202286   949 net.cpp:433] fc7 -> fc7
I1111 05:04:52.272790   949 net.cpp:155] Setting up fc7
I1111 05:04:52.272860   949 net.cpp:163] Top shape: 10 4096 (40960)
I1111 05:04:52.272881   949 layer_factory.hpp:76] Creating layer relu7
I1111 05:04:52.272904   949 net.cpp:110] Creating Layer relu7
I1111 05:04:52.272917   949 net.cpp:477] relu7 <- fc7
I1111 05:04:52.272933   949 net.cpp:419] relu7 -> fc7 (in-place)
I1111 05:04:52.272951   949 net.cpp:155] Setting up relu7
I1111 05:04:52.272964   949 net.cpp:163] Top shape: 10 4096 (40960)
I1111 05:04:52.272974   949 layer_factory.hpp:76] Creating layer drop7
I1111 05:04:52.272989   949 net.cpp:110] Creating Layer drop7
I1111 05:04:52.272999   949 net.cpp:477] drop7 <- fc7
I1111 05:04:52.273010   949 net.cpp:419] drop7 -> fc7 (in-place)
I1111 05:04:52.273026   949 net.cpp:155] Setting up drop7
I1111 05:04:52.273038   949 net.cpp:163] Top shape: 10 4096 (40960)
I1111 05:04:52.273049   949 layer_factory.hpp:76] Creating layer fc8
I1111 05:04:52.273063   949 net.cpp:110] Creating Layer fc8
I1111 05:04:52.273073   949 net.cpp:477] fc8 <- fc7
I1111 05:04:52.273087   949 net.cpp:433] fc8 -> fc8
I1111 05:04:52.290122   949 net.cpp:155] Setting up fc8
I1111 05:04:52.290164   949 net.cpp:163] Top shape: 10 1000 (10000)
I1111 05:04:52.290184   949 layer_factory.hpp:76] Creating layer prob
I1111 05:04:52.290200   949 net.cpp:110] Creating Layer prob
I1111 05:04:52.290212   949 net.cpp:477] prob <- fc8
I1111 05:04:52.290227   949 net.cpp:433] prob -> prob
I1111 05:04:52.290248   949 net.cpp:155] Setting up prob
I1111 05:04:52.290261   949 net.cpp:163] Top shape: 10 1000 (10000)
I1111 05:04:52.290271   949 net.cpp:240] prob does not need backward computation.
I1111 05:04:52.290282   949 net.cpp:240] fc8 does not need backward computation.
I1111 05:04:52.290292   949 net.cpp:240] drop7 does not need backward computation.
I1111 05:04:52.290302   949 net.cpp:240] relu7 does not need backward computation.
I1111 05:04:52.290313   949 net.cpp:240] fc7 does not need backward computation.
I1111 05:04:52.290323   949 net.cpp:240] drop6 does not need backward computation.
I1111 05:04:52.290333   949 net.cpp:240] relu6 does not need backward computation.
I1111 05:04:52.290343   949 net.cpp:240] fc6 does not need backward computation.
I1111 05:04:52.290354   949 net.cpp:240] pool5 does not need backward computation.
I1111 05:04:52.290364   949 net.cpp:240] relu5 does not need backward computation.
I1111 05:04:52.290374   949 net.cpp:240] conv5 does not need backward computation.
I1111 05:04:52.290385   949 net.cpp:240] relu4 does not need backward computation.
I1111 05:04:52.290395   949 net.cpp:240] conv4 does not need backward computation.
I1111 05:04:52.290405   949 net.cpp:240] relu3 does not need backward computation.
I1111 05:04:52.290415   949 net.cpp:240] conv3 does not need backward computation.
I1111 05:04:52.290426   949 net.cpp:240] norm2 does not need backward computation.
I1111 05:04:52.290436   949 net.cpp:240] pool2 does not need backward computation.
I1111 05:04:52.290446   949 net.cpp:240] relu2 does not need backward computation.
I1111 05:04:52.290457   949 net.cpp:240] conv2 does not need backward computation.
I1111 05:04:52.290467   949 net.cpp:240] norm1 does not need backward computation.
I1111 05:04:52.290501   949 net.cpp:240] pool1 does not need backward computation.
I1111 05:04:52.290513   949 net.cpp:240] relu1 does not need backward computation.
I1111 05:04:52.290524   949 net.cpp:240] conv1 does not need backward computation.
I1111 05:04:52.290534   949 net.cpp:283] This network produces output prob
I1111 05:04:52.290555   949 net.cpp:297] Network initialization done.
I1111 05:04:52.290565   949 net.cpp:298] Memory required for data: 62497920
I1111 05:04:53.258813   949 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1111 05:04:53.258865   949 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1111 05:04:53.258877   949 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1111 05:04:53.258885   949 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1111 05:04:53.764513   949 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
58.152.249.17:44041 - - [11/Nov/2015 05:04:54] "HTTP/1.1 POST /resources/1" - 200 OK
Traceback (most recent call last):
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 237, in process
    return p(lambda: process(processors))
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 565, in processor
    h()
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 661, in __call__
    self.check(mod)
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 680, in check
    reload(mod)
  File "/root/ds210_capstone/caffe_script/service/baseline.py", line 1, in <module>
    empty
NameError: name 'empty' is not defined

58.152.249.17:40473 - - [11/Nov/2015 05:18:55] "HTTP/1.1 POST /resources/1" - 500 Internal Server Error
Traceback (most recent call last):
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 237, in process
    return p(lambda: process(processors))
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 565, in processor
    h()
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 661, in __call__
    self.check(mod)
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 680, in check
    reload(mod)
  File "/root/ds210_capstone/caffe_script/service/baseline.py", line 1, in <module>
    empty
NameError: name 'empty' is not defined

58.152.249.17:37484 - - [11/Nov/2015 05:19:02] "HTTP/1.1 POST /resources/1" - 500 Internal Server Error
I1111 05:19:11.859071   942 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1111 05:19:11.859189   942 net.cpp:435] Input 0 -> data
I1111 05:19:11.859223   942 layer_factory.hpp:76] Creating layer conv1
I1111 05:19:11.859243   942 net.cpp:110] Creating Layer conv1
I1111 05:19:11.859254   942 net.cpp:477] conv1 <- data
I1111 05:19:11.859268   942 net.cpp:433] conv1 -> conv1
I1111 05:19:11.859330   942 net.cpp:155] Setting up conv1
I1111 05:19:11.859351   942 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1111 05:19:11.859372   942 layer_factory.hpp:76] Creating layer relu1
I1111 05:19:11.859387   942 net.cpp:110] Creating Layer relu1
I1111 05:19:11.859398   942 net.cpp:477] relu1 <- conv1
I1111 05:19:11.859410   942 net.cpp:419] relu1 -> conv1 (in-place)
I1111 05:19:11.859423   942 net.cpp:155] Setting up relu1
I1111 05:19:11.859436   942 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1111 05:19:11.859447   942 layer_factory.hpp:76] Creating layer pool1
I1111 05:19:11.859459   942 net.cpp:110] Creating Layer pool1
I1111 05:19:11.859469   942 net.cpp:477] pool1 <- conv1
I1111 05:19:11.859480   942 net.cpp:433] pool1 -> pool1
I1111 05:19:11.859498   942 net.cpp:155] Setting up pool1
I1111 05:19:11.859511   942 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1111 05:19:11.859521   942 layer_factory.hpp:76] Creating layer norm1
I1111 05:19:11.859534   942 net.cpp:110] Creating Layer norm1
I1111 05:19:11.859544   942 net.cpp:477] norm1 <- pool1
I1111 05:19:11.859555   942 net.cpp:433] norm1 -> norm1
I1111 05:19:11.859571   942 net.cpp:155] Setting up norm1
I1111 05:19:11.859583   942 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1111 05:19:11.859593   942 layer_factory.hpp:76] Creating layer conv2
I1111 05:19:11.859607   942 net.cpp:110] Creating Layer conv2
I1111 05:19:11.859617   942 net.cpp:477] conv2 <- norm1
I1111 05:19:11.859629   942 net.cpp:433] conv2 -> conv2
I1111 05:19:11.860546   942 net.cpp:155] Setting up conv2
I1111 05:19:11.860566   942 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1111 05:19:11.860582   942 layer_factory.hpp:76] Creating layer relu2
I1111 05:19:11.860596   942 net.cpp:110] Creating Layer relu2
I1111 05:19:11.860605   942 net.cpp:477] relu2 <- conv2
I1111 05:19:11.860617   942 net.cpp:419] relu2 -> conv2 (in-place)
I1111 05:19:11.860630   942 net.cpp:155] Setting up relu2
I1111 05:19:11.860642   942 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1111 05:19:11.860652   942 layer_factory.hpp:76] Creating layer pool2
I1111 05:19:11.860676   942 net.cpp:110] Creating Layer pool2
I1111 05:19:11.860687   942 net.cpp:477] pool2 <- conv2
I1111 05:19:11.860698   942 net.cpp:433] pool2 -> pool2
I1111 05:19:11.860714   942 net.cpp:155] Setting up pool2
I1111 05:19:11.860726   942 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 05:19:11.860738   942 layer_factory.hpp:76] Creating layer norm2
I1111 05:19:11.860749   942 net.cpp:110] Creating Layer norm2
I1111 05:19:11.860759   942 net.cpp:477] norm2 <- pool2
I1111 05:19:11.860771   942 net.cpp:433] norm2 -> norm2
I1111 05:19:11.860785   942 net.cpp:155] Setting up norm2
I1111 05:19:11.860797   942 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 05:19:11.860807   942 layer_factory.hpp:76] Creating layer conv3
I1111 05:19:11.860821   942 net.cpp:110] Creating Layer conv3
I1111 05:19:11.860831   942 net.cpp:477] conv3 <- norm2
I1111 05:19:11.860843   942 net.cpp:433] conv3 -> conv3
I1111 05:19:11.864545   942 net.cpp:155] Setting up conv3
I1111 05:19:11.864567   942 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 05:19:11.864583   942 layer_factory.hpp:76] Creating layer relu3
I1111 05:19:11.864598   942 net.cpp:110] Creating Layer relu3
I1111 05:19:11.864608   942 net.cpp:477] relu3 <- conv3
I1111 05:19:11.864619   942 net.cpp:419] relu3 -> conv3 (in-place)
I1111 05:19:11.864632   942 net.cpp:155] Setting up relu3
I1111 05:19:11.864645   942 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 05:19:11.864655   942 layer_factory.hpp:76] Creating layer conv4
I1111 05:19:11.864667   942 net.cpp:110] Creating Layer conv4
I1111 05:19:11.864677   942 net.cpp:477] conv4 <- conv3
I1111 05:19:11.864689   942 net.cpp:433] conv4 -> conv4
I1111 05:19:11.867491   942 net.cpp:155] Setting up conv4
I1111 05:19:11.867512   942 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 05:19:11.867527   942 layer_factory.hpp:76] Creating layer relu4
I1111 05:19:11.867539   942 net.cpp:110] Creating Layer relu4
I1111 05:19:11.867549   942 net.cpp:477] relu4 <- conv4
I1111 05:19:11.867561   942 net.cpp:419] relu4 -> conv4 (in-place)
I1111 05:19:11.867574   942 net.cpp:155] Setting up relu4
I1111 05:19:11.867586   942 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 05:19:11.867596   942 layer_factory.hpp:76] Creating layer conv5
I1111 05:19:11.867609   942 net.cpp:110] Creating Layer conv5
I1111 05:19:11.867619   942 net.cpp:477] conv5 <- conv4
I1111 05:19:11.867631   942 net.cpp:433] conv5 -> conv5
I1111 05:19:11.869487   942 net.cpp:155] Setting up conv5
I1111 05:19:11.869504   942 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 05:19:11.869521   942 layer_factory.hpp:76] Creating layer relu5
I1111 05:19:11.869534   942 net.cpp:110] Creating Layer relu5
I1111 05:19:11.869544   942 net.cpp:477] relu5 <- conv5
I1111 05:19:11.869556   942 net.cpp:419] relu5 -> conv5 (in-place)
I1111 05:19:11.869570   942 net.cpp:155] Setting up relu5
I1111 05:19:11.869580   942 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 05:19:11.869590   942 layer_factory.hpp:76] Creating layer pool5
I1111 05:19:11.869602   942 net.cpp:110] Creating Layer pool5
I1111 05:19:11.869612   942 net.cpp:477] pool5 <- conv5
I1111 05:19:11.869626   942 net.cpp:433] pool5 -> pool5
I1111 05:19:11.869639   942 net.cpp:155] Setting up pool5
I1111 05:19:11.869652   942 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1111 05:19:11.869663   942 layer_factory.hpp:76] Creating layer fc6
I1111 05:19:11.869675   942 net.cpp:110] Creating Layer fc6
I1111 05:19:11.869685   942 net.cpp:477] fc6 <- pool5
I1111 05:19:11.869698   942 net.cpp:433] fc6 -> fc6
I1111 05:19:12.028583   942 net.cpp:155] Setting up fc6
I1111 05:19:12.028656   942 net.cpp:163] Top shape: 10 4096 (40960)
I1111 05:19:12.028679   942 layer_factory.hpp:76] Creating layer relu6
I1111 05:19:12.028707   942 net.cpp:110] Creating Layer relu6
I1111 05:19:12.028720   942 net.cpp:477] relu6 <- fc6
I1111 05:19:12.028735   942 net.cpp:419] relu6 -> fc6 (in-place)
I1111 05:19:12.028758   942 net.cpp:155] Setting up relu6
I1111 05:19:12.028769   942 net.cpp:163] Top shape: 10 4096 (40960)
I1111 05:19:12.028810   942 layer_factory.hpp:76] Creating layer drop6
I1111 05:19:12.028826   942 net.cpp:110] Creating Layer drop6
I1111 05:19:12.028836   942 net.cpp:477] drop6 <- fc6
I1111 05:19:12.028848   942 net.cpp:419] drop6 -> fc6 (in-place)
I1111 05:19:12.028864   942 net.cpp:155] Setting up drop6
I1111 05:19:12.028877   942 net.cpp:163] Top shape: 10 4096 (40960)
I1111 05:19:12.028887   942 layer_factory.hpp:76] Creating layer fc7
I1111 05:19:12.028903   942 net.cpp:110] Creating Layer fc7
I1111 05:19:12.028913   942 net.cpp:477] fc7 <- fc6
I1111 05:19:12.028925   942 net.cpp:433] fc7 -> fc7
I1111 05:19:12.099063   942 net.cpp:155] Setting up fc7
I1111 05:19:12.099129   942 net.cpp:163] Top shape: 10 4096 (40960)
I1111 05:19:12.099153   942 layer_factory.hpp:76] Creating layer relu7
I1111 05:19:12.099174   942 net.cpp:110] Creating Layer relu7
I1111 05:19:12.099187   942 net.cpp:477] relu7 <- fc7
I1111 05:19:12.099203   942 net.cpp:419] relu7 -> fc7 (in-place)
I1111 05:19:12.099223   942 net.cpp:155] Setting up relu7
I1111 05:19:12.099236   942 net.cpp:163] Top shape: 10 4096 (40960)
I1111 05:19:12.099246   942 layer_factory.hpp:76] Creating layer drop7
I1111 05:19:12.099261   942 net.cpp:110] Creating Layer drop7
I1111 05:19:12.099272   942 net.cpp:477] drop7 <- fc7
I1111 05:19:12.099284   942 net.cpp:419] drop7 -> fc7 (in-place)
I1111 05:19:12.099299   942 net.cpp:155] Setting up drop7
I1111 05:19:12.099313   942 net.cpp:163] Top shape: 10 4096 (40960)
I1111 05:19:12.099323   942 layer_factory.hpp:76] Creating layer fc8
I1111 05:19:12.099336   942 net.cpp:110] Creating Layer fc8
I1111 05:19:12.099347   942 net.cpp:477] fc8 <- fc7
I1111 05:19:12.099359   942 net.cpp:433] fc8 -> fc8
I1111 05:19:12.116242   942 net.cpp:155] Setting up fc8
I1111 05:19:12.116278   942 net.cpp:163] Top shape: 10 1000 (10000)
I1111 05:19:12.116293   942 layer_factory.hpp:76] Creating layer prob
I1111 05:19:12.116308   942 net.cpp:110] Creating Layer prob
I1111 05:19:12.116320   942 net.cpp:477] prob <- fc8
I1111 05:19:12.116334   942 net.cpp:433] prob -> prob
I1111 05:19:12.116356   942 net.cpp:155] Setting up prob
I1111 05:19:12.116369   942 net.cpp:163] Top shape: 10 1000 (10000)
I1111 05:19:12.116380   942 net.cpp:240] prob does not need backward computation.
I1111 05:19:12.116390   942 net.cpp:240] fc8 does not need backward computation.
I1111 05:19:12.116400   942 net.cpp:240] drop7 does not need backward computation.
I1111 05:19:12.116410   942 net.cpp:240] relu7 does not need backward computation.
I1111 05:19:12.116420   942 net.cpp:240] fc7 does not need backward computation.
I1111 05:19:12.116430   942 net.cpp:240] drop6 does not need backward computation.
I1111 05:19:12.116441   942 net.cpp:240] relu6 does not need backward computation.
I1111 05:19:12.116451   942 net.cpp:240] fc6 does not need backward computation.
I1111 05:19:12.116461   942 net.cpp:240] pool5 does not need backward computation.
I1111 05:19:12.116472   942 net.cpp:240] relu5 does not need backward computation.
I1111 05:19:12.116482   942 net.cpp:240] conv5 does not need backward computation.
I1111 05:19:12.116492   942 net.cpp:240] relu4 does not need backward computation.
I1111 05:19:12.116503   942 net.cpp:240] conv4 does not need backward computation.
I1111 05:19:12.116513   942 net.cpp:240] relu3 does not need backward computation.
I1111 05:19:12.116523   942 net.cpp:240] conv3 does not need backward computation.
I1111 05:19:12.116533   942 net.cpp:240] norm2 does not need backward computation.
I1111 05:19:12.116544   942 net.cpp:240] pool2 does not need backward computation.
I1111 05:19:12.116554   942 net.cpp:240] relu2 does not need backward computation.
I1111 05:19:12.116564   942 net.cpp:240] conv2 does not need backward computation.
I1111 05:19:12.116575   942 net.cpp:240] norm1 does not need backward computation.
I1111 05:19:12.116585   942 net.cpp:240] pool1 does not need backward computation.
I1111 05:19:12.116596   942 net.cpp:240] relu1 does not need backward computation.
I1111 05:19:12.116606   942 net.cpp:240] conv1 does not need backward computation.
I1111 05:19:12.116641   942 net.cpp:283] This network produces output prob
I1111 05:19:12.116664   942 net.cpp:297] Network initialization done.
I1111 05:19:12.116673   942 net.cpp:298] Memory required for data: 62497920
I1111 05:19:13.083150   942 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1111 05:19:13.083201   942 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1111 05:19:13.083211   942 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1111 05:19:13.083221   942 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1111 05:19:13.588558   942 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
58.152.249.17:44341 - - [11/Nov/2015 05:19:14] "HTTP/1.1 POST /resources/1" - 200 OK
I1111 05:48:10.624186   943 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1111 05:48:10.624299   943 net.cpp:435] Input 0 -> data
I1111 05:48:10.624331   943 layer_factory.hpp:76] Creating layer conv1
I1111 05:48:10.624351   943 net.cpp:110] Creating Layer conv1
I1111 05:48:10.624361   943 net.cpp:477] conv1 <- data
I1111 05:48:10.624375   943 net.cpp:433] conv1 -> conv1
I1111 05:48:10.624435   943 net.cpp:155] Setting up conv1
I1111 05:48:10.624457   943 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1111 05:48:10.624480   943 layer_factory.hpp:76] Creating layer relu1
I1111 05:48:10.624495   943 net.cpp:110] Creating Layer relu1
I1111 05:48:10.624505   943 net.cpp:477] relu1 <- conv1
I1111 05:48:10.624517   943 net.cpp:419] relu1 -> conv1 (in-place)
I1111 05:48:10.624531   943 net.cpp:155] Setting up relu1
I1111 05:48:10.624543   943 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1111 05:48:10.624553   943 layer_factory.hpp:76] Creating layer pool1
I1111 05:48:10.624567   943 net.cpp:110] Creating Layer pool1
I1111 05:48:10.624577   943 net.cpp:477] pool1 <- conv1
I1111 05:48:10.624588   943 net.cpp:433] pool1 -> pool1
I1111 05:48:10.624605   943 net.cpp:155] Setting up pool1
I1111 05:48:10.624619   943 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1111 05:48:10.624629   943 layer_factory.hpp:76] Creating layer norm1
I1111 05:48:10.624642   943 net.cpp:110] Creating Layer norm1
I1111 05:48:10.624652   943 net.cpp:477] norm1 <- pool1
I1111 05:48:10.624665   943 net.cpp:433] norm1 -> norm1
I1111 05:48:10.624680   943 net.cpp:155] Setting up norm1
I1111 05:48:10.624692   943 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1111 05:48:10.624702   943 layer_factory.hpp:76] Creating layer conv2
I1111 05:48:10.624716   943 net.cpp:110] Creating Layer conv2
I1111 05:48:10.624725   943 net.cpp:477] conv2 <- norm1
I1111 05:48:10.624737   943 net.cpp:433] conv2 -> conv2
I1111 05:48:10.625721   943 net.cpp:155] Setting up conv2
I1111 05:48:10.625741   943 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1111 05:48:10.625757   943 layer_factory.hpp:76] Creating layer relu2
I1111 05:48:10.625771   943 net.cpp:110] Creating Layer relu2
I1111 05:48:10.625782   943 net.cpp:477] relu2 <- conv2
I1111 05:48:10.625793   943 net.cpp:419] relu2 -> conv2 (in-place)
I1111 05:48:10.625807   943 net.cpp:155] Setting up relu2
I1111 05:48:10.625818   943 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1111 05:48:10.625828   943 layer_factory.hpp:76] Creating layer pool2
I1111 05:48:10.625840   943 net.cpp:110] Creating Layer pool2
I1111 05:48:10.625849   943 net.cpp:477] pool2 <- conv2
I1111 05:48:10.625861   943 net.cpp:433] pool2 -> pool2
I1111 05:48:10.625876   943 net.cpp:155] Setting up pool2
I1111 05:48:10.625888   943 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 05:48:10.625898   943 layer_factory.hpp:76] Creating layer norm2
I1111 05:48:10.625911   943 net.cpp:110] Creating Layer norm2
I1111 05:48:10.625921   943 net.cpp:477] norm2 <- pool2
I1111 05:48:10.625932   943 net.cpp:433] norm2 -> norm2
I1111 05:48:10.625946   943 net.cpp:155] Setting up norm2
I1111 05:48:10.625958   943 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 05:48:10.625968   943 layer_factory.hpp:76] Creating layer conv3
I1111 05:48:10.625982   943 net.cpp:110] Creating Layer conv3
I1111 05:48:10.625991   943 net.cpp:477] conv3 <- norm2
I1111 05:48:10.626003   943 net.cpp:433] conv3 -> conv3
I1111 05:48:10.629678   943 net.cpp:155] Setting up conv3
I1111 05:48:10.629698   943 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 05:48:10.629715   943 layer_factory.hpp:76] Creating layer relu3
I1111 05:48:10.629729   943 net.cpp:110] Creating Layer relu3
I1111 05:48:10.629739   943 net.cpp:477] relu3 <- conv3
I1111 05:48:10.629750   943 net.cpp:419] relu3 -> conv3 (in-place)
I1111 05:48:10.629763   943 net.cpp:155] Setting up relu3
I1111 05:48:10.629776   943 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 05:48:10.629786   943 layer_factory.hpp:76] Creating layer conv4
I1111 05:48:10.629798   943 net.cpp:110] Creating Layer conv4
I1111 05:48:10.629808   943 net.cpp:477] conv4 <- conv3
I1111 05:48:10.629820   943 net.cpp:433] conv4 -> conv4
I1111 05:48:10.632571   943 net.cpp:155] Setting up conv4
I1111 05:48:10.632592   943 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 05:48:10.632607   943 layer_factory.hpp:76] Creating layer relu4
I1111 05:48:10.632619   943 net.cpp:110] Creating Layer relu4
I1111 05:48:10.632629   943 net.cpp:477] relu4 <- conv4
I1111 05:48:10.632642   943 net.cpp:419] relu4 -> conv4 (in-place)
I1111 05:48:10.632654   943 net.cpp:155] Setting up relu4
I1111 05:48:10.632666   943 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 05:48:10.632676   943 layer_factory.hpp:76] Creating layer conv5
I1111 05:48:10.632689   943 net.cpp:110] Creating Layer conv5
I1111 05:48:10.632699   943 net.cpp:477] conv5 <- conv4
I1111 05:48:10.632711   943 net.cpp:433] conv5 -> conv5
I1111 05:48:10.634522   943 net.cpp:155] Setting up conv5
I1111 05:48:10.634541   943 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 05:48:10.634557   943 layer_factory.hpp:76] Creating layer relu5
I1111 05:48:10.634570   943 net.cpp:110] Creating Layer relu5
I1111 05:48:10.634595   943 net.cpp:477] relu5 <- conv5
I1111 05:48:10.634608   943 net.cpp:419] relu5 -> conv5 (in-place)
I1111 05:48:10.634621   943 net.cpp:155] Setting up relu5
I1111 05:48:10.634634   943 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 05:48:10.634644   943 layer_factory.hpp:76] Creating layer pool5
I1111 05:48:10.634655   943 net.cpp:110] Creating Layer pool5
I1111 05:48:10.634665   943 net.cpp:477] pool5 <- conv5
I1111 05:48:10.634677   943 net.cpp:433] pool5 -> pool5
I1111 05:48:10.634692   943 net.cpp:155] Setting up pool5
I1111 05:48:10.634706   943 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1111 05:48:10.634716   943 layer_factory.hpp:76] Creating layer fc6
I1111 05:48:10.634729   943 net.cpp:110] Creating Layer fc6
I1111 05:48:10.634739   943 net.cpp:477] fc6 <- pool5
I1111 05:48:10.634752   943 net.cpp:433] fc6 -> fc6
I1111 05:48:10.794685   943 net.cpp:155] Setting up fc6
I1111 05:48:10.794749   943 net.cpp:163] Top shape: 10 4096 (40960)
I1111 05:48:10.794770   943 layer_factory.hpp:76] Creating layer relu6
I1111 05:48:10.794796   943 net.cpp:110] Creating Layer relu6
I1111 05:48:10.794809   943 net.cpp:477] relu6 <- fc6
I1111 05:48:10.794824   943 net.cpp:419] relu6 -> fc6 (in-place)
I1111 05:48:10.794843   943 net.cpp:155] Setting up relu6
I1111 05:48:10.794855   943 net.cpp:163] Top shape: 10 4096 (40960)
I1111 05:48:10.794865   943 layer_factory.hpp:76] Creating layer drop6
I1111 05:48:10.794880   943 net.cpp:110] Creating Layer drop6
I1111 05:48:10.794890   943 net.cpp:477] drop6 <- fc6
I1111 05:48:10.794903   943 net.cpp:419] drop6 -> fc6 (in-place)
I1111 05:48:10.794919   943 net.cpp:155] Setting up drop6
I1111 05:48:10.794930   943 net.cpp:163] Top shape: 10 4096 (40960)
I1111 05:48:10.794940   943 layer_factory.hpp:76] Creating layer fc7
I1111 05:48:10.794956   943 net.cpp:110] Creating Layer fc7
I1111 05:48:10.794966   943 net.cpp:477] fc7 <- fc6
I1111 05:48:10.794978   943 net.cpp:433] fc7 -> fc7
I1111 05:48:10.865931   943 net.cpp:155] Setting up fc7
I1111 05:48:10.865998   943 net.cpp:163] Top shape: 10 4096 (40960)
I1111 05:48:10.866021   943 layer_factory.hpp:76] Creating layer relu7
I1111 05:48:10.866045   943 net.cpp:110] Creating Layer relu7
I1111 05:48:10.866058   943 net.cpp:477] relu7 <- fc7
I1111 05:48:10.866075   943 net.cpp:419] relu7 -> fc7 (in-place)
I1111 05:48:10.866094   943 net.cpp:155] Setting up relu7
I1111 05:48:10.866106   943 net.cpp:163] Top shape: 10 4096 (40960)
I1111 05:48:10.866116   943 layer_factory.hpp:76] Creating layer drop7
I1111 05:48:10.866132   943 net.cpp:110] Creating Layer drop7
I1111 05:48:10.866142   943 net.cpp:477] drop7 <- fc7
I1111 05:48:10.866153   943 net.cpp:419] drop7 -> fc7 (in-place)
I1111 05:48:10.866168   943 net.cpp:155] Setting up drop7
I1111 05:48:10.866180   943 net.cpp:163] Top shape: 10 4096 (40960)
I1111 05:48:10.866191   943 layer_factory.hpp:76] Creating layer fc8
I1111 05:48:10.866206   943 net.cpp:110] Creating Layer fc8
I1111 05:48:10.866216   943 net.cpp:477] fc8 <- fc7
I1111 05:48:10.866230   943 net.cpp:433] fc8 -> fc8
I1111 05:48:10.883280   943 net.cpp:155] Setting up fc8
I1111 05:48:10.883317   943 net.cpp:163] Top shape: 10 1000 (10000)
I1111 05:48:10.883334   943 layer_factory.hpp:76] Creating layer prob
I1111 05:48:10.883352   943 net.cpp:110] Creating Layer prob
I1111 05:48:10.883363   943 net.cpp:477] prob <- fc8
I1111 05:48:10.883378   943 net.cpp:433] prob -> prob
I1111 05:48:10.883400   943 net.cpp:155] Setting up prob
I1111 05:48:10.883412   943 net.cpp:163] Top shape: 10 1000 (10000)
I1111 05:48:10.883424   943 net.cpp:240] prob does not need backward computation.
I1111 05:48:10.883433   943 net.cpp:240] fc8 does not need backward computation.
I1111 05:48:10.883443   943 net.cpp:240] drop7 does not need backward computation.
I1111 05:48:10.883453   943 net.cpp:240] relu7 does not need backward computation.
I1111 05:48:10.883463   943 net.cpp:240] fc7 does not need backward computation.
I1111 05:48:10.883473   943 net.cpp:240] drop6 does not need backward computation.
I1111 05:48:10.883484   943 net.cpp:240] relu6 does not need backward computation.
I1111 05:48:10.883493   943 net.cpp:240] fc6 does not need backward computation.
I1111 05:48:10.883504   943 net.cpp:240] pool5 does not need backward computation.
I1111 05:48:10.883514   943 net.cpp:240] relu5 does not need backward computation.
I1111 05:48:10.883524   943 net.cpp:240] conv5 does not need backward computation.
I1111 05:48:10.883535   943 net.cpp:240] relu4 does not need backward computation.
I1111 05:48:10.883545   943 net.cpp:240] conv4 does not need backward computation.
I1111 05:48:10.883556   943 net.cpp:240] relu3 does not need backward computation.
I1111 05:48:10.883568   943 net.cpp:240] conv3 does not need backward computation.
I1111 05:48:10.883577   943 net.cpp:240] norm2 does not need backward computation.
I1111 05:48:10.883589   943 net.cpp:240] pool2 does not need backward computation.
I1111 05:48:10.883599   943 net.cpp:240] relu2 does not need backward computation.
I1111 05:48:10.883610   943 net.cpp:240] conv2 does not need backward computation.
I1111 05:48:10.883621   943 net.cpp:240] norm1 does not need backward computation.
I1111 05:48:10.883631   943 net.cpp:240] pool1 does not need backward computation.
I1111 05:48:10.883642   943 net.cpp:240] relu1 does not need backward computation.
I1111 05:48:10.883652   943 net.cpp:240] conv1 does not need backward computation.
I1111 05:48:10.883662   943 net.cpp:283] This network produces output prob
I1111 05:48:10.883683   943 net.cpp:297] Network initialization done.
I1111 05:48:10.883693   943 net.cpp:298] Memory required for data: 62497920
I1111 05:48:11.853232   943 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1111 05:48:11.853282   943 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1111 05:48:11.853293   943 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1111 05:48:11.853302   943 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1111 05:48:12.357714   943 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
58.152.249.17:33111 - - [11/Nov/2015 05:48:13] "HTTP/1.1 POST /resources/1" - 200 OK
I1111 18:54:38.965714   944 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1111 18:54:38.965826   944 net.cpp:435] Input 0 -> data
I1111 18:54:38.965860   944 layer_factory.hpp:76] Creating layer conv1
I1111 18:54:38.965879   944 net.cpp:110] Creating Layer conv1
I1111 18:54:38.965890   944 net.cpp:477] conv1 <- data
I1111 18:54:38.965904   944 net.cpp:433] conv1 -> conv1
I1111 18:54:38.965965   944 net.cpp:155] Setting up conv1
I1111 18:54:38.965986   944 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1111 18:54:38.966008   944 layer_factory.hpp:76] Creating layer relu1
I1111 18:54:38.966024   944 net.cpp:110] Creating Layer relu1
I1111 18:54:38.966035   944 net.cpp:477] relu1 <- conv1
I1111 18:54:38.966048   944 net.cpp:419] relu1 -> conv1 (in-place)
I1111 18:54:38.966061   944 net.cpp:155] Setting up relu1
I1111 18:54:38.966073   944 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1111 18:54:38.966084   944 layer_factory.hpp:76] Creating layer pool1
I1111 18:54:38.966096   944 net.cpp:110] Creating Layer pool1
I1111 18:54:38.966106   944 net.cpp:477] pool1 <- conv1
I1111 18:54:38.966119   944 net.cpp:433] pool1 -> pool1
I1111 18:54:38.966136   944 net.cpp:155] Setting up pool1
I1111 18:54:38.966150   944 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1111 18:54:38.966159   944 layer_factory.hpp:76] Creating layer norm1
I1111 18:54:38.966172   944 net.cpp:110] Creating Layer norm1
I1111 18:54:38.966182   944 net.cpp:477] norm1 <- pool1
I1111 18:54:38.966194   944 net.cpp:433] norm1 -> norm1
I1111 18:54:38.966209   944 net.cpp:155] Setting up norm1
I1111 18:54:38.966222   944 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1111 18:54:38.966233   944 layer_factory.hpp:76] Creating layer conv2
I1111 18:54:38.966245   944 net.cpp:110] Creating Layer conv2
I1111 18:54:38.966266   944 net.cpp:477] conv2 <- norm1
I1111 18:54:38.966280   944 net.cpp:433] conv2 -> conv2
I1111 18:54:38.967242   944 net.cpp:155] Setting up conv2
I1111 18:54:38.967262   944 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1111 18:54:38.967279   944 layer_factory.hpp:76] Creating layer relu2
I1111 18:54:38.967293   944 net.cpp:110] Creating Layer relu2
I1111 18:54:38.967303   944 net.cpp:477] relu2 <- conv2
I1111 18:54:38.967315   944 net.cpp:419] relu2 -> conv2 (in-place)
I1111 18:54:38.967329   944 net.cpp:155] Setting up relu2
I1111 18:54:38.967339   944 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1111 18:54:38.967350   944 layer_factory.hpp:76] Creating layer pool2
I1111 18:54:38.967361   944 net.cpp:110] Creating Layer pool2
I1111 18:54:38.967371   944 net.cpp:477] pool2 <- conv2
I1111 18:54:38.967383   944 net.cpp:433] pool2 -> pool2
I1111 18:54:38.967398   944 net.cpp:155] Setting up pool2
I1111 18:54:38.967411   944 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 18:54:38.967422   944 layer_factory.hpp:76] Creating layer norm2
I1111 18:54:38.967433   944 net.cpp:110] Creating Layer norm2
I1111 18:54:38.967443   944 net.cpp:477] norm2 <- pool2
I1111 18:54:38.967454   944 net.cpp:433] norm2 -> norm2
I1111 18:54:38.967468   944 net.cpp:155] Setting up norm2
I1111 18:54:38.967480   944 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 18:54:38.967490   944 layer_factory.hpp:76] Creating layer conv3
I1111 18:54:38.967504   944 net.cpp:110] Creating Layer conv3
I1111 18:54:38.967514   944 net.cpp:477] conv3 <- norm2
I1111 18:54:38.967526   944 net.cpp:433] conv3 -> conv3
I1111 18:54:38.971276   944 net.cpp:155] Setting up conv3
I1111 18:54:38.971297   944 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 18:54:38.971313   944 layer_factory.hpp:76] Creating layer relu3
I1111 18:54:38.971328   944 net.cpp:110] Creating Layer relu3
I1111 18:54:38.971338   944 net.cpp:477] relu3 <- conv3
I1111 18:54:38.971349   944 net.cpp:419] relu3 -> conv3 (in-place)
I1111 18:54:38.971362   944 net.cpp:155] Setting up relu3
I1111 18:54:38.971374   944 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 18:54:38.971385   944 layer_factory.hpp:76] Creating layer conv4
I1111 18:54:38.971396   944 net.cpp:110] Creating Layer conv4
I1111 18:54:38.971407   944 net.cpp:477] conv4 <- conv3
I1111 18:54:38.971420   944 net.cpp:433] conv4 -> conv4
I1111 18:54:38.974210   944 net.cpp:155] Setting up conv4
I1111 18:54:38.974230   944 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 18:54:38.974243   944 layer_factory.hpp:76] Creating layer relu4
I1111 18:54:38.974256   944 net.cpp:110] Creating Layer relu4
I1111 18:54:38.974267   944 net.cpp:477] relu4 <- conv4
I1111 18:54:38.974277   944 net.cpp:419] relu4 -> conv4 (in-place)
I1111 18:54:38.974290   944 net.cpp:155] Setting up relu4
I1111 18:54:38.974303   944 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 18:54:38.974313   944 layer_factory.hpp:76] Creating layer conv5
I1111 18:54:38.974325   944 net.cpp:110] Creating Layer conv5
I1111 18:54:38.974335   944 net.cpp:477] conv5 <- conv4
I1111 18:54:38.974346   944 net.cpp:433] conv5 -> conv5
I1111 18:54:38.976223   944 net.cpp:155] Setting up conv5
I1111 18:54:38.976244   944 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 18:54:38.976261   944 layer_factory.hpp:76] Creating layer relu5
I1111 18:54:38.976274   944 net.cpp:110] Creating Layer relu5
I1111 18:54:38.976284   944 net.cpp:477] relu5 <- conv5
I1111 18:54:38.976296   944 net.cpp:419] relu5 -> conv5 (in-place)
I1111 18:54:38.976310   944 net.cpp:155] Setting up relu5
I1111 18:54:38.976321   944 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 18:54:38.976331   944 layer_factory.hpp:76] Creating layer pool5
I1111 18:54:38.976343   944 net.cpp:110] Creating Layer pool5
I1111 18:54:38.976353   944 net.cpp:477] pool5 <- conv5
I1111 18:54:38.976366   944 net.cpp:433] pool5 -> pool5
I1111 18:54:38.976380   944 net.cpp:155] Setting up pool5
I1111 18:54:38.976392   944 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1111 18:54:38.976402   944 layer_factory.hpp:76] Creating layer fc6
I1111 18:54:38.976428   944 net.cpp:110] Creating Layer fc6
I1111 18:54:38.976439   944 net.cpp:477] fc6 <- pool5
I1111 18:54:38.976451   944 net.cpp:433] fc6 -> fc6
I1111 18:54:39.136333   944 net.cpp:155] Setting up fc6
I1111 18:54:39.136399   944 net.cpp:163] Top shape: 10 4096 (40960)
I1111 18:54:39.136422   944 layer_factory.hpp:76] Creating layer relu6
I1111 18:54:39.136450   944 net.cpp:110] Creating Layer relu6
I1111 18:54:39.136462   944 net.cpp:477] relu6 <- fc6
I1111 18:54:39.136479   944 net.cpp:419] relu6 -> fc6 (in-place)
I1111 18:54:39.136499   944 net.cpp:155] Setting up relu6
I1111 18:54:39.136512   944 net.cpp:163] Top shape: 10 4096 (40960)
I1111 18:54:39.136521   944 layer_factory.hpp:76] Creating layer drop6
I1111 18:54:39.136538   944 net.cpp:110] Creating Layer drop6
I1111 18:54:39.136548   944 net.cpp:477] drop6 <- fc6
I1111 18:54:39.136559   944 net.cpp:419] drop6 -> fc6 (in-place)
I1111 18:54:39.136575   944 net.cpp:155] Setting up drop6
I1111 18:54:39.136587   944 net.cpp:163] Top shape: 10 4096 (40960)
I1111 18:54:39.136598   944 layer_factory.hpp:76] Creating layer fc7
I1111 18:54:39.136613   944 net.cpp:110] Creating Layer fc7
I1111 18:54:39.136623   944 net.cpp:477] fc7 <- fc6
I1111 18:54:39.136636   944 net.cpp:433] fc7 -> fc7
I1111 18:54:39.207293   944 net.cpp:155] Setting up fc7
I1111 18:54:39.207357   944 net.cpp:163] Top shape: 10 4096 (40960)
I1111 18:54:39.207381   944 layer_factory.hpp:76] Creating layer relu7
I1111 18:54:39.207403   944 net.cpp:110] Creating Layer relu7
I1111 18:54:39.207417   944 net.cpp:477] relu7 <- fc7
I1111 18:54:39.207432   944 net.cpp:419] relu7 -> fc7 (in-place)
I1111 18:54:39.207453   944 net.cpp:155] Setting up relu7
I1111 18:54:39.207464   944 net.cpp:163] Top shape: 10 4096 (40960)
I1111 18:54:39.207474   944 layer_factory.hpp:76] Creating layer drop7
I1111 18:54:39.207490   944 net.cpp:110] Creating Layer drop7
I1111 18:54:39.207501   944 net.cpp:477] drop7 <- fc7
I1111 18:54:39.207514   944 net.cpp:419] drop7 -> fc7 (in-place)
I1111 18:54:39.207530   944 net.cpp:155] Setting up drop7
I1111 18:54:39.207541   944 net.cpp:163] Top shape: 10 4096 (40960)
I1111 18:54:39.207552   944 layer_factory.hpp:76] Creating layer fc8
I1111 18:54:39.207568   944 net.cpp:110] Creating Layer fc8
I1111 18:54:39.207579   944 net.cpp:477] fc8 <- fc7
I1111 18:54:39.207592   944 net.cpp:433] fc8 -> fc8
I1111 18:54:39.224658   944 net.cpp:155] Setting up fc8
I1111 18:54:39.224695   944 net.cpp:163] Top shape: 10 1000 (10000)
I1111 18:54:39.224714   944 layer_factory.hpp:76] Creating layer prob
I1111 18:54:39.224731   944 net.cpp:110] Creating Layer prob
I1111 18:54:39.224742   944 net.cpp:477] prob <- fc8
I1111 18:54:39.224757   944 net.cpp:433] prob -> prob
I1111 18:54:39.224781   944 net.cpp:155] Setting up prob
I1111 18:54:39.224792   944 net.cpp:163] Top shape: 10 1000 (10000)
I1111 18:54:39.224802   944 net.cpp:240] prob does not need backward computation.
I1111 18:54:39.224813   944 net.cpp:240] fc8 does not need backward computation.
I1111 18:54:39.224823   944 net.cpp:240] drop7 does not need backward computation.
I1111 18:54:39.224833   944 net.cpp:240] relu7 does not need backward computation.
I1111 18:54:39.224843   944 net.cpp:240] fc7 does not need backward computation.
I1111 18:54:39.224853   944 net.cpp:240] drop6 does not need backward computation.
I1111 18:54:39.224864   944 net.cpp:240] relu6 does not need backward computation.
I1111 18:54:39.224874   944 net.cpp:240] fc6 does not need backward computation.
I1111 18:54:39.224884   944 net.cpp:240] pool5 does not need backward computation.
I1111 18:54:39.224895   944 net.cpp:240] relu5 does not need backward computation.
I1111 18:54:39.224905   944 net.cpp:240] conv5 does not need backward computation.
I1111 18:54:39.224915   944 net.cpp:240] relu4 does not need backward computation.
I1111 18:54:39.224925   944 net.cpp:240] conv4 does not need backward computation.
I1111 18:54:39.224936   944 net.cpp:240] relu3 does not need backward computation.
I1111 18:54:39.224946   944 net.cpp:240] conv3 does not need backward computation.
I1111 18:54:39.224982   944 net.cpp:240] norm2 does not need backward computation.
I1111 18:54:39.224994   944 net.cpp:240] pool2 does not need backward computation.
I1111 18:54:39.225005   944 net.cpp:240] relu2 does not need backward computation.
I1111 18:54:39.225015   944 net.cpp:240] conv2 does not need backward computation.
I1111 18:54:39.225025   944 net.cpp:240] norm1 does not need backward computation.
I1111 18:54:39.225036   944 net.cpp:240] pool1 does not need backward computation.
I1111 18:54:39.225047   944 net.cpp:240] relu1 does not need backward computation.
I1111 18:54:39.225057   944 net.cpp:240] conv1 does not need backward computation.
I1111 18:54:39.225067   944 net.cpp:283] This network produces output prob
I1111 18:54:39.225090   944 net.cpp:297] Network initialization done.
I1111 18:54:39.225098   944 net.cpp:298] Memory required for data: 62497920
I1111 18:54:40.193837   944 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1111 18:54:40.193887   944 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1111 18:54:40.193897   944 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1111 18:54:40.193907   944 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1111 18:54:40.700220   944 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
58.152.249.17:44488 - - [11/Nov/2015 18:54:41] "HTTP/1.1 POST /resources/1" - 200 OK
I1111 19:01:11.393514   945 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1111 19:01:11.393626   945 net.cpp:435] Input 0 -> data
I1111 19:01:11.393661   945 layer_factory.hpp:76] Creating layer conv1
I1111 19:01:11.393681   945 net.cpp:110] Creating Layer conv1
I1111 19:01:11.393692   945 net.cpp:477] conv1 <- data
I1111 19:01:11.393705   945 net.cpp:433] conv1 -> conv1
I1111 19:01:11.393767   945 net.cpp:155] Setting up conv1
I1111 19:01:11.393790   945 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1111 19:01:11.393811   945 layer_factory.hpp:76] Creating layer relu1
I1111 19:01:11.393827   945 net.cpp:110] Creating Layer relu1
I1111 19:01:11.393838   945 net.cpp:477] relu1 <- conv1
I1111 19:01:11.393851   945 net.cpp:419] relu1 -> conv1 (in-place)
I1111 19:01:11.393864   945 net.cpp:155] Setting up relu1
I1111 19:01:11.393877   945 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1111 19:01:11.393887   945 layer_factory.hpp:76] Creating layer pool1
I1111 19:01:11.393900   945 net.cpp:110] Creating Layer pool1
I1111 19:01:11.393910   945 net.cpp:477] pool1 <- conv1
I1111 19:01:11.393923   945 net.cpp:433] pool1 -> pool1
I1111 19:01:11.393940   945 net.cpp:155] Setting up pool1
I1111 19:01:11.393952   945 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1111 19:01:11.393964   945 layer_factory.hpp:76] Creating layer norm1
I1111 19:01:11.393977   945 net.cpp:110] Creating Layer norm1
I1111 19:01:11.393987   945 net.cpp:477] norm1 <- pool1
I1111 19:01:11.394000   945 net.cpp:433] norm1 -> norm1
I1111 19:01:11.394014   945 net.cpp:155] Setting up norm1
I1111 19:01:11.394027   945 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1111 19:01:11.394037   945 layer_factory.hpp:76] Creating layer conv2
I1111 19:01:11.394052   945 net.cpp:110] Creating Layer conv2
I1111 19:01:11.394062   945 net.cpp:477] conv2 <- norm1
I1111 19:01:11.394073   945 net.cpp:433] conv2 -> conv2
I1111 19:01:11.395037   945 net.cpp:155] Setting up conv2
I1111 19:01:11.395059   945 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1111 19:01:11.395076   945 layer_factory.hpp:76] Creating layer relu2
I1111 19:01:11.395089   945 net.cpp:110] Creating Layer relu2
I1111 19:01:11.395100   945 net.cpp:477] relu2 <- conv2
I1111 19:01:11.395112   945 net.cpp:419] relu2 -> conv2 (in-place)
I1111 19:01:11.395125   945 net.cpp:155] Setting up relu2
I1111 19:01:11.395136   945 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1111 19:01:11.395146   945 layer_factory.hpp:76] Creating layer pool2
I1111 19:01:11.395159   945 net.cpp:110] Creating Layer pool2
I1111 19:01:11.395169   945 net.cpp:477] pool2 <- conv2
I1111 19:01:11.395180   945 net.cpp:433] pool2 -> pool2
I1111 19:01:11.395196   945 net.cpp:155] Setting up pool2
I1111 19:01:11.395208   945 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 19:01:11.395218   945 layer_factory.hpp:76] Creating layer norm2
I1111 19:01:11.395231   945 net.cpp:110] Creating Layer norm2
I1111 19:01:11.395241   945 net.cpp:477] norm2 <- pool2
I1111 19:01:11.395252   945 net.cpp:433] norm2 -> norm2
I1111 19:01:11.395267   945 net.cpp:155] Setting up norm2
I1111 19:01:11.395279   945 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 19:01:11.395289   945 layer_factory.hpp:76] Creating layer conv3
I1111 19:01:11.395303   945 net.cpp:110] Creating Layer conv3
I1111 19:01:11.395313   945 net.cpp:477] conv3 <- norm2
I1111 19:01:11.395325   945 net.cpp:433] conv3 -> conv3
I1111 19:01:11.399081   945 net.cpp:155] Setting up conv3
I1111 19:01:11.399116   945 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 19:01:11.399135   945 layer_factory.hpp:76] Creating layer relu3
I1111 19:01:11.399149   945 net.cpp:110] Creating Layer relu3
I1111 19:01:11.399159   945 net.cpp:477] relu3 <- conv3
I1111 19:01:11.399171   945 net.cpp:419] relu3 -> conv3 (in-place)
I1111 19:01:11.399185   945 net.cpp:155] Setting up relu3
I1111 19:01:11.399197   945 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 19:01:11.399207   945 layer_factory.hpp:76] Creating layer conv4
I1111 19:01:11.399220   945 net.cpp:110] Creating Layer conv4
I1111 19:01:11.399230   945 net.cpp:477] conv4 <- conv3
I1111 19:01:11.399242   945 net.cpp:433] conv4 -> conv4
I1111 19:01:11.402036   945 net.cpp:155] Setting up conv4
I1111 19:01:11.402056   945 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 19:01:11.402070   945 layer_factory.hpp:76] Creating layer relu4
I1111 19:01:11.402083   945 net.cpp:110] Creating Layer relu4
I1111 19:01:11.402093   945 net.cpp:477] relu4 <- conv4
I1111 19:01:11.402106   945 net.cpp:419] relu4 -> conv4 (in-place)
I1111 19:01:11.402118   945 net.cpp:155] Setting up relu4
I1111 19:01:11.402130   945 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 19:01:11.402140   945 layer_factory.hpp:76] Creating layer conv5
I1111 19:01:11.402153   945 net.cpp:110] Creating Layer conv5
I1111 19:01:11.402163   945 net.cpp:477] conv5 <- conv4
I1111 19:01:11.402174   945 net.cpp:433] conv5 -> conv5
I1111 19:01:11.404070   945 net.cpp:155] Setting up conv5
I1111 19:01:11.404091   945 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 19:01:11.404109   945 layer_factory.hpp:76] Creating layer relu5
I1111 19:01:11.404122   945 net.cpp:110] Creating Layer relu5
I1111 19:01:11.404132   945 net.cpp:477] relu5 <- conv5
I1111 19:01:11.404145   945 net.cpp:419] relu5 -> conv5 (in-place)
I1111 19:01:11.404157   945 net.cpp:155] Setting up relu5
I1111 19:01:11.404170   945 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 19:01:11.404180   945 layer_factory.hpp:76] Creating layer pool5
I1111 19:01:11.404191   945 net.cpp:110] Creating Layer pool5
I1111 19:01:11.404201   945 net.cpp:477] pool5 <- conv5
I1111 19:01:11.404213   945 net.cpp:433] pool5 -> pool5
I1111 19:01:11.404229   945 net.cpp:155] Setting up pool5
I1111 19:01:11.404242   945 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1111 19:01:11.404253   945 layer_factory.hpp:76] Creating layer fc6
I1111 19:01:11.404264   945 net.cpp:110] Creating Layer fc6
I1111 19:01:11.404274   945 net.cpp:477] fc6 <- pool5
I1111 19:01:11.404286   945 net.cpp:433] fc6 -> fc6
I1111 19:01:11.564229   945 net.cpp:155] Setting up fc6
I1111 19:01:11.564295   945 net.cpp:163] Top shape: 10 4096 (40960)
I1111 19:01:11.564316   945 layer_factory.hpp:76] Creating layer relu6
I1111 19:01:11.564340   945 net.cpp:110] Creating Layer relu6
I1111 19:01:11.564352   945 net.cpp:477] relu6 <- fc6
I1111 19:01:11.564368   945 net.cpp:419] relu6 -> fc6 (in-place)
I1111 19:01:11.564388   945 net.cpp:155] Setting up relu6
I1111 19:01:11.564399   945 net.cpp:163] Top shape: 10 4096 (40960)
I1111 19:01:11.564409   945 layer_factory.hpp:76] Creating layer drop6
I1111 19:01:11.564424   945 net.cpp:110] Creating Layer drop6
I1111 19:01:11.564435   945 net.cpp:477] drop6 <- fc6
I1111 19:01:11.564446   945 net.cpp:419] drop6 -> fc6 (in-place)
I1111 19:01:11.564462   945 net.cpp:155] Setting up drop6
I1111 19:01:11.564474   945 net.cpp:163] Top shape: 10 4096 (40960)
I1111 19:01:11.564484   945 layer_factory.hpp:76] Creating layer fc7
I1111 19:01:11.564499   945 net.cpp:110] Creating Layer fc7
I1111 19:01:11.564509   945 net.cpp:477] fc7 <- fc6
I1111 19:01:11.564522   945 net.cpp:433] fc7 -> fc7
I1111 19:01:11.635351   945 net.cpp:155] Setting up fc7
I1111 19:01:11.635414   945 net.cpp:163] Top shape: 10 4096 (40960)
I1111 19:01:11.635435   945 layer_factory.hpp:76] Creating layer relu7
I1111 19:01:11.635457   945 net.cpp:110] Creating Layer relu7
I1111 19:01:11.635470   945 net.cpp:477] relu7 <- fc7
I1111 19:01:11.635485   945 net.cpp:419] relu7 -> fc7 (in-place)
I1111 19:01:11.635532   945 net.cpp:155] Setting up relu7
I1111 19:01:11.635545   945 net.cpp:163] Top shape: 10 4096 (40960)
I1111 19:01:11.635556   945 layer_factory.hpp:76] Creating layer drop7
I1111 19:01:11.635571   945 net.cpp:110] Creating Layer drop7
I1111 19:01:11.635581   945 net.cpp:477] drop7 <- fc7
I1111 19:01:11.635593   945 net.cpp:419] drop7 -> fc7 (in-place)
I1111 19:01:11.635609   945 net.cpp:155] Setting up drop7
I1111 19:01:11.635622   945 net.cpp:163] Top shape: 10 4096 (40960)
I1111 19:01:11.635632   945 layer_factory.hpp:76] Creating layer fc8
I1111 19:01:11.635646   945 net.cpp:110] Creating Layer fc8
I1111 19:01:11.635658   945 net.cpp:477] fc8 <- fc7
I1111 19:01:11.635670   945 net.cpp:433] fc8 -> fc8
I1111 19:01:11.653309   945 net.cpp:155] Setting up fc8
I1111 19:01:11.653362   945 net.cpp:163] Top shape: 10 1000 (10000)
I1111 19:01:11.653383   945 layer_factory.hpp:76] Creating layer prob
I1111 19:01:11.653403   945 net.cpp:110] Creating Layer prob
I1111 19:01:11.653416   945 net.cpp:477] prob <- fc8
I1111 19:01:11.653431   945 net.cpp:433] prob -> prob
I1111 19:01:11.653456   945 net.cpp:155] Setting up prob
I1111 19:01:11.653470   945 net.cpp:163] Top shape: 10 1000 (10000)
I1111 19:01:11.653481   945 net.cpp:240] prob does not need backward computation.
I1111 19:01:11.653491   945 net.cpp:240] fc8 does not need backward computation.
I1111 19:01:11.653501   945 net.cpp:240] drop7 does not need backward computation.
I1111 19:01:11.653512   945 net.cpp:240] relu7 does not need backward computation.
I1111 19:01:11.653522   945 net.cpp:240] fc7 does not need backward computation.
I1111 19:01:11.653532   945 net.cpp:240] drop6 does not need backward computation.
I1111 19:01:11.653542   945 net.cpp:240] relu6 does not need backward computation.
I1111 19:01:11.653553   945 net.cpp:240] fc6 does not need backward computation.
I1111 19:01:11.653563   945 net.cpp:240] pool5 does not need backward computation.
I1111 19:01:11.653573   945 net.cpp:240] relu5 does not need backward computation.
I1111 19:01:11.653583   945 net.cpp:240] conv5 does not need backward computation.
I1111 19:01:11.653594   945 net.cpp:240] relu4 does not need backward computation.
I1111 19:01:11.653604   945 net.cpp:240] conv4 does not need backward computation.
I1111 19:01:11.653614   945 net.cpp:240] relu3 does not need backward computation.
I1111 19:01:11.653625   945 net.cpp:240] conv3 does not need backward computation.
I1111 19:01:11.653636   945 net.cpp:240] norm2 does not need backward computation.
I1111 19:01:11.653647   945 net.cpp:240] pool2 does not need backward computation.
I1111 19:01:11.653657   945 net.cpp:240] relu2 does not need backward computation.
I1111 19:01:11.653667   945 net.cpp:240] conv2 does not need backward computation.
I1111 19:01:11.653678   945 net.cpp:240] norm1 does not need backward computation.
I1111 19:01:11.653688   945 net.cpp:240] pool1 does not need backward computation.
I1111 19:01:11.653699   945 net.cpp:240] relu1 does not need backward computation.
I1111 19:01:11.653709   945 net.cpp:240] conv1 does not need backward computation.
I1111 19:01:11.653719   945 net.cpp:283] This network produces output prob
I1111 19:01:11.653740   945 net.cpp:297] Network initialization done.
I1111 19:01:11.653750   945 net.cpp:298] Memory required for data: 62497920
I1111 19:01:12.626826   945 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1111 19:01:12.626873   945 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1111 19:01:12.626884   945 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1111 19:01:12.626894   945 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1111 19:01:13.134347   945 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
58.152.249.17:39874 - - [11/Nov/2015 19:01:14] "HTTP/1.1 POST /resources/1" - 200 OK
I1111 20:03:04.970351   946 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1111 20:03:04.970448   946 net.cpp:435] Input 0 -> data
I1111 20:03:04.970480   946 layer_factory.hpp:76] Creating layer conv1
I1111 20:03:04.970500   946 net.cpp:110] Creating Layer conv1
I1111 20:03:04.970512   946 net.cpp:477] conv1 <- data
I1111 20:03:04.970525   946 net.cpp:433] conv1 -> conv1
I1111 20:03:04.970624   946 net.cpp:155] Setting up conv1
I1111 20:03:04.970649   946 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1111 20:03:04.970671   946 layer_factory.hpp:76] Creating layer relu1
I1111 20:03:04.970687   946 net.cpp:110] Creating Layer relu1
I1111 20:03:04.970698   946 net.cpp:477] relu1 <- conv1
I1111 20:03:04.970710   946 net.cpp:419] relu1 -> conv1 (in-place)
I1111 20:03:04.970724   946 net.cpp:155] Setting up relu1
I1111 20:03:04.970736   946 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1111 20:03:04.970747   946 layer_factory.hpp:76] Creating layer pool1
I1111 20:03:04.970760   946 net.cpp:110] Creating Layer pool1
I1111 20:03:04.970770   946 net.cpp:477] pool1 <- conv1
I1111 20:03:04.970800   946 net.cpp:433] pool1 -> pool1
I1111 20:03:04.970820   946 net.cpp:155] Setting up pool1
I1111 20:03:04.970834   946 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1111 20:03:04.970844   946 layer_factory.hpp:76] Creating layer norm1
I1111 20:03:04.970859   946 net.cpp:110] Creating Layer norm1
I1111 20:03:04.970868   946 net.cpp:477] norm1 <- pool1
I1111 20:03:04.970880   946 net.cpp:433] norm1 -> norm1
I1111 20:03:04.970896   946 net.cpp:155] Setting up norm1
I1111 20:03:04.970908   946 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1111 20:03:04.970918   946 layer_factory.hpp:76] Creating layer conv2
I1111 20:03:04.970932   946 net.cpp:110] Creating Layer conv2
I1111 20:03:04.970942   946 net.cpp:477] conv2 <- norm1
I1111 20:03:04.970954   946 net.cpp:433] conv2 -> conv2
I1111 20:03:04.971997   946 net.cpp:155] Setting up conv2
I1111 20:03:04.972017   946 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1111 20:03:04.972033   946 layer_factory.hpp:76] Creating layer relu2
I1111 20:03:04.972046   946 net.cpp:110] Creating Layer relu2
I1111 20:03:04.972057   946 net.cpp:477] relu2 <- conv2
I1111 20:03:04.972069   946 net.cpp:419] relu2 -> conv2 (in-place)
I1111 20:03:04.972082   946 net.cpp:155] Setting up relu2
I1111 20:03:04.972095   946 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1111 20:03:04.972105   946 layer_factory.hpp:76] Creating layer pool2
I1111 20:03:04.972116   946 net.cpp:110] Creating Layer pool2
I1111 20:03:04.972126   946 net.cpp:477] pool2 <- conv2
I1111 20:03:04.972138   946 net.cpp:433] pool2 -> pool2
I1111 20:03:04.972154   946 net.cpp:155] Setting up pool2
I1111 20:03:04.972167   946 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 20:03:04.972177   946 layer_factory.hpp:76] Creating layer norm2
I1111 20:03:04.972189   946 net.cpp:110] Creating Layer norm2
I1111 20:03:04.972200   946 net.cpp:477] norm2 <- pool2
I1111 20:03:04.972211   946 net.cpp:433] norm2 -> norm2
I1111 20:03:04.972226   946 net.cpp:155] Setting up norm2
I1111 20:03:04.972239   946 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 20:03:04.972249   946 layer_factory.hpp:76] Creating layer conv3
I1111 20:03:04.972261   946 net.cpp:110] Creating Layer conv3
I1111 20:03:04.972272   946 net.cpp:477] conv3 <- norm2
I1111 20:03:04.972285   946 net.cpp:433] conv3 -> conv3
I1111 20:03:04.976181   946 net.cpp:155] Setting up conv3
I1111 20:03:04.976203   946 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 20:03:04.976220   946 layer_factory.hpp:76] Creating layer relu3
I1111 20:03:04.976234   946 net.cpp:110] Creating Layer relu3
I1111 20:03:04.976244   946 net.cpp:477] relu3 <- conv3
I1111 20:03:04.976256   946 net.cpp:419] relu3 -> conv3 (in-place)
I1111 20:03:04.976269   946 net.cpp:155] Setting up relu3
I1111 20:03:04.976281   946 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 20:03:04.976292   946 layer_factory.hpp:76] Creating layer conv4
I1111 20:03:04.976305   946 net.cpp:110] Creating Layer conv4
I1111 20:03:04.976315   946 net.cpp:477] conv4 <- conv3
I1111 20:03:04.976327   946 net.cpp:433] conv4 -> conv4
I1111 20:03:04.978940   946 net.cpp:155] Setting up conv4
I1111 20:03:04.978961   946 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 20:03:04.978976   946 layer_factory.hpp:76] Creating layer relu4
I1111 20:03:04.978988   946 net.cpp:110] Creating Layer relu4
I1111 20:03:04.978999   946 net.cpp:477] relu4 <- conv4
I1111 20:03:04.979012   946 net.cpp:419] relu4 -> conv4 (in-place)
I1111 20:03:04.979024   946 net.cpp:155] Setting up relu4
I1111 20:03:04.979038   946 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 20:03:04.979048   946 layer_factory.hpp:76] Creating layer conv5
I1111 20:03:04.979060   946 net.cpp:110] Creating Layer conv5
I1111 20:03:04.979070   946 net.cpp:477] conv5 <- conv4
I1111 20:03:04.979082   946 net.cpp:433] conv5 -> conv5
I1111 20:03:04.980913   946 net.cpp:155] Setting up conv5
I1111 20:03:04.980932   946 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 20:03:04.980949   946 layer_factory.hpp:76] Creating layer relu5
I1111 20:03:04.980962   946 net.cpp:110] Creating Layer relu5
I1111 20:03:04.980985   946 net.cpp:477] relu5 <- conv5
I1111 20:03:04.980999   946 net.cpp:419] relu5 -> conv5 (in-place)
I1111 20:03:04.981012   946 net.cpp:155] Setting up relu5
I1111 20:03:04.981025   946 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 20:03:04.981035   946 layer_factory.hpp:76] Creating layer pool5
I1111 20:03:04.981048   946 net.cpp:110] Creating Layer pool5
I1111 20:03:04.981058   946 net.cpp:477] pool5 <- conv5
I1111 20:03:04.981071   946 net.cpp:433] pool5 -> pool5
I1111 20:03:04.981086   946 net.cpp:155] Setting up pool5
I1111 20:03:04.981099   946 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1111 20:03:04.981111   946 layer_factory.hpp:76] Creating layer fc6
I1111 20:03:04.981123   946 net.cpp:110] Creating Layer fc6
I1111 20:03:04.981133   946 net.cpp:477] fc6 <- pool5
I1111 20:03:04.981145   946 net.cpp:433] fc6 -> fc6
I1111 20:03:05.141814   946 net.cpp:155] Setting up fc6
I1111 20:03:05.141880   946 net.cpp:163] Top shape: 10 4096 (40960)
I1111 20:03:05.141901   946 layer_factory.hpp:76] Creating layer relu6
I1111 20:03:05.141928   946 net.cpp:110] Creating Layer relu6
I1111 20:03:05.141940   946 net.cpp:477] relu6 <- fc6
I1111 20:03:05.141957   946 net.cpp:419] relu6 -> fc6 (in-place)
I1111 20:03:05.141976   946 net.cpp:155] Setting up relu6
I1111 20:03:05.141988   946 net.cpp:163] Top shape: 10 4096 (40960)
I1111 20:03:05.141999   946 layer_factory.hpp:76] Creating layer drop6
I1111 20:03:05.142014   946 net.cpp:110] Creating Layer drop6
I1111 20:03:05.142024   946 net.cpp:477] drop6 <- fc6
I1111 20:03:05.142036   946 net.cpp:419] drop6 -> fc6 (in-place)
I1111 20:03:05.142052   946 net.cpp:155] Setting up drop6
I1111 20:03:05.142065   946 net.cpp:163] Top shape: 10 4096 (40960)
I1111 20:03:05.142076   946 layer_factory.hpp:76] Creating layer fc7
I1111 20:03:05.142091   946 net.cpp:110] Creating Layer fc7
I1111 20:03:05.142102   946 net.cpp:477] fc7 <- fc6
I1111 20:03:05.142113   946 net.cpp:433] fc7 -> fc7
I1111 20:03:05.213414   946 net.cpp:155] Setting up fc7
I1111 20:03:05.213479   946 net.cpp:163] Top shape: 10 4096 (40960)
I1111 20:03:05.213500   946 layer_factory.hpp:76] Creating layer relu7
I1111 20:03:05.213522   946 net.cpp:110] Creating Layer relu7
I1111 20:03:05.213534   946 net.cpp:477] relu7 <- fc7
I1111 20:03:05.213549   946 net.cpp:419] relu7 -> fc7 (in-place)
I1111 20:03:05.213569   946 net.cpp:155] Setting up relu7
I1111 20:03:05.213580   946 net.cpp:163] Top shape: 10 4096 (40960)
I1111 20:03:05.213590   946 layer_factory.hpp:76] Creating layer drop7
I1111 20:03:05.213605   946 net.cpp:110] Creating Layer drop7
I1111 20:03:05.213615   946 net.cpp:477] drop7 <- fc7
I1111 20:03:05.213628   946 net.cpp:419] drop7 -> fc7 (in-place)
I1111 20:03:05.213644   946 net.cpp:155] Setting up drop7
I1111 20:03:05.213655   946 net.cpp:163] Top shape: 10 4096 (40960)
I1111 20:03:05.213666   946 layer_factory.hpp:76] Creating layer fc8
I1111 20:03:05.213680   946 net.cpp:110] Creating Layer fc8
I1111 20:03:05.213690   946 net.cpp:477] fc8 <- fc7
I1111 20:03:05.213703   946 net.cpp:433] fc8 -> fc8
I1111 20:03:05.230903   946 net.cpp:155] Setting up fc8
I1111 20:03:05.230940   946 net.cpp:163] Top shape: 10 1000 (10000)
I1111 20:03:05.230959   946 layer_factory.hpp:76] Creating layer prob
I1111 20:03:05.230978   946 net.cpp:110] Creating Layer prob
I1111 20:03:05.230990   946 net.cpp:477] prob <- fc8
I1111 20:03:05.231004   946 net.cpp:433] prob -> prob
I1111 20:03:05.231026   946 net.cpp:155] Setting up prob
I1111 20:03:05.231039   946 net.cpp:163] Top shape: 10 1000 (10000)
I1111 20:03:05.231050   946 net.cpp:240] prob does not need backward computation.
I1111 20:03:05.231060   946 net.cpp:240] fc8 does not need backward computation.
I1111 20:03:05.231070   946 net.cpp:240] drop7 does not need backward computation.
I1111 20:03:05.231081   946 net.cpp:240] relu7 does not need backward computation.
I1111 20:03:05.231091   946 net.cpp:240] fc7 does not need backward computation.
I1111 20:03:05.231101   946 net.cpp:240] drop6 does not need backward computation.
I1111 20:03:05.231137   946 net.cpp:240] relu6 does not need backward computation.
I1111 20:03:05.231148   946 net.cpp:240] fc6 does not need backward computation.
I1111 20:03:05.231159   946 net.cpp:240] pool5 does not need backward computation.
I1111 20:03:05.231169   946 net.cpp:240] relu5 does not need backward computation.
I1111 20:03:05.231180   946 net.cpp:240] conv5 does not need backward computation.
I1111 20:03:05.231190   946 net.cpp:240] relu4 does not need backward computation.
I1111 20:03:05.231201   946 net.cpp:240] conv4 does not need backward computation.
I1111 20:03:05.231212   946 net.cpp:240] relu3 does not need backward computation.
I1111 20:03:05.231222   946 net.cpp:240] conv3 does not need backward computation.
I1111 20:03:05.231233   946 net.cpp:240] norm2 does not need backward computation.
I1111 20:03:05.231245   946 net.cpp:240] pool2 does not need backward computation.
I1111 20:03:05.231254   946 net.cpp:240] relu2 does not need backward computation.
I1111 20:03:05.231266   946 net.cpp:240] conv2 does not need backward computation.
I1111 20:03:05.231276   946 net.cpp:240] norm1 does not need backward computation.
I1111 20:03:05.231287   946 net.cpp:240] pool1 does not need backward computation.
I1111 20:03:05.231297   946 net.cpp:240] relu1 does not need backward computation.
I1111 20:03:05.231307   946 net.cpp:240] conv1 does not need backward computation.
I1111 20:03:05.231317   946 net.cpp:283] This network produces output prob
I1111 20:03:05.231339   946 net.cpp:297] Network initialization done.
I1111 20:03:05.231349   946 net.cpp:298] Memory required for data: 62497920
I1111 20:03:06.215651   946 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1111 20:03:06.215703   946 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1111 20:03:06.215713   946 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1111 20:03:06.215723   946 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1111 20:03:06.725903   946 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
58.152.249.17:47834 - - [11/Nov/2015 20:03:07] "HTTP/1.1 POST /resources/1" - 200 OK
http://0.0.0.0:3000/
file no. 1 processed: ../../../dataset/temp/12071132_117024925320109_1448778029_n.jpg
file no. 2 processed: ../../../dataset/temp/11899529_409336062593154_26859144_n.jpg
file no. 3 processed: ../../../dataset/temp/12139791_172476163092798_682238343_n.jpg
file no. 4 processed: ../../../dataset/temp/10919675_339630669566407_1560505453_n.jpg
file no. 5 processed: ../../../dataset/temp/11377801_146811182334693_2053033951_n.jpg
file no. 1 processed: ../../../dataset/temp/12071132_117024925320109_1448778029_n.jpg
file no. 2 processed: ../../../dataset/temp/11899529_409336062593154_26859144_n.jpg
file no. 3 processed: ../../../dataset/temp/12139791_172476163092798_682238343_n.jpg
file no. 4 processed: ../../../dataset/temp/10919675_339630669566407_1560505453_n.jpg
file no. 5 processed: ../../../dataset/temp/11377801_146811182334693_2053033951_n.jpg
file no. 1 processed: ../../../dataset/temp/12071132_117024925320109_1448778029_n.jpg
file no. 2 processed: ../../../dataset/temp/11899529_409336062593154_26859144_n.jpg
file no. 3 processed: ../../../dataset/temp/12139791_172476163092798_682238343_n.jpg
file no. 4 processed: ../../../dataset/temp/10919675_339630669566407_1560505453_n.jpg
file no. 5 processed: ../../../dataset/temp/11377801_146811182334693_2053033951_n.jpg
file no. 1 processed: ../../../dataset/temp/12071132_117024925320109_1448778029_n.jpg
file no. 2 processed: ../../../dataset/temp/11899529_409336062593154_26859144_n.jpg
file no. 3 processed: ../../../dataset/temp/12139791_172476163092798_682238343_n.jpg
file no. 4 processed: ../../../dataset/temp/10919675_339630669566407_1560505453_n.jpg
file no. 5 processed: ../../../dataset/temp/11377801_146811182334693_2053033951_n.jpg
file no. 1 processed: ../../../dataset/temp/12071132_117024925320109_1448778029_n.jpg
file no. 2 processed: ../../../dataset/temp/11899529_409336062593154_26859144_n.jpg
file no. 3 processed: ../../../dataset/temp/12139791_172476163092798_682238343_n.jpg
file no. 4 processed: ../../../dataset/temp/10919675_339630669566407_1560505453_n.jpg
file no. 5 processed: ../../../dataset/temp/11377801_146811182334693_2053033951_n.jpg
file no. 1 processed: ../../../dataset/temp/12071132_117024925320109_1448778029_n.jpg
file no. 2 processed: ../../../dataset/temp/11899529_409336062593154_26859144_n.jpg
file no. 3 processed: ../../../dataset/temp/12139791_172476163092798_682238343_n.jpg
file no. 4 processed: ../../../dataset/temp/10919675_339630669566407_1560505453_n.jpg
file no. 5 processed: ../../../dataset/temp/11377801_146811182334693_2053033951_n.jpg
file no. 1 processed: ../../../dataset/temp/12071132_117024925320109_1448778029_n.jpg
file no. 2 processed: ../../../dataset/temp/11899529_409336062593154_26859144_n.jpg
file no. 3 processed: ../../../dataset/temp/12139791_172476163092798_682238343_n.jpg
file no. 4 processed: ../../../dataset/temp/10919675_339630669566407_1560505453_n.jpg
file no. 5 processed: ../../../dataset/temp/11377801_146811182334693_2053033951_n.jpg
file no. 1 processed: ../../../dataset/temp/12071132_117024925320109_1448778029_n.jpg
file no. 2 processed: ../../../dataset/temp/11899529_409336062593154_26859144_n.jpg
file no. 3 processed: ../../../dataset/temp/12139791_172476163092798_682238343_n.jpg
file no. 4 processed: ../../../dataset/temp/10919675_339630669566407_1560505453_n.jpg
file no. 5 processed: ../../../dataset/temp/11377801_146811182334693_2053033951_n.jpg
file no. 1 processed: ../../../dataset/temp/12071132_117024925320109_1448778029_n.jpg
file no. 2 processed: ../../../dataset/temp/11899529_409336062593154_26859144_n.jpg
file no. 3 processed: ../../../dataset/temp/12139791_172476163092798_682238343_n.jpg
file no. 4 processed: ../../../dataset/temp/10919675_339630669566407_1560505453_n.jpg
file no. 5 processed: ../../../dataset/temp/11377801_146811182334693_2053033951_n.jpg
file no. 1 processed: ../../../dataset/temp/12071132_117024925320109_1448778029_n.jpg
file no. 2 processed: ../../../dataset/temp/12139791_172476163092798_682238343_n.jpg
file no. 3 processed: ../../../dataset/temp/10919675_33963066I1111 20:03:38.982235   947 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1111 20:03:38.982341   947 net.cpp:435] Input 0 -> data
I1111 20:03:38.982374   947 layer_factory.hpp:76] Creating layer conv1
I1111 20:03:38.982393   947 net.cpp:110] Creating Layer conv1
I1111 20:03:38.982404   947 net.cpp:477] conv1 <- data
I1111 20:03:38.982419   947 net.cpp:433] conv1 -> conv1
I1111 20:03:38.982481   947 net.cpp:155] Setting up conv1
I1111 20:03:38.982501   947 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1111 20:03:38.982523   947 layer_factory.hpp:76] Creating layer relu1
I1111 20:03:38.982539   947 net.cpp:110] Creating Layer relu1
I1111 20:03:38.982549   947 net.cpp:477] relu1 <- conv1
I1111 20:03:38.982561   947 net.cpp:419] relu1 -> conv1 (in-place)
I1111 20:03:38.982599   947 net.cpp:155] Setting up relu1
I1111 20:03:38.982627   947 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1111 20:03:38.982640   947 layer_factory.hpp:76] Creating layer pool1
I1111 20:03:38.982653   947 net.cpp:110] Creating Layer pool1
I1111 20:03:38.982664   947 net.cpp:477] pool1 <- conv1
I1111 20:03:38.982676   947 net.cpp:433] pool1 -> pool1
I1111 20:03:38.982695   947 net.cpp:155] Setting up pool1
I1111 20:03:38.982708   947 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1111 20:03:38.982718   947 layer_factory.hpp:76] Creating layer norm1
I1111 20:03:38.982731   947 net.cpp:110] Creating Layer norm1
I1111 20:03:38.982741   947 net.cpp:477] norm1 <- pool1
I1111 20:03:38.982753   947 net.cpp:433] norm1 -> norm1
I1111 20:03:38.982769   947 net.cpp:155] Setting up norm1
I1111 20:03:38.982781   947 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1111 20:03:38.982791   947 layer_factory.hpp:76] Creating layer conv2
I1111 20:03:38.982805   947 net.cpp:110] Creating Layer conv2
I1111 20:03:38.982815   947 net.cpp:477] conv2 <- norm1
I1111 20:03:38.982827   947 net.cpp:433] conv2 -> conv2
I1111 20:03:38.983863   947 net.cpp:155] Setting up conv2
I1111 20:03:38.983883   947 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1111 20:03:38.983901   947 layer_factory.hpp:76] Creating layer relu2
I1111 20:03:38.983913   947 net.cpp:110] Creating Layer relu2
I1111 20:03:38.983924   947 net.cpp:477] relu2 <- conv2
I1111 20:03:38.983935   947 net.cpp:419] relu2 -> conv2 (in-place)
I1111 20:03:38.983948   947 net.cpp:155] Setting up relu2
I1111 20:03:38.983960   947 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1111 20:03:38.983970   947 layer_factory.hpp:76] Creating layer pool2
I1111 20:03:38.983983   947 net.cpp:110] Creating Layer pool2
I1111 20:03:38.983993   947 net.cpp:477] pool2 <- conv2
I1111 20:03:38.984004   947 net.cpp:433] pool2 -> pool2
I1111 20:03:38.984019   947 net.cpp:155] Setting up pool2
I1111 20:03:38.984031   947 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 20:03:38.984055   947 layer_factory.hpp:76] Creating layer norm2
I1111 20:03:38.984068   947 net.cpp:110] Creating Layer norm2
I1111 20:03:38.984078   947 net.cpp:477] norm2 <- pool2
I1111 20:03:38.984089   947 net.cpp:433] norm2 -> norm2
I1111 20:03:38.984104   947 net.cpp:155] Setting up norm2
I1111 20:03:38.984117   947 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 20:03:38.984127   947 layer_factory.hpp:76] Creating layer conv3
I1111 20:03:38.984140   947 net.cpp:110] Creating Layer conv3
I1111 20:03:38.984150   947 net.cpp:477] conv3 <- norm2
I1111 20:03:38.984163   947 net.cpp:433] conv3 -> conv3
I1111 20:03:38.988265   947 net.cpp:155] Setting up conv3
I1111 20:03:38.988286   947 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 20:03:38.988303   947 layer_factory.hpp:76] Creating layer relu3
I1111 20:03:38.988317   947 net.cpp:110] Creating Layer relu3
I1111 20:03:38.988327   947 net.cpp:477] relu3 <- conv3
I1111 20:03:38.988338   947 net.cpp:419] relu3 -> conv3 (in-place)
I1111 20:03:38.988351   947 net.cpp:155] Setting up relu3
I1111 20:03:38.988363   947 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 20:03:38.988373   947 layer_factory.hpp:76] Creating layer conv4
I1111 20:03:38.988386   947 net.cpp:110] Creating Layer conv4
I1111 20:03:38.988396   947 net.cpp:477] conv4 <- conv3
I1111 20:03:38.988409   947 net.cpp:433] conv4 -> conv4
I1111 20:03:38.991227   947 net.cpp:155] Setting up conv4
I1111 20:03:38.991250   947 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 20:03:38.991263   947 layer_factory.hpp:76] Creating layer relu4
I1111 20:03:38.991276   947 net.cpp:110] Creating Layer relu4
I1111 20:03:38.991286   947 net.cpp:477] relu4 <- conv4
I1111 20:03:38.991298   947 net.cpp:419] relu4 -> conv4 (in-place)
I1111 20:03:38.991312   947 net.cpp:155] Setting up relu4
I1111 20:03:38.991323   947 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 20:03:38.991333   947 layer_factory.hpp:76] Creating layer conv5
I1111 20:03:38.991345   947 net.cpp:110] Creating Layer conv5
I1111 20:03:38.991356   947 net.cpp:477] conv5 <- conv4
I1111 20:03:38.991369   947 net.cpp:433] conv5 -> conv5
I1111 20:03:38.993288   947 net.cpp:155] Setting up conv5
I1111 20:03:38.993306   947 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 20:03:38.993324   947 layer_factory.hpp:76] Creating layer relu5
I1111 20:03:38.993337   947 net.cpp:110] Creating Layer relu5
I1111 20:03:38.993347   947 net.cpp:477] relu5 <- conv5
I1111 20:03:38.993360   947 net.cpp:419] relu5 -> conv5 (in-place)
I1111 20:03:38.993372   947 net.cpp:155] Setting up relu5
I1111 20:03:38.993383   947 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 20:03:38.993394   947 layer_factory.hpp:76] Creating layer pool5
I1111 20:03:38.993407   947 net.cpp:110] Creating Layer pool5
I1111 20:03:38.993417   947 net.cpp:477] pool5 <- conv5
I1111 20:03:38.993428   947 net.cpp:433] pool5 -> pool5
I1111 20:03:38.993443   947 net.cpp:155] Setting up pool5
I1111 20:03:38.993455   947 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1111 20:03:38.993466   947 layer_factory.hpp:76] Creating layer fc6
I1111 20:03:38.993479   947 net.cpp:110] Creating Layer fc6
I1111 20:03:38.993489   947 net.cpp:477] fc6 <- pool5
I1111 20:03:38.993500   947 net.cpp:433] fc6 -> fc6
I1111 20:03:39.154183   947 net.cpp:155] Setting up fc6
I1111 20:03:39.154253   947 net.cpp:163] Top shape: 10 4096 (40960)
I1111 20:03:39.154273   947 layer_factory.hpp:76] Creating layer relu6
I1111 20:03:39.154299   947 net.cpp:110] Creating Layer relu6
I1111 20:03:39.154312   947 net.cpp:477] relu6 <- fc6
I1111 20:03:39.154328   947 net.cpp:419] relu6 -> fc6 (in-place)
I1111 20:03:39.154348   947 net.cpp:155] Setting up relu6
I1111 20:03:39.154359   947 net.cpp:163] Top shape: 10 4096 (40960)
I1111 20:03:39.154369   947 layer_factory.hpp:76] Creating layer drop6
I1111 20:03:39.154384   947 net.cpp:110] Creating Layer drop6
I1111 20:03:39.154394   947 net.cpp:477] drop6 <- fc6
I1111 20:03:39.154407   947 net.cpp:419] drop6 -> fc6 (in-place)
I1111 20:03:39.154422   947 net.cpp:155] Setting up drop6
I1111 20:03:39.154465   947 net.cpp:163] Top shape: 10 4096 (40960)
I1111 20:03:39.154477   947 layer_factory.hpp:76] Creating layer fc7
I1111 20:03:39.154492   947 net.cpp:110] Creating Layer fc7
I1111 20:03:39.154503   947 net.cpp:477] fc7 <- fc6
I1111 20:03:39.154516   947 net.cpp:433] fc7 -> fc7
I1111 20:03:39.225885   947 net.cpp:155] Setting up fc7
I1111 20:03:39.225955   947 net.cpp:163] Top shape: 10 4096 (40960)
I1111 20:03:39.225976   947 layer_factory.hpp:76] Creating layer relu7
I1111 20:03:39.225998   947 net.cpp:110] Creating Layer relu7
I1111 20:03:39.226011   947 net.cpp:477] relu7 <- fc7
I1111 20:03:39.226027   947 net.cpp:419] relu7 -> fc7 (in-place)
I1111 20:03:39.226045   947 net.cpp:155] Setting up relu7
I1111 20:03:39.226057   947 net.cpp:163] Top shape: 10 4096 (40960)
I1111 20:03:39.226066   947 layer_factory.hpp:76] Creating layer drop7
I1111 20:03:39.226083   947 net.cpp:110] Creating Layer drop7
I1111 20:03:39.226092   947 net.cpp:477] drop7 <- fc7
I1111 20:03:39.226104   947 net.cpp:419] drop7 -> fc7 (in-place)
I1111 20:03:39.226119   947 net.cpp:155] Setting up drop7
I1111 20:03:39.226132   947 net.cpp:163] Top shape: 10 4096 (40960)
I1111 20:03:39.226142   947 layer_factory.hpp:76] Creating layer fc8
I1111 20:03:39.226157   947 net.cpp:110] Creating Layer fc8
I1111 20:03:39.226167   947 net.cpp:477] fc8 <- fc7
I1111 20:03:39.226181   947 net.cpp:433] fc8 -> fc8
I1111 20:03:39.243384   947 net.cpp:155] Setting up fc8
I1111 20:03:39.243424   947 net.cpp:163] Top shape: 10 1000 (10000)
I1111 20:03:39.243443   947 layer_factory.hpp:76] Creating layer prob
I1111 20:03:39.243459   947 net.cpp:110] Creating Layer prob
I1111 20:03:39.243471   947 net.cpp:477] prob <- fc8
I1111 20:03:39.243485   947 net.cpp:433] prob -> prob
I1111 20:03:39.243506   947 net.cpp:155] Setting up prob
I1111 20:03:39.243520   947 net.cpp:163] Top shape: 10 1000 (10000)
I1111 20:03:39.243530   947 net.cpp:240] prob does not need backward computation.
I1111 20:03:39.243541   947 net.cpp:240] fc8 does not need backward computation.
I1111 20:03:39.243551   947 net.cpp:240] drop7 does not need backward computation.
I1111 20:03:39.243561   947 net.cpp:240] relu7 does not need backward computation.
I1111 20:03:39.243569   947 net.cpp:240] fc7 does not need backward computation.
I1111 20:03:39.243579   947 net.cpp:240] drop6 does not need backward computation.
I1111 20:03:39.243589   947 net.cpp:240] relu6 does not need backward computation.
I1111 20:03:39.243600   947 net.cpp:240] fc6 does not need backward computation.
I1111 20:03:39.243610   947 net.cpp:240] pool5 does not need backward computation.
I1111 20:03:39.243620   947 net.cpp:240] relu5 does not need backward computation.
I1111 20:03:39.243631   947 net.cpp:240] conv5 does not need backward computation.
I1111 20:03:39.243641   947 net.cpp:240] relu4 does not need backward computation.
I1111 20:03:39.243651   947 net.cpp:240] conv4 does not need backward computation.
I1111 20:03:39.243662   947 net.cpp:240] relu3 does not need backward computation.
I1111 20:03:39.243672   947 net.cpp:240] conv3 does not need backward computation.
I1111 20:03:39.243684   947 net.cpp:240] norm2 does not need backward computation.
I1111 20:03:39.243695   947 net.cpp:240] pool2 does not need backward computation.
I1111 20:03:39.243705   947 net.cpp:240] relu2 does not need backward computation.
I1111 20:03:39.243715   947 net.cpp:240] conv2 does not need backward computation.
I1111 20:03:39.243724   947 net.cpp:240] norm1 does not need backward computation.
I1111 20:03:39.243736   947 net.cpp:240] pool1 does not need backward computation.
I1111 20:03:39.243746   947 net.cpp:240] relu1 does not need backward computation.
I1111 20:03:39.243755   947 net.cpp:240] conv1 does not need backward computation.
I1111 20:03:39.243767   947 net.cpp:283] This network produces output prob
I1111 20:03:39.243788   947 net.cpp:297] Network initialization done.
I1111 20:03:39.243798   947 net.cpp:298] Memory required for data: 62497920
I1111 20:03:40.227171   947 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1111 20:03:40.227249   947 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1111 20:03:40.227262   947 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1111 20:03:40.227270   947 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1111 20:03:40.735107   947 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
Traceback (most recent call last):
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 239, in process
    return self.handle()
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 230, in handle
    return self._delegate(fn, self.fvars, args)
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 420, in _delegate
    return handle_class(cls)
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 396, in handle_class
    return tocall(*args)
  File "/root/ds210_capstone/caffe_script/service/controller.py", line 16, in POST
    return self.baseline()
  File "/root/ds210_capstone/caffe_script/service/app.py", line 19, in baseline
    respond = b.baseline_run(request)
  File "/root/ds210_capstone/caffe_script/service/baseline.py", line 29, in baseline_run
    self.caffe_predict()
  File "/root/ds210_capstone/caffe_script/service/baseline.py", line 124, in caffe_predict
    #load image into caffe preprocessor
  File "/root/caffe/python/caffe/io.py", line 295, in load_image
    img = skimage.img_as_float(skimage.io.imread(filename)).astype(np.float32)
  File "/root/anaconda/lib/python2.7/site-packages/skimage/io/_io.py", line 100, in imread
    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)
  File "/root/anaconda/lib/python2.7/site-packages/skimage/io/manage_plugins.py", line 207, in call_plugin
    return func(*args, **kwargs)
  File "/root/anaconda/lib/python2.7/site-packages/skimage/io/_plugins/pil_plugin.py", line 46, in imread
    im = Image.open(fname)
  File "/root/anaconda/lib/python2.7/site-packages/PIL/Image.py", line 2248, in open
    fp = builtins.open(fp, "rb")
IOError: [Errno 2] No such file or directory: u'../../../dataset/temp/11899529_409336062593154_26859144_n.jpg'

58.152.249.17:36880 - - [11/Nov/2015 20:03:41] "HTTP/1.1 POST /resources/1" - 500 Internal Server Error
I1111 20:31:30.248841   948 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1111 20:31:30.248951   948 net.cpp:435] Input 0 -> data
I1111 20:31:30.248986   948 layer_factory.hpp:76] Creating layer conv1
I1111 20:31:30.249006   948 net.cpp:110] Creating Layer conv1
I1111 20:31:30.249017   948 net.cpp:477] conv1 <- data
I1111 20:31:30.249030   948 net.cpp:433] conv1 -> conv1
I1111 20:31:30.249092   948 net.cpp:155] Setting up conv1
I1111 20:31:30.249114   948 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1111 20:31:30.249135   948 layer_factory.hpp:76] Creating layer relu1
I1111 20:31:30.249151   948 net.cpp:110] Creating Layer relu1
I1111 20:31:30.249162   948 net.cpp:477] relu1 <- conv1
I1111 20:31:30.249174   948 net.cpp:419] relu1 -> conv1 (in-place)
I1111 20:31:30.249188   948 net.cpp:155] Setting up relu1
I1111 20:31:30.249202   948 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1111 20:31:30.249212   948 layer_factory.hpp:76] Creating layer pool1
I1111 20:31:30.249224   948 net.cpp:110] Creating Layer pool1
I1111 20:31:30.249234   948 net.cpp:477] pool1 <- conv1
I1111 20:31:30.249246   948 net.cpp:433] pool1 -> pool1
I1111 20:31:30.249265   948 net.cpp:155] Setting up pool1
I1111 20:31:30.249279   948 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1111 20:31:30.249289   948 layer_factory.hpp:76] Creating layer norm1
I1111 20:31:30.249302   948 net.cpp:110] Creating Layer norm1
I1111 20:31:30.249312   948 net.cpp:477] norm1 <- pool1
I1111 20:31:30.249325   948 net.cpp:433] norm1 -> norm1
I1111 20:31:30.249341   948 net.cpp:155] Setting up norm1
I1111 20:31:30.249352   948 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1111 20:31:30.249363   948 layer_factory.hpp:76] Creating layer conv2
I1111 20:31:30.249377   948 net.cpp:110] Creating Layer conv2
I1111 20:31:30.249387   948 net.cpp:477] conv2 <- norm1
I1111 20:31:30.249398   948 net.cpp:433] conv2 -> conv2
I1111 20:31:30.250397   948 net.cpp:155] Setting up conv2
I1111 20:31:30.250417   948 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1111 20:31:30.250434   948 layer_factory.hpp:76] Creating layer relu2
I1111 20:31:30.250447   948 net.cpp:110] Creating Layer relu2
I1111 20:31:30.250458   948 net.cpp:477] relu2 <- conv2
I1111 20:31:30.250469   948 net.cpp:419] relu2 -> conv2 (in-place)
I1111 20:31:30.250483   948 net.cpp:155] Setting up relu2
I1111 20:31:30.250494   948 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1111 20:31:30.250504   948 layer_factory.hpp:76] Creating layer pool2
I1111 20:31:30.250516   948 net.cpp:110] Creating Layer pool2
I1111 20:31:30.250526   948 net.cpp:477] pool2 <- conv2
I1111 20:31:30.250555   948 net.cpp:433] pool2 -> pool2
I1111 20:31:30.250571   948 net.cpp:155] Setting up pool2
I1111 20:31:30.250622   948 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 20:31:30.250634   948 layer_factory.hpp:76] Creating layer norm2
I1111 20:31:30.250648   948 net.cpp:110] Creating Layer norm2
I1111 20:31:30.250658   948 net.cpp:477] norm2 <- pool2
I1111 20:31:30.250669   948 net.cpp:433] norm2 -> norm2
I1111 20:31:30.250684   948 net.cpp:155] Setting up norm2
I1111 20:31:30.250696   948 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 20:31:30.250706   948 layer_factory.hpp:76] Creating layer conv3
I1111 20:31:30.250720   948 net.cpp:110] Creating Layer conv3
I1111 20:31:30.250730   948 net.cpp:477] conv3 <- norm2
I1111 20:31:30.250742   948 net.cpp:433] conv3 -> conv3
I1111 20:31:30.254442   948 net.cpp:155] Setting up conv3
I1111 20:31:30.254462   948 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 20:31:30.254478   948 layer_factory.hpp:76] Creating layer relu3
I1111 20:31:30.254492   948 net.cpp:110] Creating Layer relu3
I1111 20:31:30.254503   948 net.cpp:477] relu3 <- conv3
I1111 20:31:30.254514   948 net.cpp:419] relu3 -> conv3 (in-place)
I1111 20:31:30.254528   948 net.cpp:155] Setting up relu3
I1111 20:31:30.254539   948 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 20:31:30.254549   948 layer_factory.hpp:76] Creating layer conv4
I1111 20:31:30.254561   948 net.cpp:110] Creating Layer conv4
I1111 20:31:30.254571   948 net.cpp:477] conv4 <- conv3
I1111 20:31:30.254611   948 net.cpp:433] conv4 -> conv4
I1111 20:31:30.257402   948 net.cpp:155] Setting up conv4
I1111 20:31:30.257421   948 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 20:31:30.257436   948 layer_factory.hpp:76] Creating layer relu4
I1111 20:31:30.257449   948 net.cpp:110] Creating Layer relu4
I1111 20:31:30.257459   948 net.cpp:477] relu4 <- conv4
I1111 20:31:30.257472   948 net.cpp:419] relu4 -> conv4 (in-place)
I1111 20:31:30.257484   948 net.cpp:155] Setting up relu4
I1111 20:31:30.257496   948 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1111 20:31:30.257506   948 layer_factory.hpp:76] Creating layer conv5
I1111 20:31:30.257519   948 net.cpp:110] Creating Layer conv5
I1111 20:31:30.257529   948 net.cpp:477] conv5 <- conv4
I1111 20:31:30.257540   948 net.cpp:433] conv5 -> conv5
I1111 20:31:30.259409   948 net.cpp:155] Setting up conv5
I1111 20:31:30.259429   948 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 20:31:30.259448   948 layer_factory.hpp:76] Creating layer relu5
I1111 20:31:30.259460   948 net.cpp:110] Creating Layer relu5
I1111 20:31:30.259470   948 net.cpp:477] relu5 <- conv5
I1111 20:31:30.259485   948 net.cpp:419] relu5 -> conv5 (in-place)
I1111 20:31:30.259498   948 net.cpp:155] Setting up relu5
I1111 20:31:30.259510   948 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1111 20:31:30.259521   948 layer_factory.hpp:76] Creating layer pool5
I1111 20:31:30.259532   948 net.cpp:110] Creating Layer pool5
I1111 20:31:30.259542   948 net.cpp:477] pool5 <- conv5
I1111 20:31:30.259554   948 net.cpp:433] pool5 -> pool5
I1111 20:31:30.259569   948 net.cpp:155] Setting up pool5
I1111 20:31:30.259582   948 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1111 20:31:30.259591   948 layer_factory.hpp:76] Creating layer fc6
I1111 20:31:30.259604   948 net.cpp:110] Creating Layer fc6
I1111 20:31:30.259614   948 net.cpp:477] fc6 <- pool5
I1111 20:31:30.259625   948 net.cpp:433] fc6 -> fc6
I1111 20:31:30.419617   948 net.cpp:155] Setting up fc6
I1111 20:31:30.419687   948 net.cpp:163] Top shape: 10 4096 (40960)
I1111 20:31:30.419709   948 layer_factory.hpp:76] Creating layer relu6
I1111 20:31:30.419735   948 net.cpp:110] Creating Layer relu6
I1111 20:31:30.419749   948 net.cpp:477] relu6 <- fc6
I1111 20:31:30.419764   948 net.cpp:419] relu6 -> fc6 (in-place)
I1111 20:31:30.419783   948 net.cpp:155] Setting up relu6
I1111 20:31:30.419795   948 net.cpp:163] Top shape: 10 4096 (40960)
I1111 20:31:30.419806   948 layer_factory.hpp:76] Creating layer drop6
I1111 20:31:30.419821   948 net.cpp:110] Creating Layer drop6
I1111 20:31:30.419862   948 net.cpp:477] drop6 <- fc6
I1111 20:31:30.419877   948 net.cpp:419] drop6 -> fc6 (in-place)
I1111 20:31:30.419893   948 net.cpp:155] Setting up drop6
I1111 20:31:30.419904   948 net.cpp:163] Top shape: 10 4096 (40960)
I1111 20:31:30.419915   948 layer_factory.hpp:76] Creating layer fc7
I1111 20:31:30.419930   948 net.cpp:110] Creating Layer fc7
I1111 20:31:30.419940   948 net.cpp:477] fc7 <- fc6
I1111 20:31:30.419953   948 net.cpp:433] fc7 -> fc7
I1111 20:31:30.491210   948 net.cpp:155] Setting up fc7
I1111 20:31:30.491278   948 net.cpp:163] Top shape: 10 4096 (40960)
I1111 20:31:30.491300   948 layer_factory.hpp:76] Creating layer relu7
I1111 20:31:30.491322   948 net.cpp:110] Creating Layer relu7
I1111 20:31:30.491334   948 net.cpp:477] relu7 <- fc7
I1111 20:31:30.491349   948 net.cpp:419] relu7 -> fc7 (in-place)
I1111 20:31:30.491369   948 net.cpp:155] Setting up relu7
I1111 20:31:30.491380   948 net.cpp:163] Top shape: 10 4096 (40960)
I1111 20:31:30.491390   948 layer_factory.hpp:76] Creating layer drop7
I1111 20:31:30.491405   948 net.cpp:110] Creating Layer drop7
I1111 20:31:30.491415   948 net.cpp:477] drop7 <- fc7
I1111 20:31:30.491427   948 net.cpp:419] drop7 -> fc7 (in-place)
I1111 20:31:30.491443   948 net.cpp:155] Setting up drop7
I1111 20:31:30.491456   948 net.cpp:163] Top shape: 10 4096 (40960)
I1111 20:31:30.491466   948 layer_factory.hpp:76] Creating layer fc8
I1111 20:31:30.491480   948 net.cpp:110] Creating Layer fc8
I1111 20:31:30.491490   948 net.cpp:477] fc8 <- fc7
I1111 20:31:30.491503   948 net.cpp:433] fc8 -> fc8
I1111 20:31:30.508712   948 net.cpp:155] Setting up fc8
I1111 20:31:30.508751   948 net.cpp:163] Top shape: 10 1000 (10000)
I1111 20:31:30.508770   948 layer_factory.hpp:76] Creating layer prob
I1111 20:31:30.508788   948 net.cpp:110] Creating Layer prob
I1111 20:31:30.508800   948 net.cpp:477] prob <- fc8
I1111 20:31:30.508813   948 net.cpp:433] prob -> prob
I1111 20:31:30.508834   948 net.cpp:155] Setting up prob
I1111 20:31:30.508847   948 net.cpp:163] Top shape: 10 1000 (10000)
I1111 20:31:30.508857   948 net.cpp:240] prob does not need backward computation.
I1111 20:31:30.508868   948 net.cpp:240] fc8 does not need backward computation.
I1111 20:31:30.508878   948 net.cpp:240] drop7 does not need backward computation.
I1111 20:31:30.508888   948 net.cpp:240] relu7 does not need backward computation.
I1111 20:31:30.508898   948 net.cpp:240] fc7 does not need backward computation.
I1111 20:31:30.508908   948 net.cpp:240] drop6 does not need backward computation.
I1111 20:31:30.508919   948 net.cpp:240] relu6 does not need backward computation.
I1111 20:31:30.508929   948 net.cpp:240] fc6 does not need backward computation.
I1111 20:31:30.508939   948 net.cpp:240] pool5 does not need backward computation.
I1111 20:31:30.508949   948 net.cpp:240] relu5 does not need backward computation.
I1111 20:31:30.508960   948 net.cpp:240] conv5 does not need backward computation.
I1111 20:31:30.508970   948 net.cpp:240] relu4 does not need backward computation.
I1111 20:31:30.508980   948 net.cpp:240] conv4 does not need backward computation.
I1111 20:31:30.508991   948 net.cpp:240] relu3 does not need backward computation.
I1111 20:31:30.509001   948 net.cpp:240] conv3 does not need backward computation.
I1111 20:31:30.509012   948 net.cpp:240] norm2 does not need backward computation.
I1111 20:31:30.509022   948 net.cpp:240] pool2 does not need backward computation.
I1111 20:31:30.509033   948 net.cpp:240] relu2 does not need backward computation.
I1111 20:31:30.509043   948 net.cpp:240] conv2 does not need backward computation.
I1111 20:31:30.509054   948 net.cpp:240] norm1 does not need backward computation.
I1111 20:31:30.509064   948 net.cpp:240] pool1 does not need backward computation.
I1111 20:31:30.509075   948 net.cpp:240] relu1 does not need backward computation.
I1111 20:31:30.509085   948 net.cpp:240] conv1 does not need backward computation.
I1111 20:31:30.509095   948 net.cpp:283] This network produces output prob
I1111 20:31:30.509116   948 net.cpp:297] Network initialization done.
I1111 20:31:30.509153   948 net.cpp:298] Memory required for data: 62497920
I1111 20:31:31.498029   948 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1111 20:31:31.498083   948 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1111 20:31:31.498095   948 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1111 20:31:31.498103   948 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1111 20:31:32.004907   948 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
Traceback (most recent call last):
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 239, in process
    return self.handle()
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 230, in handle
    return self._delegate(fn, self.fvars, args)
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 420, in _delegate
    return handle_class(cls)
  File "/root/anaconda/lib/python2.7/site-packages/web/application.py", line 396, in handle_class
    return tocall(*args)
  File "/root/ds210_capstone/caffe_script/service/controller.py", line 16, in POST
    return self.baseline()
  File "/root/ds210_capstone/caffe_script/service/app.py", line 19, in baseline
    respond = b.baseline_run(request)
  File "/root/ds210_capstone/caffe_script/service/baseline.py", line 29, in baseline_run
    self.caffe_predict()
  File "/root/ds210_capstone/caffe_script/service/baseline.py", line 124, in caffe_predict
    net.blobs['data'].data[i] = transformer.preprocess('data',
  File "/root/caffe/python/caffe/io.py", line 295, in load_image
    img = skimage.img_as_float(skimage.io.imread(filename)).astype(np.float32)
  File "/root/anaconda/lib/python2.7/site-packages/skimage/io/_io.py", line 100, in imread
    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)
  File "/root/anaconda/lib/python2.7/site-packages/skimage/io/manage_plugins.py", line 207, in call_plugin
    return func(*args, **kwargs)
  File "/root/anaconda/lib/python2.7/site-packages/skimage/io/_plugins/pil_plugin.py", line 46, in imread
    im = Image.open(fname)
  File "/root/anaconda/lib/python2.7/site-packages/PIL/Image.py", line 2248, in open
    fp = builtins.open(fp, "rb")
IOError: [Errno 2] No such file or directory: u'../../../dataset/temp/11899529_409336062593154_26859144_n.jpg'

58.152.249.17:35926 - - [11/Nov/2015 20:31:32] "HTTP/1.1 POST /resources/1" - 500 Internal Server Error
./app.py: 1: ./app.py: import: not found
./app.py: 2: ./app.py: import: not found
from: can't read /var/mail/controller
from: can't read /var/mail/baseline
./app.py: 6: ./app.py: Syntax error: "(" unexpected
WARNING: Logging before InitGoogleLogging() is written to STDERR
I1114 20:19:01.944226 22878 net.cpp:50] Initializing net from parameters: 
name: "CaffeNet"
input: "data"
state {
  phase: TEST
}
input_shape {
  dim: 10
  dim: 3
  dim: 227
  dim: 227
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8"
  top: "prob"
}
I1114 20:19:01.962234 22878 net.cpp:435] Input 0 -> data
I1114 20:19:01.962311 22878 layer_factory.hpp:76] Creating layer conv1
I1114 20:19:01.962342 22878 net.cpp:110] Creating Layer conv1
I1114 20:19:01.962353 22878 net.cpp:477] conv1 <- data
I1114 20:19:01.962373 22878 net.cpp:433] conv1 -> conv1
I1114 20:19:01.962491 22878 net.cpp:155] Setting up conv1
I1114 20:19:01.962519 22878 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1114 20:19:01.962550 22878 layer_factory.hpp:76] Creating layer relu1
I1114 20:19:01.962566 22878 net.cpp:110] Creating Layer relu1
I1114 20:19:01.962589 22878 net.cpp:477] relu1 <- conv1
I1114 20:19:01.962601 22878 net.cpp:419] relu1 -> conv1 (in-place)
I1114 20:19:01.962623 22878 net.cpp:155] Setting up relu1
I1114 20:19:01.962635 22878 net.cpp:163] Top shape: 10 96 55 55 (2904000)
I1114 20:19:01.962646 22878 layer_factory.hpp:76] Creating layer pool1
I1114 20:19:01.962659 22878 net.cpp:110] Creating Layer pool1
I1114 20:19:01.962669 22878 net.cpp:477] pool1 <- conv1
I1114 20:19:01.962680 22878 net.cpp:433] pool1 -> pool1
I1114 20:19:01.962705 22878 net.cpp:155] Setting up pool1
I1114 20:19:01.962718 22878 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1114 20:19:01.962728 22878 layer_factory.hpp:76] Creating layer norm1
I1114 20:19:01.962741 22878 net.cpp:110] Creating Layer norm1
I1114 20:19:01.962750 22878 net.cpp:477] norm1 <- pool1
I1114 20:19:01.962762 22878 net.cpp:433] norm1 -> norm1
I1114 20:19:01.962790 22878 net.cpp:155] Setting up norm1
I1114 20:19:01.962802 22878 net.cpp:163] Top shape: 10 96 27 27 (699840)
I1114 20:19:01.962812 22878 layer_factory.hpp:76] Creating layer conv2
I1114 20:19:01.962826 22878 net.cpp:110] Creating Layer conv2
I1114 20:19:01.962836 22878 net.cpp:477] conv2 <- norm1
I1114 20:19:01.962847 22878 net.cpp:433] conv2 -> conv2
I1114 20:19:01.964133 22878 net.cpp:155] Setting up conv2
I1114 20:19:01.964153 22878 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1114 20:19:01.964169 22878 layer_factory.hpp:76] Creating layer relu2
I1114 20:19:01.964181 22878 net.cpp:110] Creating Layer relu2
I1114 20:19:01.964191 22878 net.cpp:477] relu2 <- conv2
I1114 20:19:01.964215 22878 net.cpp:419] relu2 -> conv2 (in-place)
I1114 20:19:01.964231 22878 net.cpp:155] Setting up relu2
I1114 20:19:01.964241 22878 net.cpp:163] Top shape: 10 256 27 27 (1866240)
I1114 20:19:01.964251 22878 layer_factory.hpp:76] Creating layer pool2
I1114 20:19:01.964263 22878 net.cpp:110] Creating Layer pool2
I1114 20:19:01.964272 22878 net.cpp:477] pool2 <- conv2
I1114 20:19:01.964284 22878 net.cpp:433] pool2 -> pool2
I1114 20:19:01.964298 22878 net.cpp:155] Setting up pool2
I1114 20:19:01.964310 22878 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1114 20:19:01.964320 22878 layer_factory.hpp:76] Creating layer norm2
I1114 20:19:01.964332 22878 net.cpp:110] Creating Layer norm2
I1114 20:19:01.964342 22878 net.cpp:477] norm2 <- pool2
I1114 20:19:01.964354 22878 net.cpp:433] norm2 -> norm2
I1114 20:19:01.964367 22878 net.cpp:155] Setting up norm2
I1114 20:19:01.964380 22878 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1114 20:19:01.964388 22878 layer_factory.hpp:76] Creating layer conv3
I1114 20:19:01.964402 22878 net.cpp:110] Creating Layer conv3
I1114 20:19:01.964411 22878 net.cpp:477] conv3 <- norm2
I1114 20:19:01.964423 22878 net.cpp:433] conv3 -> conv3
I1114 20:19:01.968173 22878 net.cpp:155] Setting up conv3
I1114 20:19:01.968194 22878 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1114 20:19:01.968210 22878 layer_factory.hpp:76] Creating layer relu3
I1114 20:19:01.968224 22878 net.cpp:110] Creating Layer relu3
I1114 20:19:01.968233 22878 net.cpp:477] relu3 <- conv3
I1114 20:19:01.968245 22878 net.cpp:419] relu3 -> conv3 (in-place)
I1114 20:19:01.968257 22878 net.cpp:155] Setting up relu3
I1114 20:19:01.968269 22878 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1114 20:19:01.968278 22878 layer_factory.hpp:76] Creating layer conv4
I1114 20:19:01.968291 22878 net.cpp:110] Creating Layer conv4
I1114 20:19:01.968300 22878 net.cpp:477] conv4 <- conv3
I1114 20:19:01.968312 22878 net.cpp:433] conv4 -> conv4
I1114 20:19:01.971184 22878 net.cpp:155] Setting up conv4
I1114 20:19:01.971204 22878 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1114 20:19:01.971217 22878 layer_factory.hpp:76] Creating layer relu4
I1114 20:19:01.971230 22878 net.cpp:110] Creating Layer relu4
I1114 20:19:01.971240 22878 net.cpp:477] relu4 <- conv4
I1114 20:19:01.971251 22878 net.cpp:419] relu4 -> conv4 (in-place)
I1114 20:19:01.971263 22878 net.cpp:155] Setting up relu4
I1114 20:19:01.971276 22878 net.cpp:163] Top shape: 10 384 13 13 (648960)
I1114 20:19:01.971284 22878 layer_factory.hpp:76] Creating layer conv5
I1114 20:19:01.971297 22878 net.cpp:110] Creating Layer conv5
I1114 20:19:01.971307 22878 net.cpp:477] conv5 <- conv4
I1114 20:19:01.971318 22878 net.cpp:433] conv5 -> conv5
I1114 20:19:01.973261 22878 net.cpp:155] Setting up conv5
I1114 20:19:01.973280 22878 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1114 20:19:01.973297 22878 layer_factory.hpp:76] Creating layer relu5
I1114 20:19:01.973309 22878 net.cpp:110] Creating Layer relu5
I1114 20:19:01.973320 22878 net.cpp:477] relu5 <- conv5
I1114 20:19:01.973330 22878 net.cpp:419] relu5 -> conv5 (in-place)
I1114 20:19:01.973343 22878 net.cpp:155] Setting up relu5
I1114 20:19:01.973356 22878 net.cpp:163] Top shape: 10 256 13 13 (432640)
I1114 20:19:01.973364 22878 layer_factory.hpp:76] Creating layer pool5
I1114 20:19:01.973376 22878 net.cpp:110] Creating Layer pool5
I1114 20:19:01.973386 22878 net.cpp:477] pool5 <- conv5
I1114 20:19:01.973397 22878 net.cpp:433] pool5 -> pool5
I1114 20:19:01.973412 22878 net.cpp:155] Setting up pool5
I1114 20:19:01.973423 22878 net.cpp:163] Top shape: 10 256 6 6 (92160)
I1114 20:19:01.973433 22878 layer_factory.hpp:76] Creating layer fc6
I1114 20:19:01.973455 22878 net.cpp:110] Creating Layer fc6
I1114 20:19:01.973466 22878 net.cpp:477] fc6 <- pool5
I1114 20:19:01.973479 22878 net.cpp:433] fc6 -> fc6
I1114 20:19:02.135998 22878 net.cpp:155] Setting up fc6
I1114 20:19:02.136070 22878 net.cpp:163] Top shape: 10 4096 (40960)
I1114 20:19:02.136092 22878 layer_factory.hpp:76] Creating layer relu6
I1114 20:19:02.136152 22878 net.cpp:110] Creating Layer relu6
I1114 20:19:02.136164 22878 net.cpp:477] relu6 <- fc6
I1114 20:19:02.136180 22878 net.cpp:419] relu6 -> fc6 (in-place)
I1114 20:19:02.136200 22878 net.cpp:155] Setting up relu6
I1114 20:19:02.136211 22878 net.cpp:163] Top shape: 10 4096 (40960)
I1114 20:19:02.136221 22878 layer_factory.hpp:76] Creating layer drop6
I1114 20:19:02.136256 22878 net.cpp:110] Creating Layer drop6
I1114 20:19:02.136267 22878 net.cpp:477] drop6 <- fc6
I1114 20:19:02.136279 22878 net.cpp:419] drop6 -> fc6 (in-place)
I1114 20:19:02.136298 22878 net.cpp:155] Setting up drop6
I1114 20:19:02.136312 22878 net.cpp:163] Top shape: 10 4096 (40960)
I1114 20:19:02.136322 22878 layer_factory.hpp:76] Creating layer fc7
I1114 20:19:02.136335 22878 net.cpp:110] Creating Layer fc7
I1114 20:19:02.136346 22878 net.cpp:477] fc7 <- fc6
I1114 20:19:02.136358 22878 net.cpp:433] fc7 -> fc7
I1114 20:19:02.207901 22878 net.cpp:155] Setting up fc7
I1114 20:19:02.207972 22878 net.cpp:163] Top shape: 10 4096 (40960)
I1114 20:19:02.207993 22878 layer_factory.hpp:76] Creating layer relu7
I1114 20:19:02.208012 22878 net.cpp:110] Creating Layer relu7
I1114 20:19:02.208025 22878 net.cpp:477] relu7 <- fc7
I1114 20:19:02.208040 22878 net.cpp:419] relu7 -> fc7 (in-place)
I1114 20:19:02.208058 22878 net.cpp:155] Setting up relu7
I1114 20:19:02.208070 22878 net.cpp:163] Top shape: 10 4096 (40960)
I1114 20:19:02.208080 22878 layer_factory.hpp:76] Creating layer drop7
I1114 20:19:02.208094 22878 net.cpp:110] Creating Layer drop7
I1114 20:19:02.208103 22878 net.cpp:477] drop7 <- fc7
I1114 20:19:02.208115 22878 net.cpp:419] drop7 -> fc7 (in-place)
I1114 20:19:02.208129 22878 net.cpp:155] Setting up drop7
I1114 20:19:02.208142 22878 net.cpp:163] Top shape: 10 4096 (40960)
I1114 20:19:02.208151 22878 layer_factory.hpp:76] Creating layer fc8
I1114 20:19:02.208165 22878 net.cpp:110] Creating Layer fc8
I1114 20:19:02.208175 22878 net.cpp:477] fc8 <- fc7
I1114 20:19:02.208189 22878 net.cpp:433] fc8 -> fc8
I1114 20:19:02.225538 22878 net.cpp:155] Setting up fc8
I1114 20:19:02.225580 22878 net.cpp:163] Top shape: 10 1000 (10000)
I1114 20:19:02.225596 22878 layer_factory.hpp:76] Creating layer prob
I1114 20:19:02.225612 22878 net.cpp:110] Creating Layer prob
I1114 20:19:02.225623 22878 net.cpp:477] prob <- fc8
I1114 20:19:02.225636 22878 net.cpp:433] prob -> prob
I1114 20:19:02.225672 22878 net.cpp:155] Setting up prob
I1114 20:19:02.225684 22878 net.cpp:163] Top shape: 10 1000 (10000)
I1114 20:19:02.225694 22878 net.cpp:240] prob does not need backward computation.
I1114 20:19:02.225704 22878 net.cpp:240] fc8 does not need backward computation.
I1114 20:19:02.225714 22878 net.cpp:240] drop7 does not need backward computation.
I1114 20:19:02.225723 22878 net.cpp:240] relu7 does not need backward computation.
I1114 20:19:02.225733 22878 net.cpp:240] fc7 does not need backward computation.
I1114 20:19:02.225742 22878 net.cpp:240] drop6 does not need backward computation.
I1114 20:19:02.225751 22878 net.cpp:240] relu6 does not need backward computation.
I1114 20:19:02.225761 22878 net.cpp:240] fc6 does not need backward computation.
I1114 20:19:02.225771 22878 net.cpp:240] pool5 does not need backward computation.
I1114 20:19:02.225781 22878 net.cpp:240] relu5 does not need backward computation.
I1114 20:19:02.225790 22878 net.cpp:240] conv5 does not need backward computation.
I1114 20:19:02.225800 22878 net.cpp:240] relu4 does not need backward computation.
I1114 20:19:02.225811 22878 net.cpp:240] conv4 does not need backward computation.
I1114 20:19:02.225821 22878 net.cpp:240] relu3 does not need backward computation.
I1114 20:19:02.225831 22878 net.cpp:240] conv3 does not need backward computation.
I1114 20:19:02.225841 22878 net.cpp:240] norm2 does not need backward computation.
I1114 20:19:02.225850 22878 net.cpp:240] pool2 does not need backward computation.
I1114 20:19:02.225859 22878 net.cpp:240] relu2 does not need backward computation.
I1114 20:19:02.225869 22878 net.cpp:240] conv2 does not need backward computation.
I1114 20:19:02.225906 22878 net.cpp:240] norm1 does not need backward computation.
I1114 20:19:02.225917 22878 net.cpp:240] pool1 does not need backward computation.
I1114 20:19:02.225927 22878 net.cpp:240] relu1 does not need backward computation.
I1114 20:19:02.225937 22878 net.cpp:240] conv1 does not need backward computation.
I1114 20:19:02.225947 22878 net.cpp:283] This network produces output prob
I1114 20:19:02.225973 22878 net.cpp:297] Network initialization done.
I1114 20:19:02.225983 22878 net.cpp:298] Memory required for data: 62497920
I1114 20:19:03.607452 22878 upgrade_proto.cpp:609] Attempting to upgrade input file specified using deprecated transformation parameters: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1114 20:19:03.607516 22878 upgrade_proto.cpp:612] Successfully upgraded file specified using deprecated data transformation parameters.
W1114 20:19:03.607527 22878 upgrade_proto.cpp:614] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1114 20:19:03.607537 22878 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../../../caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
I1114 20:19:04.123546 22878 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
50.152.203.175:58389 - - [14/Nov/2015 20:19:04] "HTTP/1.1 POST /resources/1" - 200 OK
http://0.0.0.0:3000/
file no. 1 processed: ../../../dataset/temp/12071132_117024925320109_1448778029_n.jpg
