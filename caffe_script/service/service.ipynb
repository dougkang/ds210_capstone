{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Code for the Service using Web.py\n",
    "This contains all necessary code block to create the service. Main code file contains:\n",
    "- app.py (for initiating the web service)\n",
    "- controller.py (for directing the request and respond)\n",
    "- caffe_model.py (for applying the various caffe model to generate a respond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted code from: https://gist.github.com/w0rm/3907294"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import web\n",
    "import json\n",
    "from controller import Controller\n",
    "from caffe_models import Caffe_Models\n",
    "\n",
    "urls = (\n",
    "    r'/resources(?:/(?P<resource_id>[0-9]+))?',\n",
    "    'ResourceController',\n",
    ")\n",
    "\n",
    "class ResourceController(Controller):\n",
    "\n",
    "    def list(self):\n",
    "        return \"list resources\", format\n",
    "    \n",
    "    #MODELS THAT WE USE    \n",
    "    def style_flickr(self):\n",
    "        request = json.loads(web.data())\n",
    "        cm = Caffe_Models('style_flickr')\n",
    "        return cm.caffe_models_run(request) #response\n",
    "\n",
    "    def object_lenet(self):\n",
    "        request = json.loads(web.data())\n",
    "        cm = Caffe_Models('object_lenet')\n",
    "        return cm.caffe_models_run(request) #response\n",
    "    \n",
    "    def place_lenet(self):\n",
    "        request = json.loads(web.data())\n",
    "        cm = Caffe_Models('place_lenet')\n",
    "        return cm.caffe_models_run(request) #response\n",
    "    \n",
    "    \n",
    "    #MODELS THAT WE ARE NOT USING\n",
    "\n",
    "    ## this is the baseline\n",
    "    def object_imagenet(self):\n",
    "        request = json.loads(web.data())\n",
    "        cm = Caffe_Models('object_imagenet')\n",
    "        return cm.caffe_models_run(request) #response\n",
    "\n",
    "    def place_cnn(self):\n",
    "        request = json.loads(web.data())\n",
    "        cm = Caffe_Models('place_cnn')\n",
    "        return cm.caffe_models_run(request) #response\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "## ORIGINAL RESTFUL CONTROLLER\n",
    "#     def get(self, resource_id):\n",
    "#         return \"retrieved resource\", resource_id\n",
    "\n",
    "#     def create(self):\n",
    "#         resource = json.loads(web.data())\n",
    "#         return \"created resource\", resource\n",
    "\n",
    "#     def update(self, resource_id):\n",
    "#         resource = json.loads(web.data())\n",
    "#         return \"updated resource\", resource_id, resource\n",
    "\n",
    "#     def delete(self, resource_id):\n",
    "#         return \"deleted resource\", resource_id\n",
    "\n",
    "app = web.application(urls, globals())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##controller.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting controller.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile controller.py\n",
    "import web\n",
    "\n",
    "class Controller:\n",
    "\n",
    "    methods = (\"list\", \"get\", \"create\", \"update\", \"delete\",\n",
    "               \"update_collection\", \"delete_collection\")\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if name in self.methods and \"headers\" in web.ctx:\n",
    "            raise web.badrequest()\n",
    "        else:\n",
    "            raise AttributeError\n",
    "\n",
    "    def POST(self, resource_id=None):\n",
    "        if resource_id==\"1\":\n",
    "            return self.style_flickr()\n",
    "        elif resource_id==\"2\":\n",
    "            return self.object_lenet()\n",
    "        elif resource_id==\"3\":\n",
    "            return self.place_lenet()\n",
    "        else:\n",
    "            raise web.badrequest()\n",
    "\n",
    "## ORIGINAL CRUD OPERATION FROM RESTFUL CONTROLLER            \n",
    "#     def GET(self, resource_id=None):\n",
    "#         if resource_id is None:\n",
    "#             return self.list()\n",
    "#         else:\n",
    "#             return self.get(resource_id)\n",
    "#     #READ - TEST in browswer: http://localhost:8080/resources/23\n",
    "        \n",
    "#     def POST(self, resource_id=None):\n",
    "#         if resource_id is None:\n",
    "#             return self.create()\n",
    "#         else:\n",
    "#             raise web.badrequest()\n",
    "#     #CREATE - TEST in terminal: curl -X POST  -H \"Content-Type: application/json\" -d '{\"title\":\"a title\",\"description\":\"a description\",\"type\":\"a type\",\"author\":\"an author\"}' -i http://localhost:8080/resources/\n",
    "    \n",
    "#     def PUT(self, resource_id=None):\n",
    "#         if resource_id is None:\n",
    "#             return self.update_collection()\n",
    "#         else:\n",
    "#             return self.update(resource_id)\n",
    "#     #UPDATE: TEST in terminal: curl -X PUT  -H \"Content-Type: application/json\" -d '{\"id\":\"23\", \"title\":\"a title\",\"description\":\"a description\",\"type\":\"a type\",\"author\":\"an author\"}' -i http://localhost:8080/resources/23\n",
    "    \n",
    "#     def DELETE(self, resource_id=None):\n",
    "#         if resource_id is None:\n",
    "#             return self.delete_collection()\n",
    "#         else:\n",
    "#             return self.delete(resource_id)\n",
    "#     #DELETE: TEST in terminal: curl -X DELETE http://localhost:8080/resources/23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting caffe_models.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile caffe_models.py\n",
    "#Grab new images\n",
    "import ast\n",
    "import os\n",
    "import json\n",
    "import urllib\n",
    "import posixpath\n",
    "import urlparse \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import caffe\n",
    "import sys\n",
    "\n",
    "class Caffe_Models():\n",
    "    \n",
    "    def __init__(self, model_name):\n",
    "        if model_name=='style_flickr':\n",
    "            self.model_path = 'models/finetune_flickr_style/finetune_flickr_style.caffemodel'\n",
    "            self.model_labels = 'examples/finetune_flickr_style/style_names.txt'\n",
    "            self.model_deploy='models/finetune_flickr_style/deploy.prototxt'\n",
    "            self.model_mean='python/caffe/imagenet/ilsvrc_2012_mean.npy'\n",
    "            self.x_size=227\n",
    "            self.y_size=227\n",
    "        elif model_name=='place_lenet':\n",
    "            self.model_path = 'models/googlenet_places205/googlelet_places205_train_iter_2400000.caffemodel'\n",
    "            self.model_labels = 'models/placesCNN/categoryIndex_places205.csv'\n",
    "            self.model_deploy='models/googlenet_places205/deploy_places205.protxt'\n",
    "            self.model_mean='python/caffe/imagenet/ilsvrc_2012_mean.npy'\n",
    "            self.x_size=224\n",
    "            self.y_size=224\n",
    "        elif model_name=='object_lenet': \n",
    "            self.model_path = 'models/bvlc_googlenet/bvlc_googlenet.caffemodel'\n",
    "            self.model_labels = 'data/ilsvrc12/synset_words.txt'\n",
    "            self.model_deploy='models/bvlc_googlenet/deploy.prototxt'\n",
    "            self.model_mean='python/caffe/imagenet/ilsvrc_2012_mean.npy'\n",
    "            self.x_size=224\n",
    "            self.y_size=224\n",
    "#         elif model_name=='object_imagenet':\n",
    "#             self.model_path ='models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "#             self.model_labels = 'data/ilsvrc12/synset_words.txt'\n",
    "#             self.model_deploy='models/bvlc_reference_caffenet/deploy.prototxt'\n",
    "#         elif model_name=='place_cnn':\n",
    "#             self.model_path = 'models/placesCNN/places205CNN_iter_300000.caffemodel'\n",
    "#             self.model_labels = 'models/placesCNN/categoryIndex_places205.csv'\n",
    "#             self.model_deploy='models/placesCNN/places205CNN_deploy.prototxt'\n",
    "              \n",
    "        self.index=0\n",
    "        self.limit=999\n",
    "        self.num_images=0\n",
    "        self.num_guesses=5\n",
    "        self.images = {}\n",
    "        self.predictions = {}\n",
    "        self.DATA_PATH = \"../../../dataset/\"\n",
    "        self.caffe_root = '../../../caffe/'\n",
    "\n",
    "    #main function for running the baseline script\n",
    "    def caffe_models_run(self,request):\n",
    "        self.generate_image(request)\n",
    "        self.caffe_setup()\n",
    "        self.caffe_predict()\n",
    "        return self.predictions\n",
    "\n",
    "    #generate images\n",
    "    def generate_image(self,request):\n",
    "        #clean up temp file\n",
    "        for f in os.listdir(self.DATA_PATH+\"temp/\"):\n",
    "            os.remove(self.DATA_PATH+\"temp/\"+f)\n",
    "           \n",
    "        #for each feed_id, create image and set index for images\n",
    "        for feed_id, image_url in request.iteritems():\n",
    "            \n",
    "            #read json but need to handle index error as certain lines of JSON has errors\n",
    "            #during as we attempt to extract the value in image_url\n",
    "            try:\n",
    "                #figure out filename\n",
    "                path = urlparse.urlsplit(image_url).path\n",
    "                filename = posixpath.basename(path)\n",
    "                image_path = self.DATA_PATH+\"temp/\"+filename\n",
    "                #download to local folder and resize image\n",
    "                urllib.urlretrieve(image_url,image_path)\n",
    "                \n",
    "                #need to handle potential error due to issues not being able to open image file\n",
    "                try: \n",
    "                    img = Image.open(image_path)\n",
    "                    img.thumbnail((256,256),Image.ANTIALIAS) #best quality\n",
    "                    #set limit on number of images to process\n",
    "                    self.index+=1\n",
    "                    print \"file no.\",self.index,\"processed:\",image_path\n",
    "                    self.images[feed_id]=image_path\n",
    "                    self.num_images+=1\n",
    "                    if self.index==self.limit: break\n",
    "                except IOError:\n",
    "                    print \"Cannot open image: remove image and go to next line of JSON\"\n",
    "                    os.remove(image_path)\n",
    "                    self.images[feed_id]=\"NA\"\n",
    "\n",
    "            except IndexError:\n",
    "                print \"Index error with line of JSON: ignore and go to next line of JSON\"\n",
    "                self.images[feed_id]=\"NA\"\n",
    "\n",
    "                \n",
    "                \n",
    "    #Import required modules, set plotting parameters, and run \n",
    "    #./scripts/download_model_binary.py models/bvlc_reference_caffenet \n",
    "    #to get the pretrained CaffeNet model if it hasn't yet been fetched\n",
    "    def caffe_setup(self):\n",
    "        # Make sure that caffe is on the python path:\n",
    "        sys.path.insert(0, self.caffe_root + 'python')\n",
    "\n",
    "        plt.rcParams['figure.figsize'] = (10, 10)\n",
    "        plt.rcParams['image.interpolation'] = 'nearest'\n",
    "        plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "#         ##No need to download as Roselind already downloaded the file\n",
    "#         if not os.path.isfile(self.caffe_root + self.model_path):\n",
    "# #         if not os.path.isfile(self.caffe_root + 'models/finetune_flickr_style/finetune_flickr_style.caffemodel'):\n",
    "# #         if not os.path.isfile(self.caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'):\n",
    "#             print(\"Downloading pre-trained \"+self.model_long_name+\" model...\")   \n",
    "# #             print(\"Downloading pre-trained finetune_flickr_style model...\")   \n",
    "# #             print(\"Downloading pre-trained CaffeNet model...\")       \n",
    "#             #QUESTIONS... DIDN\"T CHANGE!!!\n",
    "#             os.system(self.caffe_root+\"scripts/download_model_binary.py caffe/models/bvlc_reference_caffenet\")\n",
    "        \n",
    "    #Make image predictions\n",
    "    def caffe_predict(self):\n",
    "        \n",
    "        # Set Caffe to CPU mode, load the net in the test phase for inference, and configure input preprocessing.\n",
    "        caffe.set_mode_cpu()\n",
    "        ##CHANGE\n",
    "        net = caffe.Net(self.caffe_root + self.model_deploy,\n",
    "                        self.caffe_root + self.model_path,\n",
    "                        caffe.TEST)\n",
    "#         net = caffe.Net(self.caffe_root + 'models/finetune_flickr_style/deploy.prototxt',\n",
    "#                         self.caffe_root + 'models/finetune_flickr_style/finetune_flickr_style.caffemodel',\n",
    "#                         caffe.TEST)\n",
    "#         net = caffe.Net(self.caffe_root + 'models/bvlc_reference_caffenet/deploy.prototxt',\n",
    "#                     self.caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel',\n",
    "#                     caffe.TEST)\n",
    "\n",
    "\n",
    "        # input preprocessing: 'data' is the name of the input blob == net.inputs[0]\n",
    "        transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "        transformer.set_transpose('data', (2,0,1))\n",
    "        ## QUESTION\n",
    "        transformer.set_mean('data', np.load(self.caffe_root + self.model_mean).mean(1).mean(1)) # mean pixel\n",
    "        transformer.set_raw_scale('data', 255)  # the reference model operates on images in [0,255] range instead of [0,1]\n",
    "        transformer.set_channel_swap('data', (2,1,0))  # the reference model has channels in BGR order instead of RGB\n",
    "\n",
    "        # set net to batch size to be the total number of images\n",
    "        net.blobs['data'].reshape(self.num_images,3,self.x_size,self.y_size)\n",
    "\n",
    "        \n",
    "        # load labels\n",
    "        ##CHANGE\n",
    "        labels_filename = self.caffe_root + self.model_labels\n",
    "#         imagenet_labels_filename = self.caffe_root + 'examples/finetune_flickr_style/style_names.txt'\n",
    "#         imagenet_labels_filename = self.caffe_root + 'data/ilsvrc12/synset_words.txt'\n",
    "        try:\n",
    "        ##CHANGE\n",
    "            labels = np.loadtxt(labels_filename, str, delimiter='\\t')\n",
    "#             labels = np.loadtxt(imagenet_labels_filename, str, delimiter='\\t')\n",
    "        except:\n",
    "#             !../data/ilsvrc12/get_ilsvrc_aux.sh\n",
    "            os.system(self.caffe_root + 'data/ilsvrc12/get_ilsvrc_aux.sh')\n",
    "\n",
    "        ##CHANGE\n",
    "            labels = np.loadtxt(labels_filename, str, delimiter='\\t')\n",
    "#             labels = np.loadtxt(imagenet_labels_filename, str, delimiter='\\t')\n",
    "\n",
    "        # load image data into model\n",
    "#         for (dirpath, dirnames, filenames) in walk(self.DATA_PATH+\"temp/\"):\n",
    "        i=0\n",
    "        image_ids = {}\n",
    "        for feed_id, img_path in self.images.iteritems():\n",
    "            #load image into caffe preprocessor\n",
    "            net.blobs['data'].data[i] = transformer.preprocess('data',  \n",
    "                caffe.io.load_image(img_path))\n",
    "            image_ids[feed_id]=i\n",
    "            i+=1\n",
    "\n",
    "        #batch computation step (show computation time)\n",
    "        net.forward()  # call once for allocation\n",
    "#         %timeit net.forward()\n",
    "        \n",
    "        #display result, showing top 5 prediction for each image\n",
    "#         for (dirpath, dirnames, filenames) in walk('../../../dataset/images/'):\n",
    "#             for i,filename in enumerate(filenames):\n",
    "        for feed_id,i in image_ids.iteritems():\n",
    "            probs = net.blobs['prob'].data[i].flatten()\n",
    "            top_probs=probs[-1:-1-self.num_guesses:-1]\n",
    "            top_k = probs.argsort()[-1:-1-self.num_guesses:-1]\n",
    "        \n",
    "            top_predictions = labels[top_k]\n",
    "\n",
    "            for top_prob,top_prediction in zip(top_probs,top_predictions):\n",
    "                self.predictions.setdefault(feed_id, [])\n",
    "                pred_id = top_prediction[:9]\n",
    "                pred_name = top_prediction[11:]\n",
    "                self.predictions[feed_id].append({\"id\":pred_id,\"name\":pred_name,\"score\":top_prob}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file no. 1 processed: ../../../dataset/temp/12071132_117024925320109_1448778029_n.jpg\n",
      "file no. 2 processed: ../../../dataset/temp/11899529_409336062593154_26859144_n.jpg\n",
      "file no. 3 processed: ../../../dataset/temp/12139791_172476163092798_682238343_n.jpg\n",
      "file no. 4 processed: ../../../dataset/temp/10919675_339630669566407_1560505453_n.jpg\n",
      "file no. 5 processed: ../../../dataset/temp/11377801_146811182334693_2053033951_n.jpg\n",
      "{'1094301226639611969_1016687101': [{'score': 0.093098111, 'id': 'Pastel', 'name': ''}, {'score': 0.00094565586, 'id': 'Vintage', 'name': ''}, {'score': 0.009112522, 'id': 'Romantic', 'name': ''}, {'score': 0.00051206991, 'id': 'Melanchol', 'name': ''}, {'score': 0.0016330597, 'id': 'Bright', 'name': ''}], '901390003869460339_1016673720': [{'score': 0.065550283, 'id': 'Vintage', 'name': ''}, {'score': 0.00089605176, 'id': 'Bokeh', 'name': ''}, {'score': 0.00041621225, 'id': 'Pastel', 'name': ''}, {'score': 0.083875611, 'id': 'Depth of ', 'name': 'eld'}, {'score': 4.8546211e-05, 'id': 'Romantic', 'name': ''}], '1091411570335070017_1002181196': [{'score': 0.098842449, 'id': 'Bright', 'name': ''}, {'score': 0.00038663961, 'id': 'Melanchol', 'name': ''}, {'score': 0.00012832184, 'id': 'Horror', 'name': ''}, {'score': 0.012524976, 'id': 'Romantic', 'name': ''}, {'score': 0.00030157017, 'id': 'Vintage', 'name': ''}], '1085670910110935094_1001957249': [{'score': 0.18516627, 'id': 'Detailed', 'name': ''}, {'score': 6.0314433e-06, 'id': 'Romantic', 'name': ''}, {'score': 0.0016276196, 'id': 'Pastel', 'name': ''}, {'score': 0.066416174, 'id': 'Depth of ', 'name': 'eld'}, {'score': 1.7392495e-05, 'id': 'Vintage', 'name': ''}], '1079932954249514250_1009689594': [{'score': 0.17882816, 'id': 'Romantic', 'name': ''}, {'score': 0.0010678327, 'id': 'Melanchol', 'name': ''}, {'score': 0.014969192, 'id': 'Vintage', 'name': ''}, {'score': 0.047268059, 'id': 'Bokeh', 'name': ''}, {'score': 0.002108936, 'id': 'Pastel', 'name': ''}]}\n"
     ]
    }
   ],
   "source": [
    "#test code\n",
    "!chmod +x app.py\n",
    "!chmod +x controller.py\n",
    "!chmod +x caffe_models.py\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from caffe_models import Caffe_Models\n",
    "\n",
    "request = {\"1094301226639611969_1016687101\": \"https://scontent.cdninstagram.com/hphotos-xfa1/t51.2885-15/e35/12071132_117024925320109_1448778029_n.jpg\", \"1079932954249514250_1009689594\": \"https://scontent.cdninstagram.com/hphotos-xaf1/t51.2885-15/s640x640/sh0.08/e35/11377801_146811182334693_2053033951_n.jpg\", \"901390003869460339_1016673720\": \"https://scontent.cdninstagram.com/hphotos-xft1/t51.2885-15/e15/10919675_339630669566407_1560505453_n.jpg\", \"1091411570335070017_1002181196\": \"https://scontent.cdninstagram.com/hphotos-xaf1/t51.2885-15/s640x640/sh0.08/e35/12139791_172476163092798_682238343_n.jpg\", \"1085670910110935094_1001957249\": \"https://scontent.cdninstagram.com/hphotos-xfa1/t51.2885-15/e35/11899529_409336062593154_26859144_n.jpg\"}\n",
    "# b = Baseline()\n",
    "# respond = b.baseline_run(request)\n",
    "# print respond\n",
    "\n",
    "cm = Caffe_Models('style_flickr')\n",
    "# cm = Caffe_Models('place_lenet')\n",
    "# cm = Caffe_Models('object_lenet')\n",
    "respond = cm.caffe_models_run(request) #response\n",
    "print respond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Appendix: For Testing Web.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting service.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile service.py\n",
    "import web\n",
    "import json\n",
    "# import index\n",
    "\n",
    "urls = (\n",
    "    '/', 'index'\n",
    ")\n",
    "\n",
    "class index:\n",
    "    #for testing purpose\n",
    "    def GET(self):\n",
    "        pyDict = {'test1':'works','test2':\"works too\"}\n",
    "        web.header('Content-Type', 'application/json')\n",
    "        return json.dumps(pyDict)\n",
    "\n",
    "    def POST(self):\n",
    "#         pyDict = {'one':1,'two':2}\n",
    "        pyDict = web.input()\n",
    "        web.header('Content-Type', 'application/json')\n",
    "        return json.dumps(pyDict)\n",
    "\n",
    "##ORIGINAL TEST CODE\n",
    "# class index:\n",
    "#     def GET(self):\n",
    "#         return \"Hello1, world!\"\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    app = web.application(urls, globals())\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://0.0.0.0:8080/\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!chmod +x service.py\n",
    "!python service.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
